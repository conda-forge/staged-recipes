jobs:
- job: linux_64
  condition: not(eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  pool:
    vmImage: ubuntu-latest
  timeoutInMinutes: 360
  steps:
  - script: |
      sudo mkdir -p /opt/empty_dir
      for d in \
          /opt/ghc \
          /opt/hostedtoolcache \
          /usr/lib/jvm \
          /usr/local/.ghcup \
          /usr/local/android \
          /usr/local/powershell \
          /usr/share/dotnet \
          /usr/share/swift \
          ; do
          sudo rsync --stats -a --delete /opt/empty_dir/ $d || true
      done
    displayName: Manage disk space

  - script: |
      sudo fallocate -l 10GiB /swapfile || true
      sudo chmod 600 /swapfile || true
      sudo mkswap /swapfile || true
      sudo swapon /swapfile || true
    displayName: Create swap file

  - script: |
      # sudo pip install --upgrade pip
      sudo pip install setuptools shyaml
    displayName: Install dependencies

  - script: |
      set -e

      # make sure there is a package directory so that artifact publishing works
      mkdir -p build_artifacts/{noarch,linux-64}/

      export CI=azure
      export CONFIG=linux64
      export DOCKER_IMAGE=quay.io/condaforge/linux-anvil-cos7-x86_64
      export AZURE=True
      .scripts/run_docker_build.sh

    displayName: Run docker build
    name: linux_64_build

  - publish: build_artifacts/linux-64/
    artifact: conda_pkgs_linux

  - publish: build_artifacts/noarch/
    artifact: conda_pkgs_noarch

- job: linux_64_cuda_118
  dependsOn: linux_64
  condition: and(not(eq(variables['Build.SourceBranch'], 'refs/heads/main')), eq(dependencies.linux_64.outputs['linux_64_build.NEED_CUDA'], '1'))
  pool:
    vmImage: ubuntu-latest
  timeoutInMinutes: 360
  steps:
  - script: |
      sudo mkdir -p /opt/empty_dir
      for d in \
          /opt/ghc \
          /opt/hostedtoolcache \
          /usr/lib/jvm \
          /usr/local/.ghcup \
          /usr/local/android \
          /usr/local/powershell \
          /usr/share/dotnet \
          /usr/share/swift \
          ; do
          sudo rsync --stats -a --delete /opt/empty_dir/ $d || true
      done
    displayName: Manage disk space

  - script: |
      # sudo pip install --upgrade pip
      sudo pip install setuptools shyaml
    displayName: Install dependencies

  - script: |
      set -e

      # make sure there is a package directory so that artifact publishing works
      mkdir -p build_artifacts/linux-64/

      export CI=azure
      export CONFIG=linux64_cuda118
      export DOCKER_IMAGE=quay.io/condaforge/linux-anvil-cuda:11.8
      export AZURE=True
      .scripts/run_docker_build.sh

    displayName: Run docker build for CUDA 11.8
  - publish: build_artifacts/linux-64/
    artifact: conda_pkgs_linux_64_cuda118

- job: linux_64_cuda_120
  dependsOn: linux_64
  condition: and(not(eq(variables['Build.SourceBranch'], 'refs/heads/main')), eq(dependencies.linux_64.outputs['linux_64_build.NEED_CUDA'], '1'))
  pool:
    vmImage: ubuntu-latest
  timeoutInMinutes: 360
  steps:
  - script: |
      sudo mkdir -p /opt/empty_dir
      for d in \
          /opt/ghc \
          /opt/hostedtoolcache \
          /usr/lib/jvm \
          /usr/local/.ghcup \
          /usr/local/android \
          /usr/local/powershell \
          /usr/share/dotnet \
          /usr/share/swift \
          ; do
          sudo rsync --stats -a --delete /opt/empty_dir/ $d || true
      done
    displayName: Manage disk space

  - script: |
      # sudo pip install --upgrade pip
      sudo pip install setuptools shyaml
    displayName: Install dependencies

  - script: |
      set -e

      # make sure there is a package directory so that artifact publishing works
      mkdir -p build_artifacts/linux-64/

      export CI=azure
      export CONFIG=linux64_cuda120
      export DOCKER_IMAGE=quay.io/condaforge/linux-anvil-cos7-x86_64
      export AZURE=True
      .scripts/run_docker_build.sh

    displayName: Run docker build for CUDA 12.0
  - publish: build_artifacts/linux-64/
    artifact: conda_pkgs_linux_64_cuda120
