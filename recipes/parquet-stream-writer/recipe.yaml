context:
  version: 0.1.0

package:
  name: parquet-stream-writer
  version: ${{ version }}

source:
- url: https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-${{ version }}.tar.gz
  sha256: 2628edf077604ca40b409f09b6ff3eae864107c2a9394ea56ab52e79ffcedd67

build:
  script: ${{ PYTHON }} -m pip install .
  noarch: python
  build: 0

requirements:
  host:
  - python
  - uv_build >=0.9,<0.10
  - pip
  run:
  - python
  - pyarrow >=21.0

tests:
- python:
    imports:
    - parquet_stream_writer
    pip_check: true

about:
  license: MIT
  license_file: LICENSE
  homepage: https://github.com/apcamargo/parquet-stream-writer
  summary: Write streaming data to Parquet files with automatic sharding.
  description: |
    `parquet-stream-writer` provides a memory-efficient way to write streaming
    data to Parquet. It buffers incoming records and writes them incrementally
    to disk. When a configurable size threshold is reached, it starts a new
    Parquet shard, avoiding the need to load the entire dataset into memory.
    This makes this library suitable for datasets that are too large to fit in
    the available memory or for continuously generated data.

extra:
  recipe-maintainers:
    - apcamargo
