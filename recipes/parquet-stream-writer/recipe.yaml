context:
  version: 0.2.0

package:
  name: parquet-stream-writer
  version: ${{ version }}

source:
- url: https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-${{ version }}.tar.gz
  sha256: 2b74fc464c41722498e5ce8481f8cd6bddd1607db7d39b87760a6e50740760cc

build:
  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  noarch: python
  number: 0

requirements:
  host:
  - python ${{ python_min }}.*
  - uv-build >=0.9,<0.10
  - pip
  run:
  - python >=${{ python_min }}
  - pyarrow >=21.0

tests:
- python:
    imports:
    - parquet_stream_writer
    pip_check: true
    python_version: ${{ python_min }}.*

about:
  license: MIT
  license_file: LICENSE
  homepage: https://github.com/apcamargo/parquet-stream-writer
  summary: Write streaming data to Parquet files with automatic sharding.
  description: |
    `parquet-stream-writer` provides a memory-efficient way to write streaming
    data to Parquet. It buffers incoming records and writes them incrementally
    to disk. When a configurable size threshold is reached, it starts a new
    Parquet shard, avoiding the need to load the entire dataset into memory.
    This makes this library suitable for datasets that are too large to fit in
    the available memory or for continuously generated data.

extra:
  recipe-maintainers:
    - apcamargo
