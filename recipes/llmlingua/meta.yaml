{% set name = "llmlingua" %}
{% set version = "0.2.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/llmlingua-{{ version }}.tar.gz
  sha256: a892093a945ea8ac5f06e84481ef63fa1eeabdbcddb268ad9a7d2524bdc84718

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python >=3.8
    - pip
  run:
    - python >=3.8
    - transformers >=4.26.0
    - accelerate
    - pytorch
    - tiktoken
    - nltk
    - numpy

test:
  imports:
    - llmlingua
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/microsoft/LLMLingua
  summary: "To speed up LLMs' inference and enhance LLM's perceive of key information, compress the prompt and KV-Cache, which achieves up to 20x compression with minimal performance loss."
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - jan-janssen
