{% set name = "gptcache" %}
{% set version = "0.1.11" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/gptcache-{{ version }}.tar.gz
  sha256: d4a18a7587e45916fb406c2e949f2d225cdf1f8fecd0f68ee3de2e7a9cfe30c2

build:
  skip: true  # [win]
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.8
    - pip
  run:
    - python >=3.8
    - openai
    - numpy
    - cachetools

test:
  imports:
    - gptcache
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/zilliztech/GPTCache
  summary: GPTCache, a powerful caching library that can be used to speed up and lower the cost of chat applications that rely on the LLM service. GPTCache works as a memcache for AIGC applications, similar to how Redis works for traditional applications.
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - YYYasin19
