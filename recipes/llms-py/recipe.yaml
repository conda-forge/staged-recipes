# yaml-language-server: $schema=https://raw.githubusercontent.com/prefix-dev/recipe-format/main/schema.json
schema_version: 1

context:
  name: llms-py
  version: "2.0.32"

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/llms_py-${{ version }}.tar.gz
  sha256: 241d95534094b7c6666de94e43b5dbcb792edb654f4d6c9809b905c33adfd5f6

build:
  number: 0
  noarch: python
  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  python:
    entry_points:
      - llms = llms.main:main

requirements:
  host:
    - python ${{ python_min }}.*
    - setuptools >=45
    - wheel
    - pip
  run:
    - python >=${{ python_min }}
    - aiohttp
    - pillow

tests:
  - python:
      imports:
        - llms
      pip_check: true
      python_version:
        - ${{ python_min }}.*
  - requirements:
      run:
        - python ${{ python_min }}.*
        - pip
    script:
      - llms --help

about:
  summary: A lightweight CLI tool and OpenAI-compatible server for querying multiple Large Language Model (LLM) providers
  license: BSD-3-Clause
  license_file: LICENSE
  homepage: https://github.com/ServiceStack/llms

extra:
  recipe-maintainers:
    - rxm7706
