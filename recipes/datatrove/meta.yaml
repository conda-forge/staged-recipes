{% set name = "datatrove" %}
{% set version = "0.2.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/datatrove-{{ version }}.tar.gz
  sha256: 32fb25a49bdfb50cf99cdb7c2537ee58a92c340fbd2efea476ea6669f6cd1eee

build:
  entry_points:
    - check_dataset = datatrove.tools.check_dataset:main
    - merge_stats = datatrove.tools.merge_stats:main
    - launch_pickled_pipeline = datatrove.tools.launch_pickled_pipeline:main
    - failed_logs = datatrove.tools.failed_logs:main
    - inspect_data = datatrove.tools.inspect_data:main
    - jobs_status = datatrove.tools.jobs_status:main
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  host:
    - python >=3.10.0
    - setuptools
    - pip
  run:
    - python >=3.10.0
    - dill >=0.3.0
    - fsspec >=2023.12.2
    - huggingface_hub >=0.17.0
    - humanize
    - loguru >=0.7.0
    - multiprocess
    - numpy >=1.25.0
    - tqdm

test:
  imports:
    - datatrove
  commands:
    - pip check
    - check_dataset --help
    - merge_stats --help
    - launch_pickled_pipeline --help
    - failed_logs --help
    - inspect_data --help
    - jobs_status --help
  requires:
    - pip

about:
  home: https://github.com/huggingface/datatrove
  summary: HuggingFace library to process and filter large amounts of webdata
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - peterbygrave
