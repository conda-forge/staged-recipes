--- qtwebengine/src/3rdparty/chromium/third_party/libvpx/source/config/linux/x64/vpx_dsp_rtcd.h.old	2016-06-07 18:07:16.418374857 -0500
+++ qtwebengine/src/3rdparty/chromium/third_party/libvpx/source/config/linux/x64/vpx_dsp_rtcd.h	2016-06-07 18:09:30.272094664 -0500
@@ -363,9 +363,9 @@
     (void)flags;
 
     vpx_get16x16var = vpx_get16x16var_sse2;
-    if (flags & HAS_AVX2) vpx_get16x16var = vpx_get16x16var_avx2;
+    //if (flags & HAS_AVX2) vpx_get16x16var = vpx_get16x16var_avx2;
     vpx_mse16x16 = vpx_mse16x16_sse2;
-    if (flags & HAS_AVX2) vpx_mse16x16 = vpx_mse16x16_avx2;
+    //if (flags & HAS_AVX2) vpx_mse16x16 = vpx_mse16x16_avx2;
     vpx_sad16x16x3 = vpx_sad16x16x3_c;
     if (flags & HAS_SSE3) vpx_sad16x16x3 = vpx_sad16x16x3_sse3;
     if (flags & HAS_SSSE3) vpx_sad16x16x3 = vpx_sad16x16x3_ssse3;
@@ -377,33 +377,33 @@
     vpx_sad16x8x8 = vpx_sad16x8x8_c;
     if (flags & HAS_SSE4_1) vpx_sad16x8x8 = vpx_sad16x8x8_sse4_1;
     vpx_sad32x16 = vpx_sad32x16_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x16 = vpx_sad32x16_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x16 = vpx_sad32x16_avx2;
     vpx_sad32x16_avg = vpx_sad32x16_avg_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x16_avg = vpx_sad32x16_avg_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x16_avg = vpx_sad32x16_avg_avx2;
     vpx_sad32x32 = vpx_sad32x32_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x32 = vpx_sad32x32_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x32 = vpx_sad32x32_avx2;
     vpx_sad32x32_avg = vpx_sad32x32_avg_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x32_avg = vpx_sad32x32_avg_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x32_avg = vpx_sad32x32_avg_avx2;
     vpx_sad32x32x4d = vpx_sad32x32x4d_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x32x4d = vpx_sad32x32x4d_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x32x4d = vpx_sad32x32x4d_avx2;
     vpx_sad32x64 = vpx_sad32x64_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x64 = vpx_sad32x64_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x64 = vpx_sad32x64_avx2;
     vpx_sad32x64_avg = vpx_sad32x64_avg_sse2;
-    if (flags & HAS_AVX2) vpx_sad32x64_avg = vpx_sad32x64_avg_avx2;
+    //if (flags & HAS_AVX2) vpx_sad32x64_avg = vpx_sad32x64_avg_avx2;
     vpx_sad4x4x3 = vpx_sad4x4x3_c;
     if (flags & HAS_SSE3) vpx_sad4x4x3 = vpx_sad4x4x3_sse3;
     vpx_sad4x4x8 = vpx_sad4x4x8_c;
     if (flags & HAS_SSE4_1) vpx_sad4x4x8 = vpx_sad4x4x8_sse4_1;
     vpx_sad64x32 = vpx_sad64x32_sse2;
-    if (flags & HAS_AVX2) vpx_sad64x32 = vpx_sad64x32_avx2;
+    //if (flags & HAS_AVX2) vpx_sad64x32 = vpx_sad64x32_avx2;
     vpx_sad64x32_avg = vpx_sad64x32_avg_sse2;
-    if (flags & HAS_AVX2) vpx_sad64x32_avg = vpx_sad64x32_avg_avx2;
+    //if (flags & HAS_AVX2) vpx_sad64x32_avg = vpx_sad64x32_avg_avx2;
     vpx_sad64x64 = vpx_sad64x64_sse2;
-    if (flags & HAS_AVX2) vpx_sad64x64 = vpx_sad64x64_avx2;
+    //if (flags & HAS_AVX2) vpx_sad64x64 = vpx_sad64x64_avx2;
     vpx_sad64x64_avg = vpx_sad64x64_avg_sse2;
-    if (flags & HAS_AVX2) vpx_sad64x64_avg = vpx_sad64x64_avg_avx2;
+    //if (flags & HAS_AVX2) vpx_sad64x64_avg = vpx_sad64x64_avg_avx2;
     vpx_sad64x64x4d = vpx_sad64x64x4d_sse2;
-    if (flags & HAS_AVX2) vpx_sad64x64x4d = vpx_sad64x64x4d_avx2;
+    //if (flags & HAS_AVX2) vpx_sad64x64x4d = vpx_sad64x64x4d_avx2;
     vpx_sad8x16x3 = vpx_sad8x16x3_c;
     if (flags & HAS_SSE3) vpx_sad8x16x3 = vpx_sad8x16x3_sse3;
     vpx_sad8x16x8 = vpx_sad8x16x8_c;
@@ -413,15 +413,15 @@
     vpx_sad8x8x8 = vpx_sad8x8x8_c;
     if (flags & HAS_SSE4_1) vpx_sad8x8x8 = vpx_sad8x8x8_sse4_1;
     vpx_variance16x16 = vpx_variance16x16_sse2;
-    if (flags & HAS_AVX2) vpx_variance16x16 = vpx_variance16x16_avx2;
+    //if (flags & HAS_AVX2) vpx_variance16x16 = vpx_variance16x16_avx2;
     vpx_variance32x16 = vpx_variance32x16_sse2;
-    if (flags & HAS_AVX2) vpx_variance32x16 = vpx_variance32x16_avx2;
+    //if (flags & HAS_AVX2) vpx_variance32x16 = vpx_variance32x16_avx2;
     vpx_variance32x32 = vpx_variance32x32_sse2;
-    if (flags & HAS_AVX2) vpx_variance32x32 = vpx_variance32x32_avx2;
+    //if (flags & HAS_AVX2) vpx_variance32x32 = vpx_variance32x32_avx2;
     vpx_variance64x32 = vpx_variance64x32_sse2;
-    if (flags & HAS_AVX2) vpx_variance64x32 = vpx_variance64x32_avx2;
+    //if (flags & HAS_AVX2) vpx_variance64x32 = vpx_variance64x32_avx2;
     vpx_variance64x64 = vpx_variance64x64_sse2;
-    if (flags & HAS_AVX2) vpx_variance64x64 = vpx_variance64x64_avx2;
+    //if (flags & HAS_AVX2) vpx_variance64x64 = vpx_variance64x64_avx2;
 }
 #endif
 
