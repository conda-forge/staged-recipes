{% set name = "sagemaker-huggingface-inference-toolkit" %}
{% set version = "1.1.2" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/sagemaker-huggingface-inference-toolkit-{{ version }}.tar.gz
  sha256: fdf2d5a5cc9d9bc74d511dc93b0785d3f99d72fe17a95309fe6ca7ccfbe59a78

build:
  number: 0
  noarch: python
  entry_points:
    - serve=sagemaker_huggingface_inference_toolkit.serving:main
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.6
  run:
    - huggingface_hub >=0.0.8
    - numpy
    - python
    - retrying
    - sagemaker-inference >=1.5.5
  run_constrained:
    - multi-model-server >=1.1.4
    - tensorflow >=2.3
    - tensorflow-cpu >=2.3
    - torch >=1.4.0

test:
  imports:
    - sagemaker_huggingface_inference_toolkit
  commands:
    - pip check
    - serve --help
  requires:
    - pip

about:
  home: https://github.com/aws/sagemaker-huggingface-inference-toolkit
  summary: Open source library for running inference workload with Hugging Face Deep Learning Containers on Amazon SageMaker.
  license: Apache-2.0
  license_file: LICENSE

extra:
  recipe-maintainers:
    - BastianZim
