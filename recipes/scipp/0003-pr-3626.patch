From 118ef295806601a5325c11fc27d5ef9b3e8dde8e Mon Sep 17 00:00:00 2001
From: Jan-Lukas Wynen <jan-lukas.wynen@ess.eu>
Date: Fri, 20 Dec 2024 10:38:16 +0100
Subject: [PATCH 1/7] Remove attrs from Python

---
 src/scipp/_binding.py                        |   2 -
 src/scipp/compat/dict.py                     |   4 +-
 src/scipp/compat/wrapping.py                 |   3 -
 src/scipp/compat/xarray_compat.py            |   2 +-
 src/scipp/core/__init__.py                   |  13 +--
 src/scipp/core/assignments.py                |  27 +----
 src/scipp/core/binning.py                    |   4 +-
 src/scipp/core/bins.py                       |  31 -----
 src/scipp/core/concepts.py                   |   6 -
 src/scipp/core/cpp_classes.pyi               |  19 ---
 src/scipp/core/deprecation.py                |  51 --------
 src/scipp/core/dimensions.py                 |  14 +--
 src/scipp/core/shape.py                      |   4 +-
 src/scipp/core/util.py                       |   2 -
 src/scipp/io/hdf5.py                         |   6 +-
 src/scipp/testing/assertions.py              |   3 +-
 src/scipp/utils/comparison.py                |  18 +--
 src/scipp/visualization/formatting_html.py   |  36 +-----
 src/scipp/visualization/show.py              |   8 +-
 src/scipp/visualization/table.py             |  27 +----
 tests/bins_test.py                           |  14 +--
 tests/compat/dict_test.py                    |   4 -
 tests/compat/wrapping_test.py                |   5 -
 tests/compat/xarray_compat_test.py           |   6 +-
 tests/coords/transform_coords_test.py        |  62 +++++-----
 tests/data_array_test.py                     | 117 -------------------
 tests/dataset_test.py                        |   4 -
 tests/dicts_test.py                          |   1 -
 tests/io/hdf5_test.py                        |   6 -
 tests/ownership_dataset_test.py              |  96 ++-------------
 tests/readonly_test.py                       |   9 --
 tests/rename_test.py                         |  40 +------
 tests/repr_test.py                           |  10 +-
 tests/scipy/ndimage/footprint_filter_test.py |   8 --
 tests/scipy/ndimage/gaussian_filter_test.py  |   8 --
 tests/scipy/signal/sosfiltfilt_test.py       |   2 -
 tests/shape_test.py                          |   4 +-
 tests/slice_bins_test.py                     |  24 ++--
 tests/slice_by_index_list_test.py            |   2 +-
 tests/testing/assertions_test.py             |  44 -------
 tests/utils/utils_comparison_test.py         |  40 ++-----
 41 files changed, 108 insertions(+), 678 deletions(-)
 delete mode 100644 src/scipp/core/deprecation.py

diff --git a/src/scipp/_binding.py b/src/scipp/_binding.py
index d11c5bcefa..e0e55c7180 100644
--- a/src/scipp/_binding.py
+++ b/src/scipp/_binding.py
@@ -17,10 +17,8 @@
     (core.Dataset, core.DataArray),
     (core.Coords, core.Variable),
     (core.Masks, core.Variable),
-    (core._BinsMeta, core.Variable),
     (core._BinsCoords, core.Variable),
     (core._BinsMasks, core.Variable),
-    (core._BinsAttrs, core.Variable),
 ]
 
 
diff --git a/src/scipp/compat/dict.py b/src/scipp/compat/dict.py
index 39475d1e35..02be1a152e 100644
--- a/src/scipp/compat/dict.py
+++ b/src/scipp/compat/dict.py
@@ -101,7 +101,7 @@ def _variable_to_dict(v: Variable) -> dict[str, Any]:
 
 def _data_array_to_dict(da: DataArray) -> dict[str, Any]:
     """Convert a Scipp DataArray to a python dict."""
-    out: dict[str, Any] = {"coords": {}, "masks": {}, "attrs": {}}
+    out: dict[str, Any] = {"coords": {}, "masks": {}}
     for key in out.keys():
         for name, item in getattr(da, key).items():
             out[key][str(name)] = _variable_to_dict(item)
@@ -195,7 +195,7 @@ def _dict_to_data_array(d: dict[str, Any]) -> DataArray:
             "To create a DataArray, the supplied dict must contain "
             f"'data'. Got {d.keys()}."
         )
-    meta: dict[str, dict[str, Variable]] = {"coords": {}, "masks": {}, "attrs": {}}
+    meta: dict[str, dict[str, Variable]] = {"coords": {}, "masks": {}}
     for key in meta.keys():
         if key in d:
             for name, item in d[key].items():
diff --git a/src/scipp/compat/wrapping.py b/src/scipp/compat/wrapping.py
index 1f4ab5b294..00a71f1ab4 100644
--- a/src/scipp/compat/wrapping.py
+++ b/src/scipp/compat/wrapping.py
@@ -111,16 +111,13 @@ def _postprocess(
         masks = _validated_masks(input_da, dim)
     if keep_coords:
         coords: Mapping[str, Variable] = input_da.coords
-        attrs: Mapping[str, Variable] = input_da.deprecated_attrs
     else:
         coords = _remove_columns_in_dim(input_da.coords, dim)
-        attrs = _remove_columns_in_dim(input_da.deprecated_attrs, dim)
 
     def add_observing_metadata(da: DataArray) -> DataArray:
         # operates in-place!
         da.coords.update(coords)
         da.masks.update((key, mask.copy()) for key, mask in masks.items())
-        da.deprecated_attrs.update(attrs)
         return da
 
     if is_partial:  # corresponds to `not isinstance(out_da, DataArray)`
diff --git a/src/scipp/compat/xarray_compat.py b/src/scipp/compat/xarray_compat.py
index 1c98deb32d..4b191362e9 100644
--- a/src/scipp/compat/xarray_compat.py
+++ b/src/scipp/compat/xarray_compat.py
@@ -141,7 +141,7 @@ def _to_xarray_dataarray(da: DataArray) -> xr.DataArray:
     out = xr.DataArray(_to_xarray_variable(da.data))
     for key, coord in da.coords.items():
         for dim in coord.dims:
-            if da.meta.is_edges(key, dim=dim):
+            if da.coords.is_edges(key, dim=dim):
                 raise ValueError("Xarray does not support coordinates with bin edges.")
         out.coords[key] = _to_xarray_variable(coord)
     out = out.drop_indexes(key for key, coord in da.coords.items() if not coord.aligned)
diff --git a/src/scipp/core/__init__.py b/src/scipp/core/__init__.py
index 6ff29ce9a9..1c7f994dd7 100644
--- a/src/scipp/core/__init__.py
+++ b/src/scipp/core/__init__.py
@@ -58,14 +58,6 @@
     _rename_dataset,
 )
 
-
-from .deprecation import _deprecated_attrs, _deprecated_meta, _deprecated_drop_attrs
-
-DataArray.attrs = property(_deprecated_attrs)  # type: ignore[assignment, method-assign]
-DataArray.meta = property(_deprecated_meta)  # type: ignore[assignment, method-assign]
-DataArray.drop_attrs = _deprecated_drop_attrs  # type: ignore[assignment, method-assign]
-del _deprecated_attrs, _deprecated_meta, _deprecated_drop_attrs
-
 for cls in (Variable, DataArray, Dataset):
     cls.rename_dims = _rename_dims  # type: ignore[method-assign]
 Variable.rename = _rename_variable  # type: ignore[method-assign]
@@ -191,13 +183,12 @@
 )
 from .like import zeros_like, ones_like, empty_like, full_like
 
-from .assignments import assign_coords, assign_masks, assign_attrs
+from .assignments import assign_coords, assign_masks
 
 Dataset.assign_coords = assign_coords  # type: ignore[method-assign]
 DataArray.assign_coords = assign_coords  # type: ignore[method-assign]
 DataArray.assign_masks = assign_masks  # type: ignore[method-assign]
-DataArray.assign_attrs = assign_attrs  # type: ignore[method-assign]
-del assign_coords, assign_masks, assign_attrs
+del assign_coords, assign_masks
 
 # Remove submodules to reduce clutter
 del (
diff --git a/src/scipp/core/assignments.py b/src/scipp/core/assignments.py
index 465f752480..6cf1af9a6f 100644
--- a/src/scipp/core/assignments.py
+++ b/src/scipp/core/assignments.py
@@ -13,7 +13,7 @@
 
 def _assign(
     obj: _T,
-    name: Literal['coords', 'masks', 'attrs'],
+    name: Literal['coords', 'masks'],
     obj_attrs: dict[str, Variable] | None = None,
     /,
     **kw_obj_attrs: Variable,
@@ -70,28 +70,3 @@ def assign_masks(
 
     """
     return _assign(self, 'masks', masks, **masks_kwargs)
-
-
-def assign_attrs(
-    self: DataArray,
-    attrs: dict[str, Variable] | None = None,
-    /,
-    **attrs_kwargs: Variable,
-) -> DataArray:
-    """Return new object with updated or inserted attrs.
-
-    Parameters
-    ----------
-    attrs :
-        New attrs.
-
-    attrs_kwargs :
-        Keyword arguments form of ``attrs``.
-
-    Returns
-    -------
-    :
-        ``scipp.DataArray`` with updated attributes.
-
-    """
-    return _assign(self, 'attrs', attrs, **attrs_kwargs)
diff --git a/src/scipp/core/binning.py b/src/scipp/core/binning.py
index 4f8c1914d4..bf7dd74677 100644
--- a/src/scipp/core/binning.py
+++ b/src/scipp/core/binning.py
@@ -301,8 +301,8 @@ def _get_coord(x: Variable | DataArray | Dataset, name: str) -> Variable:
             cmax = c.max() if cmax is None else max(cmin, c.max())  # type: ignore[call-overload]
         coord = concat([cmin, cmax], dim='dummy')  # type: ignore[type-var]
     else:
-        event_coord = x.bins.deprecated_meta.get(name) if x.bins is not None else None
-        coord = x.deprecated_meta.get(name, event_coord)
+        event_coord = x.bins.coords.get(name) if x.bins is not None else None
+        coord = x.coords.get(name, event_coord)
     _require_coord(name, coord)
     return coord  # type: ignore[return-value]
 
diff --git a/src/scipp/core/bins.py b/src/scipp/core/bins.py
index 7395efcbaa..7330591578 100644
--- a/src/scipp/core/bins.py
+++ b/src/scipp/core/bins.py
@@ -13,7 +13,6 @@
 from .bin_remapping import concat_bins
 from .cpp_classes import DataArray, Dataset, DType, Unit, Variable
 from .data_group import DataGroup
-from .deprecation import _warn_attr_removal
 from .domains import merge_equal_adjacent
 from .math import midpoints
 from .operations import islinspace
@@ -284,36 +283,6 @@ def drop_coords(self, coords: str | Sequence[str]) -> _O:
             raise NotImplementedError("bins.drop_coords does not support datasets")
         return self._map_constituents_data(lambda data: data.drop_coords(coords))
 
-    @property
-    def meta(self) -> MetaDataMap:
-        """Coords and attrs of the bins
-
-        .. deprecated:: 23.9.0
-           Use :py:attr:`coords` with unset alignment flag instead, or
-           store attributes in higher-level data structures.
-        """
-        _warn_attr_removal()
-        return self.deprecated_meta
-
-    @property
-    def attrs(self) -> MetaDataMap:
-        """Attrs of the bins
-
-        .. deprecated:: 23.9.0
-           Use :py:attr:`coords` with unset alignment flag instead, or
-           store attributes in higher-level data structures.
-        """
-        _warn_attr_removal()
-        return self.deprecated_attrs
-
-    @property
-    def deprecated_meta(self) -> MetaDataMap:
-        return _cpp._bins_view(self._data()).deprecated_meta  # type: ignore[no-any-return]
-
-    @property
-    def deprecated_attrs(self) -> MetaDataMap:
-        return _cpp._bins_view(self._data()).deprecated_attrs  # type: ignore[no-any-return]
-
     @property
     def masks(self) -> MetaDataMap:
         """Masks of the bins"""
diff --git a/src/scipp/core/concepts.py b/src/scipp/core/concepts.py
index c77028310e..5ca4e6bcbe 100644
--- a/src/scipp/core/concepts.py
+++ b/src/scipp/core/concepts.py
@@ -26,7 +26,6 @@ def rewrap_output_data(prototype: _VarOrDa, data: Variable) -> _VarOrDa:
         return DataArray(
             data=data,
             coords=prototype.coords,
-            attrs=prototype.deprecated_attrs,
             masks=_copied(prototype.masks),
         )
     else:
@@ -38,7 +37,6 @@ def rewrap_reduced_data(prototype: DataArray, data: Variable, dim: Dims) -> Data
         data,
         coords=reduced_coords(prototype, dim),
         masks=reduced_masks(prototype, dim),
-        attrs=reduced_attrs(prototype, dim),
     )
 
 
@@ -71,10 +69,6 @@ def reduced_coords(da: DataArray, dim: Dims) -> dict[str, Variable]:
     return _reduced(da.coords, concrete_dims(da, dim))
 
 
-def reduced_attrs(da: DataArray, dim: Dims) -> dict[str, Variable]:
-    return _reduced(da.deprecated_attrs, concrete_dims(da, dim))
-
-
 def reduced_masks(da: DataArray, dim: Dims) -> dict[str, Variable]:
     return _copied(_reduced(da.masks, concrete_dims(da, dim)))
 
diff --git a/src/scipp/core/cpp_classes.pyi b/src/scipp/core/cpp_classes.pyi
index 7ec971ce03..cadde0ddd3 100644
--- a/src/scipp/core/cpp_classes.pyi
+++ b/src/scipp/core/cpp_classes.pyi
@@ -222,7 +222,6 @@ class DataArray:
         data: Variable,
         coords: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {},
         masks: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {},
-        attrs: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {},
         name: str = '',
     ) -> None: ...
     def __invert__(self) -> DataArray: ...
@@ -330,9 +329,6 @@ class DataArray:
     def _repr_html_(self) -> str: ...
     def all(self, dim: str | None = None) -> DataArray: ...
     def any(self, dim: str | None = None) -> DataArray: ...
-    def assign_attrs(
-        self, attrs: dict[str, Variable] | None = None, /, **attrs_kwargs: Variable
-    ) -> DataArray: ...
     def assign_coords(
         self, coords: dict[str, Variable] | None = None, /, **coords_kwargs: Variable
     ) -> DataArray: ...
@@ -340,8 +336,6 @@ class DataArray:
         self, masks: dict[str, Variable] | None = None, /, **masks_kwargs: Variable
     ) -> DataArray: ...
     def astype(self, type: Any, *, copy: bool = True) -> DataArray: ...
-    @property
-    def attrs(self) -> Coords: ...
     def bin(
         self,
         arg_dict: dict[str, SupportsIndex | Variable] | None = None,
@@ -376,18 +370,9 @@ class DataArray:
     @data.setter
     def data(self, arg1: Variable) -> None: ...
     @property
-    def deprecated_attrs(self) -> Coords: ...
-    @overload
-    def deprecated_drop_attrs(self, arg0: str) -> DataArray: ...
-    @overload
-    def deprecated_drop_attrs(self, arg0: list[str]) -> DataArray: ...
-    @property
-    def deprecated_meta(self) -> Coords: ...
-    @property
     def dim(self) -> str: ...
     @property
     def dims(self) -> tuple[str, ...]: ...
-    def drop_attrs(self, *args: str | Sequence[str]) -> DataArray: ...
     def drop_coords(self, arg0: str | Sequence[str]) -> DataArray: ...
     def drop_masks(self, arg0: str | Sequence[str]) -> DataArray: ...
     @property
@@ -431,8 +416,6 @@ class DataArray:
     def max(self, dim: str | None = None) -> DataArray: ...
     def mean(self, dim: str | None = None) -> DataArray: ...
     def median(self, dim: Dims = None) -> DataArray: ...
-    @property
-    def meta(self) -> Coords: ...
     def min(self, dim: str | None = None) -> DataArray: ...
     @property
     def name(self) -> str: ...
@@ -688,8 +671,6 @@ class Dataset(Mapping[str, DataArray]):
     def max(self, dim: str | None = None) -> Dataset: ...
     def mean(self, dim: str | None = None) -> Dataset: ...
     def median(self, dim: Dims = None) -> Dataset: ...
-    @property
-    def meta(self) -> Coords: ...
     def min(self, dim: str | None = None) -> Dataset: ...
     def nanmax(self, dim: str | None = None) -> Dataset: ...
     def nanmean(self, dim: str | None = None) -> Dataset: ...
diff --git a/src/scipp/core/deprecation.py b/src/scipp/core/deprecation.py
deleted file mode 100644
index 5d3af8f97b..0000000000
--- a/src/scipp/core/deprecation.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import warnings
-
-from .cpp_classes import Coords, DataArray
-from .util import VisibleDeprecationWarning
-
-
-def _warn_attr_removal() -> None:
-    warnings.warn(
-        "sc.DataArray.attrs has been deprecated and will be removed in Scipp v24.12.0. "
-        "The deprecation includes sc.DataArray.meta and sc.DataArray.drop_attrs. "
-        "For unaligned coords, use sc.DataArray.coords and unset the alignment flag. "
-        "For other attributes, use a higher-level data structure.",
-        VisibleDeprecationWarning,
-        stacklevel=3,
-    )
-
-
-def _deprecated_attrs(cls: DataArray) -> Coords:
-    """
-    Dict of attrs.
-
-    .. deprecated:: 23.9.0
-       Use :py:attr:`coords` with unset alignment flag instead, or
-       store attributes in higher-level data structures.
-    """
-    _warn_attr_removal()
-    return cls.deprecated_attrs
-
-
-def _deprecated_meta(cls: DataArray) -> Coords:
-    """
-    Dict of coords and attrs.
-
-    .. deprecated:: 23.9.0
-       Use :py:attr:`coords` with unset alignment flag instead, or
-       store attributes in higher-level data structures.
-    """
-    _warn_attr_removal()
-    return cls.deprecated_meta
-
-
-def _deprecated_drop_attrs(cls: DataArray, *args: str) -> DataArray:
-    """
-    Drop attrs.
-
-    .. deprecated:: 23.9.0
-       Use :py:attr:`coords` with unset alignment flag instead, or
-       store attributes in higher-level data structures.
-    """
-    _warn_attr_removal()
-    return cls.deprecated_drop_attrs(*args)
diff --git a/src/scipp/core/dimensions.py b/src/scipp/core/dimensions.py
index 04fad3fc23..2a4ed53a11 100644
--- a/src/scipp/core/dimensions.py
+++ b/src/scipp/core/dimensions.py
@@ -116,18 +116,16 @@ def _rename_data_array(
     if out.bins is not None:
         out.data = bins(**out.bins.constituents)
     for old, new in renaming_dict.items():
-        if new in out.deprecated_meta:
+        if new in out.coords:
             raise CoordError(
-                f"Cannot rename '{old}' to '{new}', since a coord or attr named {new} "
+                f"Cannot rename '{old}' to '{new}', since a coord named {new} "
                 "already exists."
             )
-        for meta in (out.coords, out.deprecated_attrs):
-            if old in meta:
-                meta[new] = meta.pop(old)
+        if old in out.coords:
+            out.coords[new] = out.coords.pop(old)
         if out.bins is not None:
-            for meta in (out.bins.coords, out.bins.deprecated_attrs):
-                if old in meta:
-                    meta[new] = meta.pop(old)
+            if old in out.bins.coords:
+                out.bins.coords[new] = out.bins.coords.pop(old)
     return out
 
 
diff --git a/src/scipp/core/shape.py b/src/scipp/core/shape.py
index 11eb2812fb..03307af0ea 100644
--- a/src/scipp/core/shape.py
+++ b/src/scipp/core/shape.py
@@ -279,9 +279,9 @@ def flatten(
     If the input has a bin-edge coordinate that cannot be joined together it will not
     be included in the output.
 
-    If the input is a DataArray then coords, masks, and attrs that contain at least one
+    If the input is a DataArray then coords and masks that contain at least one
     of the flattened dimensions will also be flattened. This implies that when
-    flattening all dims, i.e., when ``dims=None``, all coords, masks, and attrs that
+    flattening all dims, i.e., when ``dims=None``, all coords and masks that
     share *some or all* dimensions with the data will be flattened.
 
     Parameters
diff --git a/src/scipp/core/util.py b/src/scipp/core/util.py
index 133a7f0531..8cfa45163a 100644
--- a/src/scipp/core/util.py
+++ b/src/scipp/core/util.py
@@ -29,14 +29,12 @@ def copy_for_overwrite(obj: _T) -> _T:
             copy_for_overwrite(obj.data),
             coords=_copy_dict_for_overwrite(obj.coords),
             masks=_copy_dict_for_overwrite(obj.masks),
-            attrs=_copy_dict_for_overwrite(obj.attrs),
         )
     ds = Dataset(coords=_copy_dict_for_overwrite(obj.coords))
     for name, da in obj.items():
         ds[name] = DataArray(
             copy_for_overwrite(da.data),
             masks=_copy_dict_for_overwrite(da.masks),
-            attrs=_copy_dict_for_overwrite(da.attrs),
         )
     return ds
 
diff --git a/src/scipp/io/hdf5.py b/src/scipp/io/hdf5.py
index 5883a89d06..9185972c8e 100644
--- a/src/scipp/io/hdf5.py
+++ b/src/scipp/io/hdf5.py
@@ -365,11 +365,11 @@ def write(group: h5.Group, data, override=None):
         group.attrs['name'] = data.name
         if _VariableIO.write(group.create_group('data'), var=data.data) is None:
             return None
-        views = [data.coords, data.masks, data.attrs]
+        views = [data.coords, data.masks]
         # Note that we write aligned and unaligned coords into the same group.
         # Distinction is via an attribute, which is more natural than having
         # 2 separate groups.
-        for view_name, view in zip(['coords', 'masks', 'attrs'], views, strict=True):
+        for view_name, view in zip(['coords', 'masks'], views, strict=True):
             subgroup = group.create_group(view_name)
             _write_mapping(subgroup, view, override.get(view_name))
         return group
@@ -382,7 +382,7 @@ def read(group: h5.Group, override=None):
         contents = {}
         contents['name'] = group.attrs['name']
         contents['data'] = _VariableIO.read(group['data'])
-        for category in ['coords', 'masks', 'attrs']:
+        for category in ['coords', 'masks']:
             contents[category] = _read_mapping(group[category], override.get(category))
         return DataArray(**contents)
 
diff --git a/src/scipp/testing/assertions.py b/src/scipp/testing/assertions.py
index 1cdc670bcb..efba39b040 100644
--- a/src/scipp/testing/assertions.py
+++ b/src/scipp/testing/assertions.py
@@ -21,7 +21,7 @@
 from ..core import DataArray, DataGroup, Dataset, Variable
 
 # Exception notes are formatted as 'PREPOSITION {loc}',
-# where 'loc' is set by the concrete assertion functions to indicate coords, attrs, etc.
+# where 'loc' is set by the concrete assertion functions to indicate coords and masks.
 # 'PREPOSITION' is replaced at the top level to produce exception messages like:
 #
 # [...]
@@ -164,7 +164,6 @@ def _assert_identical_variable_structure(a: Variable, b: Variable) -> None:
 
 def _assert_identical_data_array_structure(a: DataArray, b: DataArray) -> None:
     _assert_mapping_eq(a.coords, b.coords, 'coord')
-    _assert_mapping_eq(a.deprecated_attrs, b.deprecated_attrs, 'attr')
     _assert_mapping_eq(a.masks, b.masks, 'mask')
 
 
diff --git a/src/scipp/utils/comparison.py b/src/scipp/utils/comparison.py
index 77fd302cef..e803cd185f 100644
--- a/src/scipp/utils/comparison.py
+++ b/src/scipp/utils/comparison.py
@@ -13,7 +13,6 @@ def isnear(
     y: DataArray,
     rtol: Variable | None = None,
     atol: Variable | None = None,
-    include_attrs: bool = True,
     include_data: bool = True,
     equal_nan: bool = True,
 ) -> bool:
@@ -43,9 +42,6 @@ def isnear(
         absolute tolerance
     include_data:
         Compare data element-wise between x, and y
-    include_attrs:
-        Compare all meta (coords and attrs) between x and y,
-        otherwise only compare coordinates from meta
     equal_nan:
         If ``True``, consider NaNs or infs to be equal
         providing that they match in location and, for infs,
@@ -67,19 +63,15 @@ def isnear(
         if include_data
         else True
     )
-    same_len = (
-        len(x.deprecated_meta) == len(y.deprecated_meta)
-        if include_attrs
-        else len(x.coords) == len(y.coords)
-    )
+    same_len = len(x.coords) == len(y.coords)
     if not same_len:
         return False
-    for key, val in x.deprecated_meta.items() if include_attrs else x.coords.items():
-        a = x.deprecated_meta[key] if include_attrs else x.coords[key]
-        b = y.deprecated_meta[key] if include_attrs else y.coords[key]
+    for key, val in x.coords.items():
+        a = x.coords[key]
+        b = y.coords[key]
         if a.shape != b.shape:
             raise CoordError(
-                f'Coord (or attr) with key {key} have different'
+                f'Coords with key {key} have different'
                 f' shapes. For x, shape is {a.shape}. For y, shape = {b.shape}'
             )
         if val.dtype in [DType.float64, DType.float32]:
diff --git a/src/scipp/visualization/formatting_html.py b/src/scipp/visualization/formatting_html.py
index 2d164881de..da52f449f9 100644
--- a/src/scipp/visualization/formatting_html.py
+++ b/src/scipp/visualization/formatting_html.py
@@ -226,24 +226,6 @@ def summarize_masks(masks: Masks, ds: DataArray | Dataset | None = None) -> str:
     return f"<ul class='sc-var-list'>{vars_li}</ul>"
 
 
-def summarize_attrs(
-    attrs: Coords, embedded_in: DataArray | Dataset | None = None
-) -> str:
-    attrs_li = "".join(
-        "<li class='sc-var-item'>{}</li>".format(
-            summarize_variable(
-                name,
-                var,
-                has_attrs=False,
-                embedded_in=embedded_in,
-                is_aligned=False,
-            )
-        )
-        for name, var in _ordered_dict(attrs).items()
-    )
-    return f"<ul class='sc-var-list'>{attrs_li}</ul>"
-
-
 def _find_bin_edges(var: Variable | DataArray, ds: DataArray | Dataset) -> list[str]:
     """
     Checks if the coordinate contains bin-edges.
@@ -254,7 +236,7 @@ def _find_bin_edges(var: Variable | DataArray, ds: DataArray | Dataset) -> list[
 
 
 def _make_inline_attributes(
-    var: Variable | DataArray, has_attrs: bool, embedded_in: DataArray | Dataset | None
+    var: Variable | DataArray, has_attrs: bool
 ) -> tuple[str, str]:
     disabled = "disabled"
     attrs_ul = ""
@@ -265,11 +247,6 @@ def _make_inline_attributes(
             attrs_sections.append(mask_section(var.masks))
             disabled = ""
 
-    if has_attrs and hasattr(var, "deprecated_attrs"):
-        if len(var.deprecated_attrs) > 0:
-            attrs_sections.append(attr_section(var.deprecated_attrs, embedded_in))
-            disabled = ""
-
     if len(attrs_sections) > 0:
         attrs_sections_str = "".join(
             f"<li class='sc-section-item sc-subsection'>{s}</li>"
@@ -347,7 +324,7 @@ def summarize_variable(
     else:
         unit = 'ğŸ™' if var.unit == sc.units.dimensionless else str(var.unit)  # noqa: RUF001
 
-    disabled, attrs_ul = _make_inline_attributes(var, has_attrs, embedded_in)
+    disabled, attrs_ul = _make_inline_attributes(var, has_attrs)
 
     preview = _make_row(inline_variable_repr(var))
     data_repr = short_data_repr_html(var)
@@ -503,13 +480,6 @@ def variable_section(var: Variable) -> str:
     max_items_collapse=15,
 )
 
-attr_section = partial(
-    _mapping_section,
-    name="Attributes",
-    details_func=summarize_attrs,
-    max_items_collapse=10,
-)
-
 
 def _obj_repr(header_components: Iterable[str], sections: Iterable[str]) -> str:
     header = f"<div class='sc-header'>" f"{''.join(h for h in header_components)}</div>"
@@ -555,8 +525,6 @@ def data_array_dataset_repr(ds: DataArray | Dataset) -> str:
     if not isinstance(ds, Dataset):
         if len(ds.masks) > 0:
             sections.append(mask_section(ds.masks, ds))
-        if len(ds.deprecated_attrs) > 0:
-            sections.append(attr_section(ds.deprecated_attrs, ds))
 
     return _obj_repr(header_components, sections)
 
diff --git a/src/scipp/visualization/show.py b/src/scipp/visualization/show.py
index 7ad12085d1..e774381e33 100644
--- a/src/scipp/visualization/show.py
+++ b/src/scipp/visualization/show.py
@@ -135,7 +135,7 @@ def _events_height(self) -> float:
         elif isinstance(events, Dataset):
             raise ValueError("Cannot visualize Dataset events")
         else:
-            return 1 + 1.3 * (len(events.deprecated_meta) + len(events.masks))
+            return 1 + 1.3 * (len(events.coords) + len(events.masks))
 
     def size(self) -> tuple[float, float]:
         """Return the size (width and height) of the rendered output"""
@@ -406,7 +406,7 @@ def _dims(self) -> tuple[str, ...]:
         dims = self._dataset.dims
         if isinstance(self._dataset, DataArray):
             # Handle, e.g., bin edges of a slice, where data lacks the edge dim
-            for item in self._dataset.deprecated_meta.values():
+            for item in self._dataset.coords.values():
                 for dim in item.dims:
                     if dim not in dims:
                         dims = (dim, *dims)
@@ -471,8 +471,8 @@ def make_svg(self, content_only: bool = False) -> str:
         ds = self._dataset
         if isinstance(ds, DataArray):
             categories = zip(
-                ['coords', 'masks', 'attrs'],
-                [ds.coords, ds.masks, ds.deprecated_attrs],
+                ['coords', 'masks'],
+                [ds.coords, ds.masks],
                 strict=True,
             )
         else:
diff --git a/src/scipp/visualization/table.py b/src/scipp/visualization/table.py
index 2a29323724..6fa9ce1fee 100644
--- a/src/scipp/visualization/table.py
+++ b/src/scipp/visualization/table.py
@@ -98,17 +98,6 @@ def _make_data_array_table(
             )
         )
 
-    for name, var in sorted(da.deprecated_attrs.items()):
-        out.append(
-            _make_variable_column(
-                name=name,
-                var=var,
-                indices=indices,
-                need_bin_edge=bin_edges,
-                is_bin_edge=da.deprecated_attrs.is_edges(name),
-            )
-        )
-
     return out
 
 
@@ -117,7 +106,7 @@ def _make_entries_header(ds: Dataset) -> str:
     if ds.coords:
         out += f'<th colspan="{len(ds.coords)}"></th>'
     for name, da in sorted(ds.items()):
-        ncols = 1 + len(da.masks) + len(da.deprecated_attrs)
+        ncols = 1 + len(da.masks)
         out += f'<th style="{CENTER}" colspan="{ncols}">{name}</th>'
     out += '</tr>'
     return out
@@ -132,11 +121,6 @@ def _make_sections_header(ds: Dataset) -> str:
         out += f'<th style="{CENTER + border}">Data</th>'
         if da.masks:
             out += f'<th style="{CENTER}" colspan="{len(da.masks)}">Masks</th>'
-        if da.deprecated_attrs:
-            out += (
-                f'<th style="{CENTER}" '
-                f'colspan="{len(da.deprecated_attrs)}">Attributes</th>'
-            )
     out += '</tr>'
     return out
 
@@ -155,10 +139,6 @@ def _find_bin_edges(ds: Dataset) -> bool:
     for key in ds.coords:
         if ds.coords.is_edges(key):
             return True
-    for da in ds.values():
-        for key in da.deprecated_attrs:
-            if da.deprecated_attrs.is_edges(key):
-                return True
     return False
 
 
@@ -170,11 +150,6 @@ def _strip_scalars_and_broadcast_masks(ds: Dataset) -> Dataset:
             coords={
                 key: var for key, var in da.coords.items() if var.dims == da.data.dims
             },
-            attrs={
-                key: var
-                for key, var in da.deprecated_attrs.items()
-                if var.dims == da.data.dims
-            },
             masks={key: var.broadcast(sizes=da.sizes) for key, var in da.masks.items()},
         )
     return Dataset(out)
diff --git a/tests/bins_test.py b/tests/bins_test.py
index 5b79c7b12e..d4277c5624 100644
--- a/tests/bins_test.py
+++ b/tests/bins_test.py
@@ -72,33 +72,25 @@ def test_bins_works_with_int32_begin():
 
 def test_bins_constituents():
     var = sc.Variable(dims=['x'], values=[1, 2, 3, 4])
-    data = sc.DataArray(
-        data=var, coords={'coord': var}, masks={'mask': var}, attrs={'attr': var}
-    )
+    data = sc.DataArray(data=var, coords={'coord': var}, masks={'mask': var})
     begin = sc.Variable(dims=['y'], values=[0, 2], dtype=sc.DType.int64, unit=None)
     end = sc.Variable(dims=['y'], values=[2, 4], dtype=sc.DType.int64, unit=None)
     binned = sc.bins(begin=begin, end=end, dim='x', data=data)
     events = binned.bins.constituents['data']
     assert 'coord' in events.coords
     assert 'mask' in events.masks
-    assert 'attr' in events.attrs
     del events.coords['coord']
     del events.masks['mask']
-    del events.attrs['attr']
     # sc.bins makes a (shallow) copy of `data`
     assert 'coord' in data.coords
     assert 'mask' in data.masks
-    assert 'attr' in data.attrs
     # ... but when buffer is accessed we can insert/delete meta data
     assert 'coord' not in events.coords
     assert 'mask' not in events.masks
-    assert 'attr' not in events.attrs
     events.coords['coord'] = var
     events.masks['mask'] = var
-    events.attrs['attr'] = var
     assert 'coord' in events.coords
     assert 'mask' in events.masks
-    assert 'attr' in events.attrs
 
 
 def test_bins():
@@ -136,7 +128,6 @@ def make_binned():
     table = sc.DataArray(
         data=col,
         coords={'time': col * 2.2},
-        attrs={'attr': col * 3.3},
         masks={'mask': col == col},
     )
     begin = sc.Variable(dims=['y'], values=[0, 2], dtype=sc.DType.int64, unit=None)
@@ -147,9 +138,6 @@ def make_binned():
 def test_bins_view():
     var = make_binned()
     assert 'time' in var.bins.coords
-    assert 'time' in var.bins.meta
-    assert 'attr' in var.bins.meta
-    assert 'attr' in var.bins.attrs
     assert 'mask' in var.bins.masks
     col = sc.Variable(dims=['event'], values=[1, 2, 3, 4])
     with pytest.raises(sc.DTypeError):
diff --git a/tests/compat/dict_test.py b/tests/compat/dict_test.py
index b493b7adea..ec173c8180 100644
--- a/tests/compat/dict_test.py
+++ b/tests/compat/dict_test.py
@@ -203,7 +203,6 @@ def test_data_array_to_dict():
         masks={
             "amask": sc.Variable(dims=["y"], values=[True, True, False, True, False])
         },
-        attrs={"attr1": sc.Variable(dims=["x"], values=np.random.random(10))},
         data=sc.Variable(dims=["y", "x"], values=np.random.random([5, 10])),
     )
     da.coords.set_aligned("y", False)
@@ -218,7 +217,6 @@ def test_data_array_to_dict():
     assert sc.identical(sc.from_dict(da_dict["coords"]["y"]), da.coords["y"])
     assert not da_dict["coords"]["y"]["aligned"]
     assert sc.identical(sc.from_dict(da_dict["masks"]["amask"]), da.masks["amask"])
-    assert sc.identical(sc.from_dict(da_dict["attrs"]["attr1"]), da.attrs["attr1"])
 
 
 def test_data_array_from_dict():
@@ -228,7 +226,6 @@ def test_data_array_from_dict():
             "y": {"dims": ["y"], "values": np.arange(5), "unit": sc.units.m},
         },
         "masks": {"amask": {"dims": ["y"], "values": [True, True, False, True, False]}},
-        "attrs": {"attr1": {"dims": ["x"], "values": np.random.random(10)}},
         "data": {"dims": ["y", "x"], "values": np.random.random([5, 10])},
     }
     da = sc.from_dict(da_dict)
@@ -237,7 +234,6 @@ def test_data_array_from_dict():
     assert sc.identical(da.coords["y"], sc.from_dict(da_dict["coords"]["y"]))
     assert da.coords["y"].aligned
     assert sc.identical(da.masks["amask"], sc.from_dict(da_dict["masks"]["amask"]))
-    assert sc.identical(da.attrs["attr1"], sc.from_dict(da_dict["attrs"]["attr1"]))
     assert sc.identical(da.data, sc.from_dict(da_dict["data"]))
 
 
diff --git a/tests/compat/wrapping_test.py b/tests/compat/wrapping_test.py
index fa3e1c4fa7..a528376ebd 100644
--- a/tests/compat/wrapping_test.py
+++ b/tests/compat/wrapping_test.py
@@ -31,9 +31,6 @@ def make_array():
     mask = y.copy()
     mask.unit = ''
     da.masks['yy'] = mask < mask**2
-    da.deprecated_attrs['xx'] = x
-    da.deprecated_attrs['yy'] = y
-    da.deprecated_attrs['scalar'] = x[0]
     return da
 
 
@@ -44,8 +41,6 @@ def check_metadata(out, da, x):
     assert sc.identical(out.coords['yy'], da.coords['yy'])
     assert sc.identical(out.coords['scalar'], da.coords['scalar'])
     assert sc.identical(out.masks['yy'], da.masks['yy'])
-    assert sc.identical(out.attrs['yy'], da.attrs['yy'])
-    assert sc.identical(out.attrs['scalar'], da.attrs['scalar'])
     out.masks['yy'] ^= out.masks['yy']
     assert not sc.identical(out.masks['yy'], da.masks['yy'])
 
diff --git a/tests/compat/xarray_compat_test.py b/tests/compat/xarray_compat_test.py
index c4f2457bac..6c4c9de606 100644
--- a/tests/compat/xarray_compat_test.py
+++ b/tests/compat/xarray_compat_test.py
@@ -26,8 +26,6 @@ def test_from_xarray_empty_attrs_dataarray():
 
     sc_da = from_xarray(xr_da)
 
-    assert len(sc_da.attrs) == 0
-
     assert len(sc_da.dims) == 1
     assert "x" in sc_da.dims
 
@@ -46,9 +44,7 @@ def test_from_xarray_attrs_dataarray_warns_if_attrs_dropped():
     )
 
     with pytest.warns(UserWarning):
-        sc_da = from_xarray(xr_da)
-
-    assert len(sc_da.attrs) == 0
+        _ = from_xarray(xr_da)
 
 
 def test_from_xarray_converts_names_to_strings_in_dataarray():
diff --git a/tests/coords/transform_coords_test.py b/tests/coords/transform_coords_test.py
index 02b4bff764..20ca2cd9b9 100644
--- a/tests/coords/transform_coords_test.py
+++ b/tests/coords/transform_coords_test.py
@@ -550,10 +550,10 @@ def test_not_keep_inputs_binned(binned_in_a_b, keep_aliases, keep_intermediate):
         keep_inputs=False,
         keep_intermediate=keep_intermediate,
     )
-    assert 'a' not in da.meta
-    assert 'a' not in da.bins.meta
-    assert 'b' not in da.meta
-    assert 'b' not in da.bins.meta
+    assert 'a' not in da.coords
+    assert 'a' not in da.bins.coords
+    assert 'b' not in da.coords
+    assert 'b' not in da.bins.coords
 
     # Requesting input as target preserves it.
     da = binned_in_a_b.transform_coords(
@@ -565,8 +565,8 @@ def test_not_keep_inputs_binned(binned_in_a_b, keep_aliases, keep_intermediate):
     )
     assert 'a' in da.coords
     assert 'a' in da.bins.coords
-    assert 'b' not in da.meta
-    assert 'b' not in da.bins.meta
+    assert 'b' not in da.coords
+    assert 'b' not in da.bins.coords
 
 
 @pytest.mark.parametrize('keep_aliases', [True, False])
@@ -683,8 +683,8 @@ def test_binned_does_not_modify_inputs(binned_in_a_b):
     _ = binned_in_a_b.transform_coords(['b2'], graph={'b2': 'b'})
     assert 'b' in binned_in_a_b.coords
     assert 'b' in binned_in_a_b.bins.coords
-    assert 'b2' not in binned_in_a_b.meta
-    assert 'b2' not in binned_in_a_b.bins.meta
+    assert 'b2' not in binned_in_a_b.coords
+    assert 'b2' not in binned_in_a_b.bins.coords
 
 
 def test_binned_with_range_slice_does_not_modify_inputs(binned_in_a_b):
@@ -693,8 +693,8 @@ def test_binned_with_range_slice_does_not_modify_inputs(binned_in_a_b):
     _ = original.transform_coords(['b2'], graph={'b2': 'b'})
     assert 'b' in original.coords
     assert 'b' in original.bins.coords
-    assert 'b2' not in original.meta
-    assert 'b2' not in original.bins.meta
+    assert 'b2' not in original.coords
+    assert 'b2' not in original.bins.coords
 
 
 def test_binned_with_range_slice_does_not_modify_inputs_copy(binned_in_a_b):
@@ -704,8 +704,8 @@ def test_binned_with_range_slice_does_not_modify_inputs_copy(binned_in_a_b):
     _ = original.transform_coords(['b2'], graph={'b2': lambda b: b.copy()})
     assert 'b' in original.coords
     assert 'b' in original.bins.coords
-    assert 'b2' not in original.meta
-    assert 'b2' not in original.bins.meta
+    assert 'b2' not in original.coords
+    assert 'b2' not in original.bins.coords
 
 
 def test_binned_with_point_slice_does_not_modify_inputs(binned_in_a_b):
@@ -714,8 +714,8 @@ def test_binned_with_point_slice_does_not_modify_inputs(binned_in_a_b):
     _ = original.transform_coords(['b2'], graph={'b2': 'b'})
     assert 'b' in original.coords
     assert 'b' in original.bins.coords
-    assert 'b2' not in original.meta
-    assert 'b2' not in original.bins.meta
+    assert 'b2' not in original.coords
+    assert 'b2' not in original.bins.coords
 
 
 def test_binned_computes_correct_results(binned_in_a_b):
@@ -727,13 +727,16 @@ def convert(*, a2, b):
     renamed = binned_in_a_b.rename_dims({'a': 'a2'})
 
     # `a` was renamed to `a2`
-    assert sc.identical(converted.meta['a2'], renamed.meta['a'])
-    assert sc.identical(converted.bins.meta['a2'], renamed.bins.meta['a'])
+    assert sc.identical(converted.coords['a2'], renamed.coords['a'])
+    assert sc.identical(converted.bins.coords['a2'], renamed.bins.coords['a'])
 
     # `a*b` is indeed the product of `a` and `b`
-    assert sc.identical(converted.coords['a*b'], renamed.meta['a'] * renamed.meta['b'])
     assert sc.identical(
-        converted.bins.coords['a*b'], renamed.bins.meta['a'] * renamed.bins.meta['b']
+        converted.coords['a*b'], renamed.coords['a'] * renamed.coords['b']
+    )
+    assert sc.identical(
+        converted.bins.coords['a*b'],
+        renamed.bins.coords['a'] * renamed.bins.coords['b'],
     )
 
 
@@ -761,11 +764,12 @@ def convert(*, a, b2):
     renamed = binned_in_a_b.rename_dims({'b': 'b2'})
 
     # `b` was renamed to `b2`
-    assert sc.identical(converted.bins.meta['b2'], renamed.bins.meta['b'])
+    assert sc.identical(converted.bins.coords['b2'], renamed.bins.coords['b'])
 
     # `a*b` is indeed the product of `a` and `b`
     assert sc.identical(
-        converted.bins.coords['a*b'], renamed.bins.meta['a'] * renamed.bins.meta['b']
+        converted.bins.coords['a*b'],
+        renamed.bins.coords['a'] * renamed.bins.coords['b'],
     )
 
 
@@ -779,10 +783,12 @@ def convert(*, a, b2):
     renamed = binned_in_a_b.rename_dims({'b': 'b2'})
 
     # `b` was renamed to `b2`
-    assert sc.identical(converted.meta['b2'], renamed.meta['b'])
+    assert sc.identical(converted.coords['b2'], renamed.coords['b'])
 
     # `a*b` is indeed the product of `a` and `b`
-    assert sc.identical(converted.coords['a*b'], renamed.meta['a'] * renamed.meta['b'])
+    assert sc.identical(
+        converted.coords['a*b'], renamed.coords['a'] * renamed.coords['b']
+    )
 
 
 def make_binned():
@@ -822,7 +828,7 @@ def test_only_outputs_in_graph_are_stored(a):
     original = sc.DataArray(data=a, coords={'a': a})
     graph = {'b': split}
     da = original.transform_coords(['b'], graph=graph)
-    assert 'c' not in da.meta  # c is not stored
+    assert 'c' not in da.coords  # c is not stored
     with pytest.raises(KeyError):
         # c is not computable
         original.transform_coords(['c'], graph=graph)
@@ -975,16 +981,6 @@ def to_bd(*, a):
     assert 'b' in da.coords
 
 
-def test_does_not_use_attrs_as_inputs():
-    def f(x, a):
-        return x - a
-
-    da = sc.data.table_xyz(nrow=10)
-    da.attrs['a'] = sc.scalar(1)
-    with pytest.raises(KeyError):
-        da.transform_coords(['b'], graph={'b': f})
-
-
 def test_keyword_syntax_equivalent_to_explicit_syntax():
     da = sc.data.table_xyz(nrow=10)
 
diff --git a/tests/data_array_test.py b/tests/data_array_test.py
index bc4d106a28..535ce3cefa 100644
--- a/tests/data_array_test.py
+++ b/tests/data_array_test.py
@@ -17,7 +17,6 @@ def make_dataarray(dim1='x', dim2='y', seed=None):
             dim2: sc.Variable(dims=[dim2], values=np.arange(3.0), unit=sc.units.m),
             'aux': sc.Variable(dims=[dim2], values=np.random.rand(3)),
         },
-        attrs={'meta': sc.Variable(dims=[dim2], values=np.arange(3))},
     )
 
 
@@ -44,12 +43,9 @@ def test_init():
             'x': sc.Variable(dims=['x'], values=np.arange(3), unit=sc.units.m),
             'lib1': sc.Variable(dims=['x'], values=np.random.rand(3)),
         },
-        attrs={'met1': sc.Variable(dims=['x'], values=np.arange(3))},
         masks={'mask1': sc.Variable(dims=['x'], values=np.ones(3, dtype=bool))},
     )
-    assert len(d.meta) == 3
     assert len(d.coords) == 2
-    assert len(d.attrs) == 1
     assert len(d.masks) == 1
     assert d.ndim == 1
 
@@ -64,13 +60,11 @@ def test_init_from_variable_views():
     a = sc.DataArray(
         data=var,
         coords={'x': var},
-        attrs={'meta': var},
         masks={'mask1': sc.less(var, sc.scalar(3))},
     )
     b = sc.DataArray(
         data=a.data,
         coords={'x': a.coords['x']},
-        attrs={'meta': a.attrs['meta']},
         masks={'mask1': a.masks['mask1']},
     )
     assert sc.identical(a, b)
@@ -79,7 +73,6 @@ def test_init_from_variable_views():
     c = sc.DataArray(
         data=a.data,
         coords={'x': var},
-        attrs={'meta': a.attrs['meta']},
         masks={'mask1': a.masks['mask1']},
     )
 
@@ -93,21 +86,16 @@ def test_init_from_existing_metadata(coords_wrapper, attrs_wrapper, masks_wrappe
     da1 = sc.DataArray(
         sc.arange('x', 4),
         coords={'x': sc.arange('x', 5, unit='m'), 'y': sc.scalar(12.34)},
-        attrs={'a': sc.arange('x', 4, unit='s'), 'b': sc.scalar('attr-b')},
         masks={'m': sc.array(dims=['x'], values=[False, True, True, False, False])},
     )
     da2 = sc.DataArray(
         -sc.arange('x', 4),
         coords=coords_wrapper(da1.coords),
-        attrs=attrs_wrapper(da1.attrs),
         masks=masks_wrapper(da1.masks),
     )
     assert set(da2.coords.keys()) == {'x', 'y'}
     assert sc.identical(da2.coords['x'], da1.coords['x'])
     assert sc.identical(da2.coords['y'], da1.coords['y'])
-    assert set(da2.attrs.keys()) == {'a', 'b'}
-    assert sc.identical(da2.attrs['a'], da1.attrs['a'])
-    assert sc.identical(da2.attrs['b'], da1.attrs['b'])
     assert set(da2.masks.keys()) == {'m'}
     assert sc.identical(da2.masks['m'], da1.masks['m'])
 
@@ -116,7 +104,6 @@ def test_init_from_iterable_of_tuples():
     da = sc.DataArray(
         sc.arange('x', 4),
         coords=[('x', sc.arange('x', 5, unit='m')), ('y', sc.scalar(12.34))],
-        attrs=(('a', sc.arange('x', 4, unit='s')), ('b', sc.scalar('attr-b'))),
         masks={
             'm': sc.array(dims=['x'], values=[False, True, True, False, False])
         }.items(),
@@ -124,9 +111,6 @@ def test_init_from_iterable_of_tuples():
     assert set(da.coords.keys()) == {'x', 'y'}
     assert sc.identical(da.coords['x'], sc.arange('x', 5, unit='m'))
     assert sc.identical(da.coords['y'], sc.scalar(12.34))
-    assert set(da.attrs.keys()) == {'a', 'b'}
-    assert sc.identical(da.attrs['a'], sc.arange('x', 4, unit='s'))
-    assert sc.identical(da.attrs['b'], sc.scalar('attr-b'))
     assert set(da.masks.keys()) == {'m'}
     assert sc.identical(
         da.masks['m'], sc.array(dims=['x'], values=[False, True, True, False, False])
@@ -147,14 +131,10 @@ def test_builtin_len(make):
 
 def test_coords():
     da = make_dataarray()
-    assert len(dict(da.meta)) == len(da.meta) == 4
     assert len(dict(da.coords)) == len(da.coords) == 3
-    assert len(dict(da.attrs)) == len(da.attrs) == 1
     assert 'x' in da.coords
     assert 'y' in da.coords
     assert 'aux' in da.coords
-    assert 'meta' in da.meta
-    assert 'meta' in da.attrs
 
 
 def test_masks():
@@ -182,8 +162,6 @@ def test_ipython_key_completion():
     mask = sc.Variable(dims=['x'], values=np.array([False, True], dtype=bool))
     da.masks['mask1'] = mask
     assert set(da.coords._ipython_key_completions_()) == set(da.coords.keys())
-    assert set(da.attrs._ipython_key_completions_()) == set(da.attrs.keys())
-    assert set(da.meta._ipython_key_completions_()) == set(da.meta.keys())
     assert set(da.masks._ipython_key_completions_()) == set(da.masks.keys())
 
 
@@ -449,28 +427,6 @@ def test_drop_masks():
     assert 'mask2' in da.drop_masks(['mask0', 'mask1']).masks
 
 
-def test_drop_attrs():
-    data = sc.array(dims=['x', 'y', 'z'], values=np.random.rand(4, 3, 5))
-    attr0 = sc.scalar('attribute_0')
-    attr1 = sc.linspace('y', start=0.2, stop=1.61, num=4)
-    attr2 = sc.linspace('z', start=-10, stop=10, num=5)
-    da = sc.DataArray(data, attrs={'attr0': attr0, 'attr1': attr1, 'attr2': attr2})
-
-    assert 'attr0' not in da.drop_attrs('attr0').attrs
-    assert 'attr1' in da.drop_attrs('attr0').attrs
-    assert 'attr2' in da.drop_attrs(['attr0']).attrs
-    assert 'attr0' not in da.drop_attrs(['attr0', 'attr1']).attrs
-    assert 'attr1' not in da.drop_attrs(['attr0', 'attr1']).attrs
-    assert 'attr2' in da.drop_attrs(['attr0', 'attr1']).attrs
-
-
-def test_attrs_update_from_dict_adds_items():
-    da = sc.DataArray(sc.scalar(0.0), attrs={'a': sc.scalar(1.0)})
-    da.attrs.update({'b': sc.scalar(2.0)})
-    assert sc.identical(da.attrs['a'], sc.scalar(1.0))
-    assert sc.identical(da.attrs['b'], sc.scalar(2.0))
-
-
 def test_masks_update_from_dict_adds_items():
     da = sc.DataArray(sc.scalar(0.0), masks={'a': sc.scalar(True)})
     da.masks.update({'b': sc.scalar(False)})
@@ -575,79 +531,6 @@ def test_assign_update_masks():
     )
 
 
-def test_assign_attrs():
-    data = sc.array(dims=['x', 'y', 'z'], values=np.random.rand(4, 3, 5))
-    attr0 = sc.scalar('attribute_0')
-    attr1 = sc.linspace('y', start=0.2, stop=1.61, num=4)
-    da_o = sc.DataArray(data)
-    da_n = da_o.assign_attrs({'attr0': attr0, 'attr1': attr1})
-    assert sc.identical(da_o, sc.DataArray(data))
-    assert sc.identical(
-        da_n, sc.DataArray(data, attrs={'attr0': attr0, 'attr1': attr1})
-    )
-
-
-def test_assign_attrs_kwargs():
-    data = sc.array(dims=['x', 'y', 'z'], values=np.random.rand(4, 3, 5))
-    attr0 = sc.scalar('attribute_0')
-    attr1 = sc.linspace('y', start=0.2, stop=1.61, num=4)
-    da_o = sc.DataArray(data)
-    da_n = da_o.assign_attrs(attr0=attr0, attr1=attr1)
-    assert sc.identical(da_o, sc.DataArray(data))
-    assert sc.identical(
-        da_n, sc.DataArray(data, attrs={'attr0': attr0, 'attr1': attr1})
-    )
-
-
-def test_assign_attrs_overlapping_names():
-    data = sc.array(dims=['x', 'y', 'z'], values=np.random.rand(4, 3, 5))
-    attr0 = sc.scalar('attribute_0')
-    da = sc.DataArray(data)
-    with pytest.raises(ValueError, match='names .* distinct'):
-        da.assign_attrs({'attr0': attr0}, attr0=attr0)
-
-
-def test_assign_update_attrs():
-    data = sc.array(dims=['x', 'y', 'z'], values=np.random.rand(4, 3, 5))
-    attr0_o = sc.scalar('attribute_0')
-    attr1_o = sc.linspace('y', start=0.2, stop=1.61, num=4)
-    da_o = sc.DataArray(data, attrs={'attr0': attr0_o, 'attr1': attr1_o})
-
-    attr0_n = sc.scalar('attribute_new')
-    attr1_n = sc.linspace('y', start=-1.61, stop=0.2, num=4)
-    da_n = da_o.assign_attrs({"attr0": attr0_n, "attr1": attr1_n})
-    assert sc.identical(
-        da_o, sc.DataArray(data, attrs={'attr0': attr0_o, 'attr1': attr1_o})
-    )
-    assert sc.identical(
-        da_n, sc.DataArray(data, attrs={'attr0': attr0_n, 'attr1': attr1_n})
-    )
-
-
-def test_accessing_attrs_property_warns_about_deprecation():
-    da = sc.DataArray(sc.arange('x', 4))
-    with pytest.warns(sc.VisibleDeprecationWarning):
-        da.attrs
-
-
-def test_accessing_meta_property_warns_about_deprecation():
-    da = sc.DataArray(sc.arange('x', 4))
-    with pytest.warns(sc.VisibleDeprecationWarning):
-        da.meta
-
-
-def test_accessing_attrs_property_of_bins_warns_about_deprecation():
-    da = sc.data.binned_x(1, 1)
-    with pytest.warns(sc.VisibleDeprecationWarning):
-        da.bins.attrs
-
-
-def test_accessing_meta_property_of_bins_warns_about_deprecation():
-    da = sc.data.binned_x(1, 1)
-    with pytest.warns(sc.VisibleDeprecationWarning):
-        da.bins.meta
-
-
 def test_setting_binned_var_as_coord_or_mask_raises():
     da = sc.data.binned_x(1, 1)
     bad = da.bins.coords['x']
diff --git a/tests/dataset_test.py b/tests/dataset_test.py
index a1cbfd3b34..a2ab6b692e 100644
--- a/tests/dataset_test.py
+++ b/tests/dataset_test.py
@@ -641,14 +641,10 @@ def test_is_edges():
     da = sc.DataArray(
         sc.zeros(sizes={'a': 2, 'b': 3}),
         coords={'coord': sc.zeros(sizes={'a': 3})},
-        attrs={'attr': sc.zeros(sizes={'a': 2, 'b': 4})},
         masks={'mask': sc.zeros(sizes={'b': 3})},
     )
     assert da.coords.is_edges('coord')
     assert da.coords.is_edges('coord', 'a')
-    assert da.meta.is_edges('coord')
-    assert not da.attrs.is_edges('attr', 'a')
-    assert da.attrs.is_edges('attr', 'b')
     assert not da.masks.is_edges('mask', 'b')
 
 
diff --git a/tests/dicts_test.py b/tests/dicts_test.py
index 7b64080931..97f16d9ebf 100644
--- a/tests/dicts_test.py
+++ b/tests/dicts_test.py
@@ -19,7 +19,6 @@ def make_dataset(var, **kwargs):
     [
         (make_data_array, "coords"),
         (make_data_array, "masks"),
-        (make_data_array, "attrs"),
         (make_dataset, "coords"),
     ],
 ]
diff --git a/tests/io/hdf5_test.py b/tests/io/hdf5_test.py
index a0eae92f37..2bc9657ee7 100644
--- a/tests/io/hdf5_test.py
+++ b/tests/io/hdf5_test.py
@@ -65,7 +65,6 @@ def check_roundtrip(obj):
         'mask.1': sc.less(x, 1.5 * sc.units.m),
         'mask.2': sc.less(x, 2.5 * sc.units.m),
     },
-    attrs={'attr1': x, 'attr2': 1.2 * sc.units.K},
 )
 array_2d = sc.DataArray(
     data=xy,
@@ -74,7 +73,6 @@ def check_roundtrip(obj):
         'mask1': sc.less(x, 1.5 * sc.units.m),
         'mask2': sc.less(xy, 0.5 * sc.units.kg),
     },
-    attrs={'attr1': xy, 'attr2': 1.2 * sc.units.K},
 )
 
 
@@ -225,10 +223,6 @@ def test_data_array_unsupported_PyObject_coord():
     assert not sc.identical(a, b)
     del a.coords['obj']
     assert sc.identical(a, b)
-    a.attrs['obj'] = obj
-    assert not sc.identical(a, b)
-    del a.attrs['obj']
-    assert sc.identical(a, b)
 
 
 def test_data_array_coord_alignment():
diff --git a/tests/ownership_dataset_test.py b/tests/ownership_dataset_test.py
index 5d07ffc0da..6fcd235ebd 100644
--- a/tests/ownership_dataset_test.py
+++ b/tests/ownership_dataset_test.py
@@ -11,9 +11,8 @@
 def data_array_components():
     v = sc.array(dims=['x'], values=[10, 20], unit='m')
     c = sc.array(dims=['x'], values=[1, 2], unit='s')
-    a = sc.array(dims=['x'], values=[100, 200])
     m = sc.array(dims=['x'], values=[True, False])
-    return v, c, a, m
+    return v, c, m
 
 
 @pytest.fixture(
@@ -32,7 +31,7 @@ def coords_arg_wrapper(request):
     params=(
         lambda k, v: {k: v},
         lambda k, v: {k: v}.items(),
-        lambda k, v: sc.DataArray(v, attrs={k: v}).attrs,
+        lambda k, v: sc.DataArray(v, coords={k: v}).coords,
     ),
     ids=['dict', 'iterator', 'Coords'],
 )
@@ -46,7 +45,7 @@ def attrs_arg_wrapper(request):
         lambda k, v: {k: v}.items(),
         lambda k, v: sc.DataArray(v, masks={k: v}).masks,
     ),
-    ids=['dict', 'iterator', 'Coords'],
+    ids=['dict', 'iterator', 'Masks'],
 )
 def masks_arg_wrapper(request):
     return request.param
@@ -54,32 +53,29 @@ def masks_arg_wrapper(request):
 
 @pytest.fixture
 def data_array_and_components(coords_arg_wrapper, attrs_arg_wrapper, masks_arg_wrapper):
-    v, c, a, m = data_array_components()
+    v, c, m = data_array_components()
     da = sc.DataArray(
         v,
         coords=coords_arg_wrapper('x', c),
-        attrs=attrs_arg_wrapper('a', a),
         masks=masks_arg_wrapper('m', m),
     )
-    return da, v, c, a, m
+    return da, v, c, m
 
 
 def make_data_array():
-    v, c, a, m = data_array_components()
-    da = sc.DataArray(v, coords={'x': c}, attrs={'a': a}, masks={'m': m})
-    return da, v, c, a, m
+    v, c, m = data_array_components()
+    da = sc.DataArray(v, coords={'x': c}, masks={'m': m})
+    return da, v, c, m
 
 
 def test_own_darr_set(data_array_and_components):
     # Data and metadata are shared
-    da, v, c, a, m = data_array_and_components
+    da, v, c, m = data_array_and_components
     da['x', 0] = -10
     da.data['x', 1] = -20
     da.coords['x']['x', 0] = -1
-    da.attrs['a']['x', 0] = -100
     da.masks['m']['x', 0] = False
     c['x', 1] = -2
-    a['x', 1] = -200
     m['x', 1] = True
     da.unit = 'kg'
     da.coords['x'].unit = 'J'
@@ -88,26 +84,22 @@ def test_own_darr_set(data_array_and_components):
         sc.DataArray(
             sc.array(dims=['x'], values=[-10, -20], unit='kg'),
             coords={'x': sc.array(dims=['x'], values=[-1, -2], unit='J')},
-            attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
             masks={'m': sc.array(dims=['x'], values=[False, True])},
         ),
     )
     assert sc.identical(v, sc.array(dims=['x'], values=[-10, -20], unit='kg'))
     assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
     assert sc.identical(m, sc.array(dims=['x'], values=[False, True]))
 
     # Assignments overwrite data but not metadata.
     da.data = sc.array(dims=['x'], values=[11, 22], unit='m')
     da.coords['x'] = sc.array(dims=['x'], values=[3, 4], unit='s')
-    da.attrs['a'] = sc.array(dims=['x'], values=[300, 400])
     da.masks['m'] = sc.array(dims=['x'], values=[True, True])
     assert sc.identical(
         da,
         sc.DataArray(
             sc.array(dims=['x'], values=[11, 22], unit='m'),
             coords={'x': sc.array(dims=['x'], values=[3, 4], unit='s')},
-            attrs={'a': sc.array(dims=['x'], values=[300, 400])},
             masks={'m': sc.array(dims=['x'], values=[True, True])},
         ),
     )
@@ -115,7 +107,6 @@ def test_own_darr_set(data_array_and_components):
     assert not sc.identical(v, sc.array(dims=['x'], values=[11, 22], unit='m'))
     assert sc.identical(da.data, sc.array(dims=['x'], values=[11, 22], unit='m'))
     assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
     assert sc.identical(m, sc.array(dims=['x'], values=[False, True]))
 
 
@@ -124,15 +115,12 @@ def test_own_darr_get():
     da = make_data_array()[0]
     v = da.data
     c = da.coords['x']
-    a = da.attrs['a']
     m = da.masks['m']
     da['x', 0] = -10
     da.data['x', 1] = -20
     da.coords['x']['x', 0] = -1
-    da.attrs['a']['x', 0] = -100
     da.masks['m']['x', 0] = False
     c['x', 1] = -2
-    a['x', 1] = -200
     m['x', 1] = True
     da.unit = 'kg'
     da.coords['x'].unit = 'J'
@@ -141,26 +129,22 @@ def test_own_darr_get():
         sc.DataArray(
             sc.array(dims=['x'], values=[-10, -20], unit='kg'),
             coords={'x': sc.array(dims=['x'], values=[-1, -2], unit='J')},
-            attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
             masks={'m': sc.array(dims=['x'], values=[False, True])},
         ),
     )
     assert sc.identical(v, sc.array(dims=['x'], values=[-10, -20], unit='kg'))
     assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
     assert sc.identical(m, sc.array(dims=['x'], values=[False, True]))
 
     # Assignments overwrite data but not coords.
     da.data = sc.array(dims=['x'], values=[11, 22], unit='m')
     da.coords['x'] = sc.array(dims=['x'], values=[3, 4], unit='s')
-    da.attrs['a'] = sc.array(dims=['x'], values=[300, 400])
     da.masks['m'] = sc.array(dims=['x'], values=[True, True])
     assert sc.identical(
         da,
         sc.DataArray(
             sc.array(dims=['x'], values=[11, 22], unit='m'),
             coords={'x': sc.array(dims=['x'], values=[3, 4], unit='s')},
-            attrs={'a': sc.array(dims=['x'], values=[300, 400])},
             masks={'m': sc.array(dims=['x'], values=[True, True])},
         ),
     )
@@ -168,59 +152,12 @@ def test_own_darr_get():
     assert not sc.identical(v, sc.array(dims=['x'], values=[11, 22], unit='m'))
     assert sc.identical(da.data, sc.array(dims=['x'], values=[11, 22], unit='m'))
     assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
     assert sc.identical(m, sc.array(dims=['x'], values=[False, True]))
 
 
-def test_own_darr_get_meta():
-    # Data and metadata are shared.
-    da = make_data_array()[0]
-    del da.masks['m']  # not accessible through .meta and tested elsewhere
-    v = da.data
-    c = da.meta['x']
-    a = da.meta['a']
-    da['x', 0] = -10
-    da.data['x', 1] = -20
-    da.coords['x']['x', 0] = -1
-    da.attrs['a']['x', 0] = -100
-    c['x', 1] = -2
-    a['x', 1] = -200
-    da.unit = 'kg'
-    da.coords['x'].unit = 'J'
-    assert sc.identical(
-        da,
-        sc.DataArray(
-            sc.array(dims=['x'], values=[-10, -20], unit='kg'),
-            coords={'x': sc.array(dims=['x'], values=[-1, -2], unit='J')},
-            attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
-        ),
-    )
-    assert sc.identical(v, sc.array(dims=['x'], values=[-10, -20], unit='kg'))
-    assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
-
-    # Assignments overwrite data but not coords.
-    da.data = sc.array(dims=['x'], values=[11, 22], unit='m')
-    da.coords['x'] = sc.array(dims=['x'], values=[3, 4], unit='s')
-    da.attrs['a'] = sc.array(dims=['x'], values=[300, 400])
-    assert sc.identical(
-        da,
-        sc.DataArray(
-            sc.array(dims=['x'], values=[11, 22], unit='m'),
-            coords={'x': sc.array(dims=['x'], values=[3, 4], unit='s')},
-            attrs={'a': sc.array(dims=['x'], values=[300, 400])},
-        ),
-    )
-    # Assignment replaces data
-    assert not sc.identical(v, sc.array(dims=['x'], values=[11, 22], unit='m'))
-    assert sc.identical(da.data, sc.array(dims=['x'], values=[11, 22], unit='m'))
-    assert sc.identical(c, sc.array(dims=['x'], values=[-1, -2], unit='J'))
-    assert sc.identical(a, sc.array(dims=['x'], values=[-100, -200]))
-
-
 def test_own_darr_copy():
     # Depth of copy can be controlled.
-    da, _, c, a, m = make_data_array()
+    da, _, c, m = make_data_array()
     da_copy = copy(da)
     da_deepcopy = deepcopy(da)
     da_methcopy = da.copy(deep=False)
@@ -228,10 +165,8 @@ def test_own_darr_copy():
     da['x', 0] = -10
     da.data['x', 1] = -20
     da.coords['x']['x', 0] = -1
-    da.attrs['a']['x', 0] = -100
     da.masks['m']['x', 0] = False
     c['x', 1] = -2
-    a['x', 1] = -200
     m['x', 1] = True
     da.unit = 'kg'
     da.coords['x'].unit = 'J'
@@ -239,7 +174,6 @@ def test_own_darr_copy():
     modified = sc.DataArray(
         sc.array(dims=['x'], values=[-10, -20], unit='kg'),
         coords={'x': sc.array(dims=['x'], values=[-1, -2], unit='J')},
-        attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
         masks={'m': sc.array(dims=['x'], values=[False, True])},
     )
     assert sc.identical(da, modified)
@@ -259,18 +193,15 @@ def test_own_dset_init(data_array_wrapper):
     dset = sc.Dataset(data_array_wrapper('da1', da))
 
     dset['da1']['x', 0] = -10
-    dset['da1'].attrs['a']['x', 0] = -100
     dset['da1'].masks['m']['x', 0] = False
     da['x', 1] = -20
     da.coords['x']['x', 1] = -2
-    da.attrs['a']['x', 1] = -200
     da.masks['m']['x', 1] = True
     dset['da1'].unit = 'kg'
 
     expected = sc.DataArray(
         sc.array(dims=['x'], values=[-10, -20], unit='kg'),
         coords={'x': sc.array(dims=['x'], values=[1, -2], unit='s')},
-        attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
         masks={'m': sc.array(dims=['x'], values=[False, True])},
     )
     assert sc.identical(dset, sc.Dataset(data={'da1': expected}))
@@ -283,18 +214,15 @@ def test_own_dset_set_access_through_dataarray():
     dset = sc.Dataset({'da1': da})
 
     dset['da1']['x', 0] = -10
-    dset['da1'].attrs['a']['x', 0] = -100
     dset['da1'].masks['m']['x', 0] = False
     da['x', 1] = -20
     da.coords['x']['x', 1] = -2
-    da.attrs['a']['x', 1] = -200
     da.masks['m']['x', 1] = True
     dset['da1'].unit = 'kg'
 
     expected = sc.DataArray(
         sc.array(dims=['x'], values=[-10, -20], unit='kg'),
         coords={'x': sc.array(dims=['x'], values=[1, -2], unit='s')},
-        attrs={'a': sc.array(dims=['x'], values=[-100, -200])},
         masks={'m': sc.array(dims=['x'], values=[False, True])},
     )
     assert sc.identical(dset, sc.Dataset(data={'da1': expected}))
@@ -307,7 +235,6 @@ def test_own_dset_set_access_through_scalar_slice():
     dset = sc.Dataset({'da1': da})
 
     dset['x', 0]['da1'].value = -10
-    dset['x', 0]['da1'].attrs['a'].value = -100
     dset['x', 0]['da1'].masks['m'].value = False
     with pytest.raises(sc.VariableError):
         dset['x', 0]['da1'].coords['x'].value = -1
@@ -317,7 +244,6 @@ def test_own_dset_set_access_through_scalar_slice():
     expected = sc.DataArray(
         sc.array(dims=['x'], values=[-10, 20], unit='m'),
         coords={'x': sc.array(dims=['x'], values=[1, 2], unit='s')},
-        attrs={'a': sc.array(dims=['x'], values=[-100, 200])},
         masks={'m': sc.array(dims=['x'], values=[False, False])},
     )
     assert sc.identical(dset, sc.Dataset(data={'da1': expected}))
@@ -330,14 +256,12 @@ def test_own_dset_set_access_through_range_slice():
     dset = sc.Dataset({'da1': da})
 
     dset['x', :]['da1']['x', 0] = -10
-    dset['x', :]['da1'].attrs['a']['x', 0] = -100
     dset['x', :]['da1'].masks['m']['x', False] = False
     dset['x', :]['da1'].unit = 'kg'
 
     expected = sc.DataArray(
         sc.array(dims=['x'], values=[-10, 20], unit='kg'),
         coords={'x': sc.array(dims=['x'], values=[1, 2], unit='s')},
-        attrs={'a': sc.array(dims=['x'], values=[-100, 200])},
         masks={'m': sc.array(dims=['x'], values=[False, False])},
     )
     assert sc.identical(dset, sc.Dataset(data={'da1': expected}))
diff --git a/tests/readonly_test.py b/tests/readonly_test.py
index ec5c0d15aa..111f7d038b 100644
--- a/tests/readonly_test.py
+++ b/tests/readonly_test.py
@@ -65,7 +65,6 @@ def assert_readonly_data_array(da, readonly_data: bool):
         da.data = var  # slice is readonly
     assert_dict_readonly(da.coords)
     assert_dict_readonly(da.masks)
-    assert_dict_readonly(da.attrs)
     if readonly_data:
         assert_variable_readonly(da.data)
         assert_variable_readonly(da.copy(deep=False).data)
@@ -104,7 +103,6 @@ def _make_data_array():
         data=var.copy(),
         coords={'x': var.copy()},
         masks={'m': var.copy()},
-        attrs={'a': var.copy()},
     )
 
 
@@ -120,11 +118,9 @@ def test_readonly_metadata():
     da = _make_data_array()
     assert_dict_readonly(da['x', 1:2].coords)
     assert_dict_readonly(da['x', 1:2].masks)
-    assert_dict_readonly(da['x', 1:2].attrs)
     # Shallow copy makes dict writable
     assert_dict_writable(da['x', 1:2].copy(deep=False).coords)
     assert_dict_writable(da['x', 1:2].copy(deep=False).masks)
-    assert_dict_writable(da['x', 1:2].copy(deep=False).attrs)
 
 
 def test_readonly_metadata_broadcast_sets_readonly_flag():
@@ -132,15 +128,12 @@ def test_readonly_metadata_broadcast_sets_readonly_flag():
     da = sc.concat([da, da], 'y')
     assert_variable_readonly(da['y', 1].coords['x'])
     assert_variable_readonly(da['y', 1].masks['m'])
-    assert_variable_readonly(da['y', 1].attrs['a'])
     # Shallow copy makes dict writable but not the items (buffers)
     assert_variable_readonly(da['y', 1].copy(deep=False).coords['x'])
     assert_variable_readonly(da['y', 1].copy(deep=False).masks['m'])
-    assert_variable_readonly(da['y', 1].copy(deep=False).attrs['a'])
     # Deep copy copies buffers
     assert_variable_writable(da['y', 1].copy().coords['x'])
     assert_variable_writable(da['y', 1].copy().masks['m'])
-    assert_variable_writable(da['y', 1].copy().attrs['a'])
 
 
 def test_dataset_readonly_metadata_dicts():
@@ -148,7 +141,6 @@ def test_dataset_readonly_metadata_dicts():
     # Coords dicts are shared and thus readonly
     assert_dict_readonly(ds['a'].coords)
     assert_dict_writable(ds['a'].masks)
-    assert_dict_writable(ds['a'].attrs)
 
 
 def test_dataset_readonly_metadata_items():
@@ -156,7 +148,6 @@ def test_dataset_readonly_metadata_items():
     # Coords are shared and thus readonly
     assert_variable_readonly(ds['a'].coords['x'])
     assert_variable_writable(ds['a'].masks['m'])
-    assert_variable_writable(ds['a'].attrs['a'])
 
 
 def test_readonly_dataset_slice():
diff --git a/tests/rename_test.py b/tests/rename_test.py
index 0db4cc6de2..435f2fcb71 100644
--- a/tests/rename_test.py
+++ b/tests/rename_test.py
@@ -49,15 +49,6 @@ def test_rename_kwargs():
     assert sc.identical(renamed, make_dataarray('y', 'x'))
 
 
-def test_rename_with_attr():
-    da = make_dataarray('x', 'y')
-    da.attrs['y'] = da.coords.pop('y')
-    renamed = da.rename({'y': 'z'})
-    expected = make_dataarray('x', 'z')
-    expected.attrs['z'] = expected.coords.pop('z')
-    assert sc.identical(renamed, expected)
-
-
 def test_rename_fails_when_coord_already_exists():
     da = make_dataarray('x', 'y')
     da.coords['z'] = da.coords['x'].copy()
@@ -65,52 +56,31 @@ def test_rename_fails_when_coord_already_exists():
         da.rename({'x': 'z'})
 
 
-def test_rename_fails_when_attr_already_exists():
-    da = make_dataarray('x', 'y')
-    da.attrs['y'] = da.coords.pop('y')
-    da.attrs['z'] = da.attrs['y'].copy()
-    with pytest.raises(sc.CoordError):
-        da.rename({'y': 'z'})
-
-
-def test_rename_fails_when_attr_with_same_name_already_exists():
-    da = make_dataarray('x', 'y')
-    da.attrs['meta'] = sc.scalar(5)
-    with pytest.raises(sc.CoordError):
-        da.rename({'x': 'meta'})
-
-
 def test_rename_fails_when_coord_with_same_name_already_exists():
     da = make_dataarray('x', 'y')
-    da.attrs['aux'] = sc.scalar(5)
-    da.attrs['y'] = da.coords.pop('y')
+    da.coords['aux'] = sc.scalar(5)
+    da.coords['y'] = da.coords.pop('y')
     with pytest.raises(sc.CoordError):
         da.rename({'y': 'aux'})
 
 
-def test_rename_renames_bins_coords_and_attrs():
+def test_rename_renames_bins_coords():
     table = sc.data.table_xyz(10)
-    table.attrs['y'] = table.coords.pop('y')
     da = table.bin(x=2, y=2)
     renamed = da.rename(x='x2', y='y2')
     assert 'x' not in renamed.bins.coords
-    assert 'y' not in renamed.bins.attrs
     assert 'x2' in renamed.bins.coords
-    assert 'y2' in renamed.bins.attrs
 
 
-def test_rename_of_bins_coords_and_attrs_does_not_affect_input():
+def test_rename_of_bins_coords__does_not_affect_input():
     table = sc.data.table_xyz(10)
-    table.attrs['y'] = table.coords.pop('y')
     da = table.bin(x=2, y=2)
     _ = da.rename(x='x2', y='y2')
     assert 'x' in da.bins.coords
-    assert 'y' in da.bins.attrs
 
 
-def test_rename_raises_DimensionError_if_only_bins_coords_or_attrs():
+def test_rename_raises_DimensionError_if_only_bins_coords():
     table = sc.data.table_xyz(10)
-    table.attrs['z'] = table.coords.pop('z')
     da = table.bin(x=2)
     with pytest.raises(sc.DimensionError):
         da.rename(y='y2', z='z2')
diff --git a/tests/repr_test.py b/tests/repr_test.py
index 7378c7e353..015ae67eda 100644
--- a/tests/repr_test.py
+++ b/tests/repr_test.py
@@ -6,10 +6,9 @@
 import scipp as sc
 
 
-@pytest.mark.parametrize("mapping", ["coords", "attrs", "meta", "masks"])
+@pytest.mark.parametrize("mapping", ["coords", "masks"])
 def test_data_array_mapping_repr_does_not_raise(mapping):
     da = sc.data.table_xyz(10)
-    da.attrs['a'] = da.coords['x']
     da.masks['m'] = da.coords['x'] > sc.scalar(0.5, unit='m')
     repr(getattr(da, mapping))
     repr(getattr(da, mapping).keys())
@@ -17,7 +16,7 @@ def test_data_array_mapping_repr_does_not_raise(mapping):
     repr(getattr(da, mapping).items())
 
 
-@pytest.mark.parametrize("mapping", ["coords", "attrs", "meta", "masks"])
+@pytest.mark.parametrize("mapping", ["coords", "masks"])
 def test_data_array_empty_mapping_repr_does_not_raise(mapping):
     da = sc.DataArray(data=sc.arange('x', 10))
     repr(getattr(da, mapping))
@@ -74,10 +73,9 @@ def test_data_group_repr_includes_items():
     assert idx1 < idx2
 
 
-@pytest.mark.parametrize("mapping", ["coords", "attrs", "meta", "masks"])
+@pytest.mark.parametrize("mapping", ["coords", "masks"])
 def test_data_array_mapping_str_does_not_raise(mapping):
     da = sc.data.table_xyz(10)
-    da.attrs['a'] = da.coords['x']
     da.masks['m'] = da.coords['x'] > sc.scalar(0.5, unit='m')
     str(getattr(da, mapping))
     str(getattr(da, mapping).keys())
@@ -85,7 +83,7 @@ def test_data_array_mapping_str_does_not_raise(mapping):
     str(getattr(da, mapping).items())
 
 
-@pytest.mark.parametrize("mapping", ["coords", "attrs", "meta", "masks"])
+@pytest.mark.parametrize("mapping", ["coords", "masks"])
 def test_data_array_empty_mapping_str_does_not_raise(mapping):
     da = sc.DataArray(data=sc.arange('x', 10))
     str(getattr(da, mapping))
diff --git a/tests/scipy/ndimage/footprint_filter_test.py b/tests/scipy/ndimage/footprint_filter_test.py
index 6bdd685818..6bc4945609 100644
--- a/tests/scipy/ndimage/footprint_filter_test.py
+++ b/tests/scipy/ndimage/footprint_filter_test.py
@@ -213,14 +213,6 @@ def test_size_is_equivalent_to_scipy_size(size):
     assert sc.identical(result, reference)
 
 
-def test_attributes_are_propagated(simple_filter_func):
-    da = make_histogram2d()
-    da.attrs['attr'] = sc.scalar(1.2)
-    result = simple_filter_func(da, size=2)
-    assert set(result.attrs) == {'attr'}
-    assert sc.identical(result.attrs['attr'], da.attrs['attr'])
-
-
 def test_coordinates_are_propagated(simple_filter_func):
     da = make_histogram2d()
     result = simple_filter_func(da, size=2)
diff --git a/tests/scipy/ndimage/gaussian_filter_test.py b/tests/scipy/ndimage/gaussian_filter_test.py
index e770e8022c..f687f56c5d 100644
--- a/tests/scipy/ndimage/gaussian_filter_test.py
+++ b/tests/scipy/ndimage/gaussian_filter_test.py
@@ -143,14 +143,6 @@ def test_sigma_is_equivalent_to_scipy_sigma(sigma):
     assert sc.identical(result, reference)
 
 
-def test_attributes_are_propagated():
-    da = make_histogram2d()
-    da.attrs['attr'] = sc.scalar(1.2)
-    result = gaussian_filter(da, sigma=3.4)
-    assert set(result.attrs) == {'attr'}
-    assert sc.identical(result.attrs['attr'], da.attrs['attr'])
-
-
 def test_coordinates_are_propagated():
     da = make_histogram2d()
     result = gaussian_filter(da, sigma=3.4)
diff --git a/tests/scipy/signal/sosfiltfilt_test.py b/tests/scipy/signal/sosfiltfilt_test.py
index 2d7316b79c..c38d4d42a6 100644
--- a/tests/scipy/signal/sosfiltfilt_test.py
+++ b/tests/scipy/signal/sosfiltfilt_test.py
@@ -62,12 +62,10 @@ def test_output_properties_match_input_properties():
     dim = da.dim
     da = sc.concat([da, da + da], 'extra_dim')
     da.coords['extra_dim'] = sc.array(dims=['new_dim'], values=[1, 2])
-    da.attrs['attr'] = sc.scalar(1)
     sos = butter(da.coords[dim], N=4, Wn=4 / da.coords[dim].unit)
     out = sosfiltfilt(da, dim, sos=sos)
     assert out.dims == da.dims
     assert out.unit == da.unit
-    assert out.attrs == da.attrs
     assert out.coords == da.coords
 
 
diff --git a/tests/shape_test.py b/tests/shape_test.py
index c33f5d1999..b5e9996233 100644
--- a/tests/shape_test.py
+++ b/tests/shape_test.py
@@ -24,13 +24,11 @@ def test_broadcast_data_array():
     N = 6
     d = sc.linspace('x', 2.0, 10.0, N)
     x = sc.arange('x', float(N))
-    a = sc.arange('x', float(N)) + 3.0
     m = x < 3.0
-    da = sc.DataArray(d, coords={'x': x}, attrs={'a': a}, masks={'m': m})
+    da = sc.DataArray(d, coords={'x': x}, masks={'m': m})
     expected = sc.DataArray(
         sc.broadcast(d, sizes={'x': 6, 'y': 3}),
         coords={'x': x},
-        attrs={'a': a},
         masks={'m': m},
     )
     assert sc.identical(sc.broadcast(da, sizes={'x': 6, 'y': 3}), expected)
diff --git a/tests/slice_bins_test.py b/tests/slice_bins_test.py
index f2eb4434a1..48f2d4cd27 100644
--- a/tests/slice_bins_test.py
+++ b/tests/slice_bins_test.py
@@ -76,12 +76,12 @@ def test_slice_bins_by_half_open_float_range_splits_without_duplication():
     right = da.bins['z', split:]
     assert left.bins.size().sum().value + right.bins.size().sum().value == 100
     assert sc.identical(
-        left.meta['z'], sc.concat([da.bins.meta['z'].min(), split], 'z')
+        left.coords['z'], sc.concat([da.bins.coords['z'].min(), split], 'z')
     )
     import numpy as np
 
-    expected_stop = np.nextafter(da.bins.meta['z'].max().value, np.inf) * sc.Unit('m')
-    assert sc.identical(right.meta['z'], sc.concat([split, expected_stop], 'z'))
+    expected_stop = np.nextafter(da.bins.coords['z'].max().value, np.inf) * sc.Unit('m')
+    assert sc.identical(right.coords['z'], sc.concat([split, expected_stop], 'z'))
 
 
 def test_slice_bins_by_half_open_int_range_splits_without_duplication():
@@ -93,10 +93,12 @@ def test_slice_bins_by_half_open_int_range_splits_without_duplication():
     right = da.bins['param', split:]
     assert left.bins.size().sum().value + right.bins.size().sum().value == 100
     assert sc.identical(
-        left.meta['param'], sc.concat([da.bins.meta['param'].min(), split], 'param')
+        left.coords['param'], sc.concat([da.bins.coords['param'].min(), split], 'param')
+    )
+    expected_stop = da.bins.coords['param'].max() + 1 * sc.Unit('s')
+    assert sc.identical(
+        right.coords['param'], sc.concat([split, expected_stop], 'param')
     )
-    expected_stop = da.bins.meta['param'].max() + 1 * sc.Unit('s')
-    assert sc.identical(right.meta['param'], sc.concat([split, expected_stop], 'param'))
 
 
 def test_slice_bins_with_step_raises():
@@ -121,18 +123,20 @@ def test_slice_bins_with_int_index_raises():
 def test_bins_slicing_open_start_too_small_stop_given():
     table = sc.data.table_xyz(nrow=100)
     da = table.bin(x=7)
-    too_small_stop = da.bins.meta['x'].min() - 0.001 * sc.Unit('m')
+    too_small_stop = da.bins.coords['x'].min() - 0.001 * sc.Unit('m')
     left = da.bins['x', :too_small_stop]
     assert left.bins.size().sum().value == 0
     assert sc.identical(
-        left.meta['x'], sc.concat([too_small_stop, too_small_stop], 'x')
+        left.coords['x'], sc.concat([too_small_stop, too_small_stop], 'x')
     )
 
 
 def test_bins_slicing_open_stop_too_big_stop_given():
     table = sc.data.table_xyz(nrow=100)
     da = table.bin(x=7)
-    too_big_start = da.bins.meta['x'].max() + 0.001 * sc.Unit('m')
+    too_big_start = da.bins.coords['x'].max() + 0.001 * sc.Unit('m')
     right = da.bins['x', too_big_start:]
     assert right.bins.size().sum().value == 0
-    assert sc.identical(right.meta['x'], sc.concat([too_big_start, too_big_start], 'x'))
+    assert sc.identical(
+        right.coords['x'], sc.concat([too_big_start, too_big_start], 'x')
+    )
diff --git a/tests/slice_by_index_list_test.py b/tests/slice_by_index_list_test.py
index 8811175e8e..6066c97783 100644
--- a/tests/slice_by_index_list_test.py
+++ b/tests/slice_by_index_list_test.py
@@ -84,7 +84,7 @@ def test_reversing_twice_gives_original(sliceable):
 
 
 @pytest.mark.parametrize("sliceable", [make_array(), make_dataset()])
-@pytest.mark.parametrize("what", ["coords", "masks", "attrs"])
+@pytest.mark.parametrize("what", ["coords", "masks"])
 def test_bin_edges_are_dropped(sliceable, what):
     sliceable = sliceable.copy()
     base = sliceable.copy()
diff --git a/tests/testing/assertions_test.py b/tests/testing/assertions_test.py
index 3dcc578e57..bf4356bacb 100644
--- a/tests/testing/assertions_test.py
+++ b/tests/testing/assertions_test.py
@@ -173,15 +173,10 @@ def test_assert_similar_variable_presence_of_variances(
     [
         sc.DataArray(sc.scalar(91, unit='F')),
         sc.DataArray(sc.scalar(6.4), coords={'g': sc.scalar(4)}),
-        sc.DataArray(sc.scalar(6.4), attrs={'rat': sc.scalar(0.01)}),
         sc.DataArray(sc.scalar(6.4), masks={'m': sc.scalar(False)}),
         sc.DataArray(
             sc.arange('y', 6.1, unit='mm'),
             coords={'y': sc.arange('y', 6.1, unit='s') * 3, 'e': sc.arange('y', 8)},
-            attrs={
-                'w': sc.scalar('wws'),
-                'qkk': sc.array(dims=['t'], values=[1.0, 2.0], variances=[0.0, 0.1]),
-            },
             masks={'1': sc.arange('y', 7) < 4},
         ),
     ],
@@ -265,44 +260,6 @@ def test_assert_similar_data_array_extra_coord(
         assert_similar(b, a)
 
 
-@pytest_mark_parameterize_assert_similar
-def test_assert_similar_data_array_attrs_key_mismatch(
-    assert_similar,
-):
-    a = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(33)})
-    b = sc.DataArray(sc.scalar(-8), attrs={'n': sc.scalar(33)})
-    with pytest.raises(AssertionError):
-        assert_similar(a, b)
-    with pytest.raises(AssertionError):
-        assert_similar(b, a)
-
-    a = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(33)})
-    b = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(33), 't': sc.scalar(3)})
-    with pytest.raises(AssertionError):
-        assert_similar(a, b)
-    with pytest.raises(AssertionError):
-        assert_similar(b, a)
-
-
-@pytest_mark_parameterize_assert_similar
-def test_assert_similar_data_array_attrs_value_mismatch(
-    assert_similar,
-):
-    a = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(82.0)})
-    b = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(82)})
-    with pytest.raises(AssertionError):
-        assert_similar(a, b)
-    with pytest.raises(AssertionError):
-        assert_similar(b, a)
-
-    a = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(33), 't': sc.scalar('yrr')})
-    b = sc.DataArray(sc.scalar(-8), attrs={'a': sc.scalar(33), 't': sc.scalar('yra')})
-    with pytest.raises(AssertionError):
-        assert_similar(a, b)
-    with pytest.raises(AssertionError):
-        assert_similar(b, a)
-
-
 @pytest_mark_parameterize_assert_similar
 def test_assert_similar_data_array_masks_key_mismatch(
     assert_similar,
@@ -351,7 +308,6 @@ def test_assert_similar_data_array_masks_value_mismatch(
             {
                 'yy': sc.DataArray(
                     sc.arange('w', 15).fold('w', sizes={'i': 3, 'yy': 5}),
-                    attrs={'a': sc.scalar([2, 3])},
                     masks={'m': sc.arange('yy', 5) < 2},
                 ),
             },
diff --git a/tests/utils/utils_comparison_test.py b/tests/utils/utils_comparison_test.py
index 550304cd1d..c93cb8af00 100644
--- a/tests/utils/utils_comparison_test.py
+++ b/tests/utils/utils_comparison_test.py
@@ -5,35 +5,29 @@
 import scipp.utils as su
 
 
-def test_wont_match_when_meta_size_unequal():
+def test_wont_match_when_coord_size_unequal():
     point = sc.scalar(value=1.0)
-    a = sc.DataArray(data=point, attrs={'x': point})
+    a = sc.DataArray(data=point, coords={'x': point})
     b = sc.DataArray(data=point)
     assert not su.isnear(a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one)
-    # ignore attributes, should give the same result
-    assert su.isnear(
-        a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one, include_attrs=False
-    )
 
 
-def test_wont_match_when_meta_keys_unequal():
+def test_wont_match_when_coord_keys_unequal():
     point = sc.scalar(value=1.0)
-    a = sc.DataArray(data=point, attrs={'x': point})
-    b = sc.DataArray(data=point, attrs={'y': point})
+    a = sc.DataArray(data=point, coords={'x': point})
+    b = sc.DataArray(data=point, coords={'y': point})
     with pytest.raises(KeyError):
         su.isnear(a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one)
-    # Raise nothing if we are ignoring differing parts
-    su.isnear(a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one, include_attrs=False)
 
 
-def test_wont_match_when_meta_sizes_unequal():
+def test_wont_match_when_coord_sizes_unequal():
     point = sc.scalar(value=1.0)
-    a = sc.DataArray(data=point, attrs={'x': point})
-    b = sc.DataArray(data=point, attrs={'x': sc.array(dims=['x'], values=np.arange(2))})
+    a = sc.DataArray(data=point, coords={'x': point})
+    b = sc.DataArray(
+        data=point, coords={'x': sc.array(dims=['x'], values=np.arange(2))}
+    )
     with pytest.raises(sc.CoordError):
         su.isnear(a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one)
-    # Raise nothing if we are ignoring differing parts
-    su.isnear(a, b, rtol=0 * sc.units.one, atol=1.0 * sc.units.one, include_attrs=False)
 
 
 def test_data_scalar_no_coords():
@@ -70,17 +64,3 @@ def test_with_many_coords():
     assert su.isnear(a, a, rtol=0.0 * sc.units.one, atol=1e-14 * sc.units.one)
     assert su.isnear(a, b, rtol=0.0 * sc.units.one, atol=1.0 * sc.units.one)
     assert not su.isnear(a, b, rtol=0.0 * sc.units.one, atol=0.9999 * sc.units.one)
-
-
-def test_with_many_coords_and_attrs():
-    x = sc.array(dims=['x'], values=np.arange(10.0))
-    xx = sc.array(dims=['x'], values=np.arange(1, 11.0))
-    a = sc.DataArray(data=x, coords={'a': x, 'b': x}, attrs={'c': x, 'd': x})
-    b = sc.DataArray(data=x, coords={'a': x, 'b': x}, attrs={'c': x, 'd': xx})
-    assert su.isnear(a, a, rtol=0.0 * sc.units.one, atol=1e-14 * sc.units.one)
-    assert su.isnear(a, b, rtol=0.0 * sc.units.one, atol=1.0 * sc.units.one)
-    assert not su.isnear(a, b, rtol=0.0 * sc.units.one, atol=0.9999 * sc.units.one)
-    # Now disable attrs matching (should be near)
-    assert su.isnear(
-        a, b, rtol=0.0 * sc.units.one, atol=0.9999 * sc.units.one, include_attrs=False
-    )

From 4191748bd772b508ac59318139b6c0937ec1006b Mon Sep 17 00:00:00 2001
From: Jan-Lukas Wynen <jan-lukas.wynen@ess.eu>
Date: Fri, 20 Dec 2024 11:51:02 +0100
Subject: [PATCH 2/7] Reove attrs from C++

---
 lib/dataset/astype.cpp                        |   2 +-
 lib/dataset/bin.cpp                           |  46 +++---
 lib/dataset/bins.cpp                          |  26 ++--
 lib/dataset/data_array.cpp                    |  47 +-----
 lib/dataset/dataset.cpp                       |  36 ++---
 lib/dataset/dataset_operations_common.h       |  19 +--
 lib/dataset/extract.cpp                       |   6 +-
 lib/dataset/groupby.cpp                       |  11 +-
 lib/dataset/include/scipp/dataset/bin.h       |   4 +-
 lib/dataset/include/scipp/dataset/bins_view.h |   7 -
 .../include/scipp/dataset/data_array.h        |  20 +--
 lib/dataset/include/scipp/dataset/dataset.h   |  27 +---
 .../include/scipp/dataset/dataset_util.h      |   1 -
 .../include/scipp/dataset/sized_dict.h        |   2 -
 .../scipp/dataset/sized_dict_forward.h        |   2 -
 lib/dataset/operations.cpp                    |  41 ++----
 lib/dataset/shape.cpp                         |   9 +-
 lib/dataset/sized_dict.cpp                    |   8 +-
 lib/dataset/sort.cpp                          |   2 +-
 lib/dataset/string.cpp                        |   5 -
 lib/dataset/test/CMakeLists.txt               |   1 -
 lib/dataset/test/attributes_test.cpp          | 138 ------------------
 lib/dataset/test/bin_test.cpp                 |  74 ----------
 lib/dataset/test/binned_arithmetic_test.cpp   |   3 +-
 lib/dataset/test/binned_creation_test.cpp     |   4 +-
 lib/dataset/test/bins_test.cpp                |  10 +-
 lib/dataset/test/bins_view_test.cpp           |   4 -
 lib/dataset/test/concat_test.cpp              |  29 ----
 lib/dataset/test/copy_test.cpp                |  57 +-------
 .../test/data_array_comparison_test.cpp       |  39 -----
 lib/dataset/test/data_array_test.cpp          |  99 ++-----------
 lib/dataset/test/dataset_arithmetic_test.cpp  |   2 +-
 lib/dataset/test/dataset_test.cpp             |  49 -------
 lib/dataset/test/equals_nan_test.cpp          |  17 +--
 lib/dataset/test/generated_test.cpp           |  14 --
 lib/dataset/test/groupby_test.cpp             |  33 +----
 lib/dataset/test/histogram_test.cpp           |   2 +-
 lib/dataset/test/merge_test.cpp               |   8 -
 lib/dataset/test/shape_test.cpp               |  72 ---------
 lib/dataset/test/size_of_test.cpp             |   7 +-
 lib/dataset/test/test_data_arrays.cpp         |   3 -
 lib/dataset/test/test_data_arrays.h           |   2 +-
 lib/dataset/test/to_unit_test.cpp             |  14 +-
 lib/dataset/to_unit.cpp                       |   2 +-
 lib/dataset/util.cpp                          |  15 +-
 .../variable_instantiate_bin_elements.cpp     |   4 +-
 lib/python/bind_data_array.h                  |  19 ---
 lib/python/bins.cpp                           |   4 -
 lib/python/dataset.cpp                        |  23 +--
 lib/templates/dataset_binary.cpp.in           |   8 +-
 lib/templates/dataset_unary.cpp.in            |   2 +-
 51 files changed, 134 insertions(+), 945 deletions(-)
 delete mode 100644 lib/dataset/test/attributes_test.cpp

diff --git a/lib/dataset/astype.cpp b/lib/dataset/astype.cpp
index efe0e8eabc..5c94aaea67 100644
--- a/lib/dataset/astype.cpp
+++ b/lib/dataset/astype.cpp
@@ -15,6 +15,6 @@ DataArray astype(const DataArray &array, const DType type,
                        ? array.masks()
                        : dataset::copy(array.masks());
   return DataArray(std::move(new_data), array.coords(), std::move(new_masks),
-                   array.attrs(), array.name());
+                   array.name());
 }
 } // namespace scipp::dataset
diff --git a/lib/dataset/bin.cpp b/lib/dataset/bin.cpp
index 384557fd5a..c87d412865 100644
--- a/lib/dataset/bin.cpp
+++ b/lib/dataset/bin.cpp
@@ -251,10 +251,10 @@ auto extract_unbinned(T &array, Mapping &map) {
 ///   meaningless. Note that rebinned masks have been applied before the binning
 ///   step.
 /// - If rebinning, existing meta data along unchanged dimensions is preserved.
-template <class Coords, class Masks, class Attrs>
+template <class Coords, class Masks>
 DataArray add_metadata(const Variable &data, std::unique_ptr<Mapper> mapper,
                        const Coords &coords, const Masks &masks,
-                       const Attrs &attrs, const std::vector<Variable> &edges,
+                       const std::vector<Variable> &edges,
                        const std::vector<Variable> &groups,
                        const std::vector<Dim> &erase) {
   auto bin_sizes = mapper->bin_sizes();
@@ -283,13 +283,8 @@ DataArray add_metadata(const Variable &data, std::unique_ptr<Mapper> mapper,
   for (const auto &[name, mask] : masks)
     if (!rebinned(mask))
       out_masks.insert_or_assign(name, copy(mask));
-  auto out_attrs = extract_unbinned(buffer, buffer.attrs());
-  for (const auto &[dim_, coord] : attrs)
-    if (!rebinned(coord) && !out_coords.contains(dim_))
-      out_attrs.insert_or_assign(dim_, coord);
   return DataArray{bins_from_sizes(std::move(buffer), bin_sizes),
-                   std::move(out_coords), std::move(out_masks),
-                   std::move(out_attrs)};
+                   std::move(out_coords), std::move(out_masks)};
 }
 
 class TargetBinBuilder {
@@ -559,10 +554,10 @@ DataArray groupby_concat_bins(const DataArray &array, const Variable &edges,
   builder.erase(reductionDim);
   const auto dims = array.dims();
   for (const auto &dim : dims.labels())
-    if (array.meta().contains(dim)) {
-      if (array.meta()[dim].dims().ndim() != 1 &&
-          array.meta()[dim].dims().contains(reductionDim))
-        builder.join(dim, array.meta()[dim]);
+    if (array.coords().contains(dim)) {
+      if (array.coords()[dim].dims().ndim() != 1 &&
+          array.coords()[dim].dims().contains(reductionDim))
+        builder.join(dim, array.coords()[dim]);
       else if (dim != reductionDim)
         builder.existing(dim, array.dims()[dim]);
     }
@@ -570,13 +565,13 @@ DataArray groupby_concat_bins(const DataArray &array, const Variable &edges,
   const auto masked =
       hide_masked(array.data(), array.masks(), builder.dims().labels());
   TargetBins<DataArray> target_bins(masked, builder.dims());
-  builder.build(*target_bins, array.meta());
+  builder.build(*target_bins, array.coords());
   // Note: Unlike in the other cases below we do not call
   // `drop_grouped_event_coords` here. Grouping is based on a bin-coord rather
   // than event-coord so we do not touch the latter.
   return add_metadata(masked, make_mapper(target_bins.release(), builder),
-                      array.coords(), array.masks(), array.attrs(),
-                      builder.edges(), builder.groups(), {reductionDim});
+                      array.coords(), array.masks(), builder.edges(),
+                      builder.groups(), {reductionDim});
 }
 
 namespace {
@@ -625,11 +620,9 @@ DataArray bin(const DataArray &array, const std::vector<Variable> &edges,
   validate_bin_args(array, edges, groups);
   const auto &data = array.data();
   const auto &coords = array.coords();
-  const auto &meta = array.meta();
   const auto &masks = array.masks();
-  const auto &attrs = array.attrs();
   if (data.dtype() == dtype<core::bin<DataArray>>) {
-    return bin(data, coords, masks, attrs, edges, groups, erase);
+    return bin(data, coords, masks, edges, groups, erase);
   } else {
     // Pretend existing binning along outermost binning dim to enable threading
     const auto tmp = pretend_bins_for_threading(
@@ -639,13 +632,13 @@ DataArray bin(const DataArray &array, const std::vector<Variable> &edges,
         (data.dims().volume() > std::numeric_limits<int32_t>::max())
             ? makeVariable<int64_t>(data.dims(), units::none)
             : makeVariable<int32_t>(data.dims(), units::none);
-    auto builder = axis_actions(data, meta, edges, groups, erase);
-    builder.build(target_bins_buffer, meta);
+    auto builder = axis_actions(data, coords, edges, groups, erase);
+    builder.build(target_bins_buffer, coords);
     auto target_bins = make_bins_no_validate(
         tmp.bin_indices(), data.dims().inner(), target_bins_buffer);
     return add_metadata(drop_grouped_event_coords(tmp, groups),
                         make_mapper(std::move(target_bins), builder), coords,
-                        masks, attrs, builder.edges(), builder.groups(), erase);
+                        masks, builder.edges(), builder.groups(), erase);
   }
 }
 
@@ -662,19 +655,18 @@ DataArray bin(const DataArray &array, const std::vector<Variable> &edges,
 ///        bin_sizes = count(bin_index) // number of events per target bin
 ///        bin_offset = cumsum(bin_sizes) - bin_sizes
 /// 3. Copy from input to output bin, based on offset
-template <class Coords, class Masks, class Attrs>
+template <class Coords, class Masks>
 DataArray bin(const Variable &data, const Coords &coords, const Masks &masks,
-              const Attrs &attrs, const std::vector<Variable> &edges,
+              const std::vector<Variable> &edges,
               const std::vector<Variable> &groups,
               const std::vector<Dim> &erase) {
-  const auto meta = attrs.merge_from(coords);
-  auto builder = axis_actions(data, meta, edges, groups, erase);
+  auto builder = axis_actions(data, coords, edges, groups, erase);
   const auto masked = hide_masked(data, masks, builder.dims().labels());
   TargetBins<DataArray> target_bins(masked, builder.dims());
-  builder.build(*target_bins, bins_view<DataArray>(masked).meta(), meta);
+  builder.build(*target_bins, bins_view<DataArray>(masked).coords(), coords);
   return add_metadata(drop_grouped_event_coords(masked, groups),
                       make_mapper(target_bins.release(), builder), coords,
-                      masks, attrs, builder.edges(), builder.groups(), erase);
+                      masks, builder.edges(), builder.groups(), erase);
 }
 
 } // namespace scipp::dataset
diff --git a/lib/dataset/bins.cpp b/lib/dataset/bins.cpp
index 7dc350feed..78f47bd9c9 100644
--- a/lib/dataset/bins.cpp
+++ b/lib/dataset/bins.cpp
@@ -82,10 +82,10 @@ auto make_fill(const DataArray &function,
 void copy_slices(const DataArray &src, DataArray dst, const Dim dim,
                  const Variable &srcIndices, const Variable &dstIndices) {
   copy_slices(src.data(), dst.data(), dim, srcIndices, dstIndices);
-  expect_matching_keys(src.meta(), dst.meta());
+  expect_matching_keys(src.coords(), dst.coords());
   expect_matching_keys(src.masks(), dst.masks());
-  for (const auto &[name, coord] : src.meta())
-    copy_or_match(coord, dst.meta()[name], dim, srcIndices, dstIndices);
+  for (const auto &[name, coord] : src.coords())
+    copy_or_match(coord, dst.coords()[name], dim, srcIndices, dstIndices);
   for (const auto &[name, mask] : src.masks())
     copy_or_match(mask, dst.masks()[name], dim, srcIndices, dstIndices);
 }
@@ -98,13 +98,10 @@ void copy_slices(const Dataset &src, Dataset dst, const Dim dim,
   expect_matching_keys(src, dst);
   for (const auto &item : src) {
     const auto &dst_ = dst[item.name()];
-    expect_matching_keys(item.attrs(), dst_.attrs());
     expect_matching_keys(item.masks(), dst_.masks());
     copy_or_match(item.data(), dst_.data(), dim, srcIndices, dstIndices);
     for (const auto &[name, var] : item.masks())
       copy_or_match(var, dst_.masks()[name], dim, srcIndices, dstIndices);
-    for (const auto &[name, var] : item.attrs())
-      copy_or_match(var, dst_.attrs()[name], dim, srcIndices, dstIndices);
   }
 }
 
@@ -133,8 +130,6 @@ DataArray resize_default_init(const DataArray &parent, const Dim dim,
     buffer.coords().set(name, copy_or_resize(var, dim, size));
   for (const auto &[name, var] : parent.masks())
     buffer.masks().set(name, copy_or_resize(var, dim, size));
-  for (const auto &[name, var] : parent.attrs())
-    buffer.attrs().set(name, copy_or_resize(var, dim, size));
   return buffer;
 }
 
@@ -151,8 +146,6 @@ Dataset resize_default_init(const Dataset &parent, const Dim dim,
     buffer.setData(item.name(), copy_or_resize(item.data(), dim, size));
     for (const auto &[name, var] : item.masks())
       buffer[item.name()].masks().set(name, copy_or_resize(var, dim, size));
-    for (const auto &[name, var] : item.attrs())
-      buffer[item.name()].attrs().set(name, copy_or_resize(var, dim, size));
   }
   return buffer;
 }
@@ -203,7 +196,7 @@ bool is_bins(const Dataset &dataset) {
 Variable lookup_previous(const DataArray &function, const Variable &x, Dim dim,
                          const std::optional<Variable> &fill_value) {
   const auto fill = make_fill(function, fill_value);
-  const auto &coord = function.meta()[dim];
+  const auto &coord = function.coords()[dim];
   const auto data = masked_data(function, dim, fill);
   const auto weights = subspan_view(data, dim);
   if (!allsorted(coord, dim))
@@ -279,8 +272,7 @@ Variable concatenate(const Variable &var0, const Variable &var1) {
 DataArray concatenate(const DataArray &a, const DataArray &b) {
   return DataArray{buckets::concatenate(a.data(), b.data()),
                    union_(a.coords(), b.coords(), "concatenate"),
-                   union_or(a.masks(), b.masks()),
-                   intersection(a.attrs(), b.attrs())};
+                   union_or(a.masks(), b.masks())};
 }
 
 /// Reduce a dimension by concatenating all elements along the dimension.
@@ -347,7 +339,7 @@ Variable histogram(const Variable &data, const Variable &binEdges) {
   }
 
   const auto masked = masked_data(buffer, dim);
-  const auto coord = buffer.meta()[hist_dim];
+  const auto coord = buffer.coords()[hist_dim];
   const auto dt = common_type(binEdges, coord);
   const auto promoted_coord = astype(coord, dt, CopyPolicy::TryAvoid);
   const auto promoted_edges = astype(binEdges, dt, CopyPolicy::TryAvoid);
@@ -367,7 +359,7 @@ Variable map(const DataArray &function, const Variable &x, Dim dim,
   const auto fill = make_fill(function, fill_value);
   if (dim == Dim::Invalid)
     dim = edge_dimension(function);
-  const auto &edges = function.meta()[dim];
+  const auto &edges = function.coords()[dim];
   if (!is_edges(function.dims(), edges.dims(), dim))
     throw except::BinEdgeError(
         "Function used as lookup table in map operation must be a histogram");
@@ -392,8 +384,8 @@ void scale(DataArray &array, const DataArray &histogram, Dim dim) {
   // scale applies masks along dim but others are kept
   union_or_in_place(array.masks(), histogram.slice({dim, 0}).masks());
   auto data = bins_view<DataArray>(array.data()).data();
-  const auto &coord = bins_view<DataArray>(array.data()).meta()[dim];
-  const auto &edges = histogram.meta()[dim];
+  const auto &coord = bins_view<DataArray>(array.data()).coords()[dim];
+  const auto &edges = histogram.coords()[dim];
   const auto masked = masked_data(histogram, dim);
   const auto weights = subspan_view(masked, dim);
   if (all(islinspace(edges, dim)).value<bool>()) {
diff --git a/lib/dataset/data_array.cpp b/lib/dataset/data_array.cpp
index 5403ed1024..610ec80ac2 100644
--- a/lib/dataset/data_array.cpp
+++ b/lib/dataset/data_array.cpp
@@ -21,37 +21,27 @@ template <class T> auto copy_shared(const std::shared_ptr<T> &obj) {
 }
 } // namespace
 
-DataArray::DataArray(const DataArray &other, const AttrPolicy attrPolicy)
+DataArray::DataArray(const DataArray &other)
     : m_name(other.m_name), m_data(copy_shared(other.m_data)),
       m_coords(copy_shared(other.m_coords)),
-      m_masks(copy_shared(other.m_masks)),
-      m_attrs(attrPolicy == AttrPolicy::Keep ? copy_shared(other.m_attrs)
-                                             : std::make_shared<Attrs>()),
-      m_readonly(false) {}
-
-DataArray::DataArray(const DataArray &other)
-    : DataArray(other, AttrPolicy::Keep) {}
+      m_masks(copy_shared(other.m_masks)), m_readonly(false) {}
 
-DataArray::DataArray(Variable data, Coords coords, Masks masks, Attrs attrs,
+DataArray::DataArray(Variable data, Coords coords, Masks masks,
                      const std::string_view name)
     : m_name(name), m_data(std::make_shared<Variable>(std::move(data))),
       m_coords(std::make_shared<Coords>(std::move(coords))),
-      m_masks(std::make_shared<Masks>(std::move(masks))),
-      m_attrs(std::make_shared<Attrs>(std::move(attrs))) {
+      m_masks(std::make_shared<Masks>(std::move(masks))) {
   const Sizes sizes(dims());
   m_coords->setSizes(sizes);
   m_masks->setSizes(sizes);
-  m_attrs->setSizes(sizes);
 }
 
 DataArray::DataArray(Variable data, typename Coords::holder_type coords,
                      typename Masks::holder_type masks,
-                     typename Attrs::holder_type attrs,
                      const std::string_view name)
     : m_name(name), m_data(std::make_shared<Variable>(std::move(data))),
       m_coords(std::make_shared<Coords>(dims(), std::move(coords))),
-      m_masks(std::make_shared<Masks>(dims(), std::move(masks))),
-      m_attrs(std::make_shared<Attrs>(dims(), std::move(attrs))) {}
+      m_masks(std::make_shared<Masks>(dims(), std::move(masks))) {}
 
 DataArray &DataArray::operator=(const DataArray &other) {
   if (this == &other) {
@@ -70,7 +60,6 @@ DataArray &DataArray::operator=(DataArray &&other) {
   m_data = std::move(other.m_data);
   m_coords = std::move(other.m_coords);
   m_masks = std::move(other.m_masks);
-  m_attrs = std::move(other.m_attrs);
   m_readonly = other.m_readonly;
   return *this;
 }
@@ -93,8 +82,6 @@ bool operator==(const DataArray &a, const DataArray &b) {
     return false;
   if (a.masks() != b.masks())
     return false;
-  if (a.attrs() != b.attrs())
-    return false;
   return a.data() == b.data();
 }
 
@@ -107,8 +94,6 @@ bool equals_nan(const DataArray &a, const DataArray &b) {
     return false;
   if (!equals_nan(a.masks(), b.masks()))
     return false;
-  if (!equals_nan(a.attrs(), b.attrs()))
-    return false;
   return equals_nan(a.data(), b.data());
 }
 
@@ -120,15 +105,9 @@ const std::string &DataArray::name() const { return m_name; }
 
 void DataArray::setName(const std::string_view name) { m_name = name; }
 
-Coords DataArray::meta() const {
-  auto out = attrs().merge_from(coords());
-  out.set_readonly();
-  return out;
-}
-
 DataArray DataArray::slice(const Slice &s) const {
   auto out = DataArray{m_data->slice(s), m_coords->slice_coords(s),
-                       m_masks->slice(s), m_attrs->slice(s), m_name};
+                       m_masks->slice(s), m_name};
   out.m_readonly = true;
   return out;
 }
@@ -158,7 +137,6 @@ DataArray DataArray::view() const {
   out.m_data = m_data;     // share data
   out.m_coords = m_coords; // share coords
   out.m_masks = m_masks;   // share masks
-  out.m_attrs = m_attrs;   // share attrs
   out.m_name = m_name;
   return out;
 }
@@ -177,7 +155,6 @@ DataArray DataArray::view_with_coords(const Coords &coords,
   out.m_coords =
       std::make_shared<Coords>(sizes, std::move(selected), readonly_coords);
   out.m_masks = m_masks; // share masks
-  out.m_attrs = m_attrs; // share attrs
   out.m_name = name;
   out.m_readonly = readonly;
   return out;
@@ -199,24 +176,16 @@ DataArray::drop_masks(const scipp::span<const std::string> mask_names) const {
   return result;
 }
 
-DataArray DataArray::drop_attrs(const scipp::span<const Dim> attr_names) const {
-  DataArray result = *this;
-  for (const auto &name : attr_names)
-    result.attrs().erase(name);
-  return result;
-}
-
 DataArray DataArray::rename_dims(const std::vector<std::pair<Dim, Dim>> &names,
                                  const bool fail_on_unknown) const {
   return DataArray(m_data->rename_dims(names, fail_on_unknown),
                    m_coords->rename_dims(names, false),
-                   m_masks->rename_dims(names, false),
-                   m_attrs->rename_dims(names, false));
+                   m_masks->rename_dims(names, false));
 }
 
 DataArray DataArray::as_const() const {
   auto out = DataArray(data().as_const(), coords().as_const(),
-                       masks().as_const(), attrs().as_const(), name());
+                       masks().as_const(), name());
   out.m_readonly = true;
   return out;
 }
diff --git a/lib/dataset/dataset.cpp b/lib/dataset/dataset.cpp
index bdc19b0ca2..e1090d6b9e 100644
--- a/lib/dataset/dataset.cpp
+++ b/lib/dataset/dataset.cpp
@@ -96,11 +96,6 @@ Dataset Dataset::drop_coords(const scipp::span<const Dim> coord_names) const {
   return result;
 }
 
-/// Alias for coords().
-const Coords &Dataset::meta() const noexcept { return coords(); }
-/// Alias for coords().
-Coords &Dataset::meta() noexcept { return coords(); }
-
 bool Dataset::contains(const std::string &name) const noexcept {
   return m_data.contains(name);
 }
@@ -139,30 +134,21 @@ void Dataset::setCoord(const Dim dim, Variable coord) {
 /// Set (insert or replace) data (values, optional variances) with given name.
 ///
 /// Throws if the provided values bring the dataset into an inconsistent state
-/// (mismatching dimensions). The default is to drop existing attributes, unless
-/// AttrPolicy::Keep is specified.
-void Dataset::setData(const std::string &name, Variable data,
-                      const AttrPolicy attrPolicy) {
+/// (mismatching dimensions).
+void Dataset::setData(const std::string &name, Variable data) {
   expect_writable(*this);
   expect_valid(*this);
   expect_matching_item_dims(*this, name, data);
-  const auto replace = contains(name);
-  if (replace && attrPolicy == AttrPolicy::Keep)
-    m_data.insert_or_assign(
-        name, DataArray(std::move(data), {}, m_data[name].masks().items(),
-                        m_data[name].attrs().items(), name));
-  else
-    m_data.insert_or_assign(name, DataArray(std::move(data)));
+  m_data.insert_or_assign(name, DataArray(std::move(data)));
 }
 
 // See docs of overload for data arrays.
-void Dataset::setDataInit(const std::string &name, Variable data,
-                          const AttrPolicy attrPolicy) {
+void Dataset::setDataInit(const std::string &name, Variable data) {
   if (!is_valid()) {
     m_coords.setSizes(data.dims());
     m_valid = true;
   }
-  setData(name, std::move(data), attrPolicy);
+  setData(name, std::move(data));
 }
 
 namespace {
@@ -182,15 +168,15 @@ auto coords_to_skip(const Dataset &dst, const DataArray &src) {
 
 /// Set (insert or replace) data from a DataArray with a given name.
 ///
-/// Coordinates, masks, and attributes of the data array are added to the
-/// dataset. Throws if there are existing but mismatching coords, masks, or
-/// attributes. Throws if the provided data brings the dataset into an
+/// Coordinates and masks of the data array are added to the dataset.
+/// Throws if there are existing but mismatching coords or masks.
+/// Throws if the provided data brings the dataset into an
 /// inconsistent state (mismatching dimensions).
 void Dataset::setData(const std::string &name, const DataArray &data) {
   // Return early on self assign to avoid exceptions from Python inplace ops
   if (const auto it = find(name); it != end()) {
     if (it->data().is_same(data.data()) && it->masks() == data.masks() &&
-        it->attrs() == data.attrs() && it->coords() == data.coords())
+        it->coords() == data.coords())
       return;
   }
   const auto to_skip = coords_to_skip(*this, data);
@@ -201,10 +187,6 @@ void Dataset::setData(const std::string &name, const DataArray &data) {
     if (m_coords.find(dim) == m_coords.end() &&
         std::find(to_skip.begin(), to_skip.end(), dim) == to_skip.end())
       setCoord(dim, coord);
-  // Attrs might be shadowed by a coord, but this cannot be prevented in
-  // general, so instead of failing here we proceed (and may fail later if
-  // meta() is called).
-  item.attrs() = data.attrs();
   item.masks() = data.masks();
 }
 
diff --git a/lib/dataset/dataset_operations_common.h b/lib/dataset/dataset_operations_common.h
index 2f503c62bf..13b0031a72 100644
--- a/lib/dataset/dataset_operations_common.h
+++ b/lib/dataset/dataset_operations_common.h
@@ -21,16 +21,14 @@ DataArray apply_or_copy_dim_impl(const DataArray &da, Func func, const Dim dim,
     return out;
   };
   auto coords = copy_independent(da.coords(), true);
-  auto attrs = copy_independent(da.attrs(), true);
   auto masks = copy_independent(da.masks(), false);
 
   if constexpr (ApplyToData) {
     return DataArray(func(da.data(), dim, args...), std::move(coords),
-                     std::move(masks), std::move(attrs), da.name());
+                     std::move(masks), da.name());
   } else {
     return DataArray(func(da, dim, std::forward<Args>(args)...),
-                     std::move(coords), std::move(masks), std::move(attrs),
-                     da.name());
+                     std::move(coords), std::move(masks), da.name());
   }
 }
 
@@ -39,7 +37,7 @@ DataArray apply_or_copy_dim_impl(const DataArray &da, Func func, const Dim dim,
 ///
 /// Examples are mostly reduction operations such as `sum` (dropping a
 /// dimension), or `resize` (altering a dimension extent). Creates new data
-/// array by applying `func` to data and dropping coords/masks/attrs depending
+/// array by applying `func` to data and dropping coords/masks depending
 /// on dim.
 template <class Func, class... Args>
 DataArray apply_to_data_and_drop_dim(const DataArray &a, Func func,
@@ -66,14 +64,6 @@ DataArray apply_to_items(const DataArray &d, Func func, Args &&...args) {
   return func(d, std::forward<Args>(args)...);
 }
 
-template <class... Args>
-bool copy_attr(const Variable &attr, const Dim dim, const Args &...) {
-  return !attr.dims().contains(dim);
-}
-template <class... Args> bool copy_attr(const Variable &, const Args &...) {
-  return true;
-}
-
 template <class Func, class... Args>
 Dataset apply_to_items(const Dataset &d, Func func, Args &&...args) {
   Dataset result;
@@ -102,8 +92,7 @@ template <class T, class Func> DataArray transform(const T &a, Func func) {
   return DataArray(
       func(a.data()),
       transform_map<typename Coords::holder_type>(a.coords(), func),
-      transform_map<typename Masks::holder_type>(a.masks(), func),
-      transform_map<typename Attrs::holder_type>(a.attrs(), func), a.name());
+      transform_map<typename Masks::holder_type>(a.masks(), func));
 }
 
 [[nodiscard]] DataArray strip_if_broadcast_along(const DataArray &a,
diff --git a/lib/dataset/extract.cpp b/lib/dataset/extract.cpp
index c3ee1c8b0e..95458ca9c2 100644
--- a/lib/dataset/extract.cpp
+++ b/lib/dataset/extract.cpp
@@ -15,8 +15,7 @@ namespace scipp {
 
 namespace {
 
-/// Transform data of data array or dataset, coord, masks, and and attrs are
-/// shallow-copied.
+/// Transform data of data array or dataset, coord and masks are shallow-copied.
 ///
 /// Beware of the mask-copy behavior, which is not suitable for data returned to
 /// the user.
@@ -29,8 +28,7 @@ T transform_data(const T &obj, Func func, const Ts &...other) {
     out.setData(func(obj.data(), other.data()...));
   } else {
     for (const auto &item : obj)
-      out.setData(item.name(), func(item.data(), other[item.name()].data()...),
-                  dataset::AttrPolicy::Keep);
+      out.setData(item.name(), func(item.data(), other[item.name()].data()...));
   }
   return out;
 }
diff --git a/lib/dataset/groupby.cpp b/lib/dataset/groupby.cpp
index 579e701f27..d516ba24e6 100644
--- a/lib/dataset/groupby.cpp
+++ b/lib/dataset/groupby.cpp
@@ -197,8 +197,7 @@ template <class T> T GroupBy<T>::mean(const Dim reductionDim) const {
   if constexpr (std::is_same_v<T, Dataset>) {
     for (auto &&item : out) {
       if (is_int(item.data().dtype()))
-        out.setData(item.name(), item.data() * get_scale(m_data[item.name()]),
-                    AttrPolicy::Keep);
+        out.setData(item.name(), item.data() * get_scale(m_data[item.name()]));
       else
         item *= get_scale(m_data[item.name()]);
     }
@@ -334,7 +333,7 @@ GroupBy<T> call_groupby(const T &array, const Variable &key, const Dim &dim) {
 /// Grouping will create a new coordinate for the dimension of the grouping
 /// coord in a later apply/combine step.
 GroupBy<DataArray> groupby(const DataArray &array, const Dim dim) {
-  const auto &key = array.meta()[dim];
+  const auto &key = array.coords()[dim];
   return call_groupby(array, key, dim);
 }
 
@@ -345,7 +344,7 @@ GroupBy<DataArray> groupby(const DataArray &array, const Dim dim) {
 /// new coordinate to the output in a later apply/combine step.
 GroupBy<DataArray> groupby(const DataArray &array, const Dim dim,
                            const Variable &bins) {
-  const auto &key = array.meta()[dim];
+  const auto &key = array.coords()[dim];
   return groupby(array, key, bins);
 }
 
@@ -368,7 +367,7 @@ GroupBy<DataArray> groupby(const DataArray &array, const Variable &key,
 /// Grouping will create a new coordinate for the dimension of the grouping
 /// coord in a later apply/combine step.
 GroupBy<Dataset> groupby(const Dataset &dataset, const Dim dim) {
-  const auto &key = dataset.meta()[dim];
+  const auto &key = dataset.coords()[dim];
   return call_groupby(dataset, key, dim);
 }
 
@@ -379,7 +378,7 @@ GroupBy<Dataset> groupby(const Dataset &dataset, const Dim dim) {
 /// new coordinate to the output in a later apply/combine step.
 GroupBy<Dataset> groupby(const Dataset &dataset, const Dim dim,
                          const Variable &bins) {
-  const auto &key = dataset.meta()[dim];
+  const auto &key = dataset.coords()[dim];
   return groupby(dataset, key, bins);
 }
 
diff --git a/lib/dataset/include/scipp/dataset/bin.h b/lib/dataset/include/scipp/dataset/bin.h
index 54c2fbef63..08d2edbd5f 100644
--- a/lib/dataset/include/scipp/dataset/bin.h
+++ b/lib/dataset/include/scipp/dataset/bin.h
@@ -13,9 +13,9 @@ SCIPP_DATASET_EXPORT DataArray bin(const DataArray &array,
                                    const std::vector<Variable> &groups = {},
                                    const std::vector<Dim> &erase = {});
 
-template <class Coords, class Masks, class Attrs>
+template <class Coords, class Masks>
 SCIPP_DATASET_EXPORT DataArray bin(const Variable &data, const Coords &coords,
-                                   const Masks &masks, const Attrs &attrs,
+                                   const Masks &masks,
                                    const std::vector<Variable> &edges,
                                    const std::vector<Variable> &groups = {},
                                    const std::vector<Dim> &erase = {});
diff --git a/lib/dataset/include/scipp/dataset/bins_view.h b/lib/dataset/include/scipp/dataset/bins_view.h
index 19d5a57b7f..e13e26ad5d 100644
--- a/lib/dataset/include/scipp/dataset/bins_view.h
+++ b/lib/dataset/include/scipp/dataset/bins_view.h
@@ -131,9 +131,7 @@ template <class T> class Bins : public BinsCommon<T> {
   void setData(const Variable &var) {
     this->buffer().setData(this->check_and_get_buf(var));
   }
-  auto meta() const { return BinsMapView(*this, get_meta); }
   auto coords() const { return BinsMapView(*this, get_coords); }
-  auto attrs() const { return BinsMapView(*this, get_attrs); }
   auto masks() const { return BinsMapView(*this, get_masks); }
   auto &name() const { return this->buffer().name(); }
   auto drop_coords(const scipp::span<const Dim> coord_names) const {
@@ -146,11 +144,6 @@ template <class T> class Bins : public BinsCommon<T> {
     for (const auto &name : mask_names)
       result.masks().erase(name);
   }
-  auto drop_attrs(const scipp::span<const Dim> attr_names) const {
-    auto result = *this;
-    for (const auto &name : attr_names)
-      result.attrs().erase(name);
-  }
 };
 } // namespace bins_view_detail
 
diff --git a/lib/dataset/include/scipp/dataset/data_array.h b/lib/dataset/include/scipp/dataset/data_array.h
index 0c3bfa080e..fbec20d262 100644
--- a/lib/dataset/include/scipp/dataset/data_array.h
+++ b/lib/dataset/include/scipp/dataset/data_array.h
@@ -12,23 +12,17 @@
 
 namespace scipp::dataset {
 
-/// Policies for attribute propagation in operations with data arrays or
-/// dataset.
-enum class AttrPolicy { Keep, Drop };
-
-/// Data array, a variable with coordinates, masks, and attributes.
+/// Data array, a variable with coordinates and masks.
 class SCIPP_DATASET_EXPORT DataArray {
 public:
   DataArray() = default;
-  DataArray(const DataArray &other, AttrPolicy attrPolicy);
   DataArray(const DataArray &other);
   DataArray(DataArray &&other) = default;
 
-  DataArray(Variable data, Coords coords, Masks masks, Attrs attrs,
+  DataArray(Variable data, Coords coords, Masks masks,
             std::string_view name = "");
   explicit DataArray(Variable data, typename Coords::holder_type coords = {},
                      typename Masks::holder_type masks = {},
-                     typename Attrs::holder_type attrs = {},
                      std::string_view name = "");
 
   DataArray &operator=(const DataArray &other);
@@ -51,13 +45,6 @@ class SCIPP_DATASET_EXPORT DataArray {
 
   DataArray drop_masks(const scipp::span<const std::string> mask_names) const;
 
-  const Attrs &attrs() const { return *m_attrs; }
-  Attrs &attrs() { return *m_attrs; }
-
-  DataArray drop_attrs(const scipp::span<const Dim> attr_names) const;
-
-  Coords meta() const;
-
   [[nodiscard]] const Dimensions &dims() const { return m_data->dims(); }
   [[nodiscard]] Dim dim() const { return m_data->dim(); }
   [[nodiscard]] scipp::index ndim() const { return m_data->ndim(); }
@@ -118,7 +105,6 @@ class SCIPP_DATASET_EXPORT DataArray {
   std::shared_ptr<Variable> m_data;
   std::shared_ptr<Coords> m_coords;
   std::shared_ptr<Masks> m_masks;
-  std::shared_ptr<Attrs> m_attrs;
   bool m_readonly{false};
 };
 
@@ -126,7 +112,7 @@ SCIPP_DATASET_EXPORT bool operator==(const DataArray &a, const DataArray &b);
 SCIPP_DATASET_EXPORT bool operator!=(const DataArray &a, const DataArray &b);
 
 [[nodiscard]] SCIPP_DATASET_EXPORT DataArray
-copy(const DataArray &array, AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const DataArray &array);
 
 [[nodiscard]] SCIPP_DATASET_EXPORT bool equals_nan(const DataArray &a,
                                                    const DataArray &b);
diff --git a/lib/dataset/include/scipp/dataset/dataset.h b/lib/dataset/include/scipp/dataset/dataset.h
index 4aff536fa9..c76ccd1841 100644
--- a/lib/dataset/include/scipp/dataset/dataset.h
+++ b/lib/dataset/include/scipp/dataset/dataset.h
@@ -95,7 +95,7 @@ class SCIPP_DATASET_EXPORT Dataset {
 
   /// Return the number of data items in the dataset.
   ///
-  /// This does not include coordinates or attributes, but only all named
+  /// This does not include coordinates and masks, but only all named
   /// entities (which can consist of various combinations of values, variances,
   /// and events coordinates).
   index size() const noexcept { return scipp::size(m_data); }
@@ -113,11 +113,6 @@ class SCIPP_DATASET_EXPORT Dataset {
 
   Dataset drop_masks(const scipp::span<const std::string> mask_names) const;
 
-  Dataset drop_attrs(const scipp::span<const Dim> attr_names) const;
-
-  const Coords &meta() const noexcept;
-  Coords &meta() noexcept;
-
   bool contains(const std::string &name) const noexcept;
 
   void erase(const std::string &name);
@@ -185,11 +180,9 @@ class SCIPP_DATASET_EXPORT Dataset {
   auto keys_end() & noexcept { return m_data.keys_end(); }
 
   void setCoord(const Dim dim, Variable coord);
-  void setData(const std::string &name, Variable data,
-               const AttrPolicy attrPolicy = AttrPolicy::Drop);
+  void setData(const std::string &name, Variable data);
   void setData(const std::string &name, const DataArray &data);
-  void setDataInit(const std::string &name, Variable data,
-                   const AttrPolicy attrPolicy = AttrPolicy::Drop);
+  void setDataInit(const std::string &name, Variable data);
   void setDataInit(const std::string &name, const DataArray &data);
 
   Dataset slice(const Slice &s) const;
@@ -244,20 +237,16 @@ class SCIPP_DATASET_EXPORT Dataset {
 };
 
 [[nodiscard]] SCIPP_DATASET_EXPORT Dataset
-copy(const Dataset &dataset, const AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const Dataset &dataset);
 
 [[maybe_unused]] SCIPP_DATASET_EXPORT DataArray &
-copy(const DataArray &array, DataArray &out,
-     const AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const DataArray &array, DataArray &out);
 [[maybe_unused]] SCIPP_DATASET_EXPORT DataArray
-copy(const DataArray &array, DataArray &&out,
-     const AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const DataArray &array, DataArray &&out);
 [[maybe_unused]] SCIPP_DATASET_EXPORT Dataset &
-copy(const Dataset &dataset, Dataset &out,
-     const AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const Dataset &dataset, Dataset &out);
 [[maybe_unused]] SCIPP_DATASET_EXPORT Dataset
-copy(const Dataset &dataset, Dataset &&out,
-     const AttrPolicy attrPolicy = AttrPolicy::Keep);
+copy(const Dataset &dataset, Dataset &&out);
 
 SCIPP_DATASET_EXPORT Dataset operator+(const Dataset &lhs, const Dataset &rhs);
 SCIPP_DATASET_EXPORT Dataset operator+(const Dataset &lhs,
diff --git a/lib/dataset/include/scipp/dataset/dataset_util.h b/lib/dataset/include/scipp/dataset/dataset_util.h
index 28e20b937a..6246090c77 100644
--- a/lib/dataset/include/scipp/dataset/dataset_util.h
+++ b/lib/dataset/include/scipp/dataset/dataset_util.h
@@ -58,7 +58,6 @@ void check_nested_in_assign(const L &lhs, const R &rhs) {
     check_nested_in_assign(lhs, item.data());
     check_nested_in_assign(lhs, item.coords());
     check_nested_in_assign(lhs, item.masks());
-    check_nested_in_assign(lhs, item.attrs());
   };
 
   if constexpr (std::is_same_v<std::decay_t<R>, DataArray>) {
diff --git a/lib/dataset/include/scipp/dataset/sized_dict.h b/lib/dataset/include/scipp/dataset/sized_dict.h
index 376559cba9..a1de6c2859 100644
--- a/lib/dataset/include/scipp/dataset/sized_dict.h
+++ b/lib/dataset/include/scipp/dataset/sized_dict.h
@@ -189,11 +189,9 @@ core::Dict<Key, Value> intersection(const SizedDict<Key, Value> &a,
 
 constexpr auto get_data = [](auto &&a) -> decltype(auto) { return a.data(); };
 constexpr auto get_sizes = [](auto &&a) -> decltype(auto) { return a.sizes(); };
-constexpr auto get_meta = [](auto &&a) -> decltype(auto) { return a.meta(); };
 constexpr auto get_coords = [](auto &&a) -> decltype(auto) {
   return a.coords();
 };
-constexpr auto get_attrs = [](auto &&a) -> decltype(auto) { return a.attrs(); };
 constexpr auto get_masks = [](auto &&a) -> decltype(auto) { return a.masks(); };
 
 } // namespace scipp::dataset
diff --git a/lib/dataset/include/scipp/dataset/sized_dict_forward.h b/lib/dataset/include/scipp/dataset/sized_dict_forward.h
index 721f4f6d58..44b7a2b0a8 100644
--- a/lib/dataset/include/scipp/dataset/sized_dict_forward.h
+++ b/lib/dataset/include/scipp/dataset/sized_dict_forward.h
@@ -19,8 +19,6 @@ template <class Key, class Value> class SizedDict;
 using Coords = SizedDict<Dim, variable::Variable>;
 /// Dict of masks of DataArray and Dataset.
 using Masks = SizedDict<std::string, variable::Variable>;
-/// Dict of attributes of DataArray and Dataset.
-using Attrs = SizedDict<Dim, variable::Variable>;
 
 [[nodiscard]] SCIPP_DATASET_EXPORT Coords copy(const Coords &coords);
 [[nodiscard]] SCIPP_DATASET_EXPORT Masks copy(const Masks &masks);
diff --git a/lib/dataset/operations.cpp b/lib/dataset/operations.cpp
index be94246473..eead362278 100644
--- a/lib/dataset/operations.cpp
+++ b/lib/dataset/operations.cpp
@@ -48,66 +48,56 @@ Coords copy(const Coords &coords) { return {coords.sizes(), copy_map(coords)}; }
 Masks copy(const Masks &masks) { return {masks.sizes(), copy_map(masks)}; }
 
 /// Return a deep copy of a DataArray.
-DataArray copy(const DataArray &array, const AttrPolicy attrPolicy) {
+DataArray copy(const DataArray &array) {
   // When data is copied we generally need to copy masks, since masks are
   // typically modified when data is modified.
-  return DataArray(
-      copy(array.data()), copy(array.coords()), copy(array.masks()),
-      attrPolicy == AttrPolicy::Keep ? copy(array.attrs()) : Attrs{},
-      array.name());
+  return DataArray(copy(array.data()), copy(array.coords()),
+                   copy(array.masks()), array.name());
 }
 
 /// Return a deep copy of a Dataset.
-Dataset copy(const Dataset &dataset, const AttrPolicy attrPolicy) {
+Dataset copy(const Dataset &dataset) {
   Dataset out{{}, copy(dataset.coords())};
   for (const auto &item : dataset) {
-    out.setData(item.name(), copy(item, attrPolicy));
+    out.setData(item.name(), copy(item));
   }
   return out;
 }
 
 namespace {
-template <class T>
-void copy_item(const DataArray &from, T &&to, const AttrPolicy attrPolicy) {
+template <class T> void copy_item(const DataArray &from, T &&to) {
   for (const auto &[name, mask] : from.masks())
     copy(mask, to.masks()[name]);
-  if (attrPolicy == AttrPolicy::Keep)
-    for (const auto &[dim, attr] : from.attrs())
-      copy(attr, to.attrs()[dim]);
   copy(from.data(), to.data());
 }
 } // namespace
 
 /// Copy data array to output data array
-DataArray &copy(const DataArray &array, DataArray &out,
-                const AttrPolicy attrPolicy) {
+DataArray &copy(const DataArray &array, DataArray &out) {
   for (const auto &[dim, coord] : array.coords())
     copy(coord, out.coords()[dim]);
-  copy_item(array, out, attrPolicy);
+  copy_item(array, out);
   return out;
 }
 
 /// Copy data array to output data array
-DataArray copy(const DataArray &array, DataArray &&out,
-               const AttrPolicy attrPolicy) {
-  copy(array, out, attrPolicy);
+DataArray copy(const DataArray &array, DataArray &&out) {
+  copy(array, out);
   return std::move(out);
 }
 
 /// Copy dataset to output dataset
-Dataset &copy(const Dataset &dataset, Dataset &out,
-              const AttrPolicy attrPolicy) {
+Dataset &copy(const Dataset &dataset, Dataset &out) {
   for (const auto &[dim, coord] : dataset.coords())
     copy(coord, out.coords()[dim]);
   for (const auto &array : dataset)
-    copy_item(array, out[array.name()], attrPolicy);
+    copy_item(array, out[array.name()]);
   return out;
 }
 
 /// Copy dataset to output dataset
-Dataset copy(const Dataset &dataset, Dataset &&out,
-             const AttrPolicy attrPolicy) {
-  copy(dataset, out, attrPolicy);
+Dataset copy(const Dataset &dataset, Dataset &&out) {
+  copy(dataset, out);
   return std::move(out);
 }
 
@@ -137,8 +127,7 @@ template <class Dict> auto strip_(const Dict &dict, const Dim dim) {
 } // namespace
 
 DataArray strip_if_broadcast_along(const DataArray &a, const Dim dim) {
-  return {a.data(), strip_(a.coords(), dim), strip_(a.masks(), dim),
-          strip_(a.attrs(), dim), a.name()};
+  return {a.data(), strip_(a.coords(), dim), strip_(a.masks(), dim), a.name()};
 }
 
 Dataset strip_if_broadcast_along(const Dataset &d, const Dim dim) {
diff --git a/lib/dataset/shape.cpp b/lib/dataset/shape.cpp
index b2f0d79af6..aecfad6049 100644
--- a/lib/dataset/shape.cpp
+++ b/lib/dataset/shape.cpp
@@ -121,9 +121,6 @@ DataArray concat(const scipp::span<const DataArray> das, const Dim dim) {
                                   [&d = d](auto &_) { return _.contains(d); }));
     out.coords().set(d, std::move(coord));
   }
-  for (auto &&[d, attr] : concat_maps(map(das, get_attrs), dim)) {
-    out.attrs().set(d, std::move(attr));
-  }
   return out;
 }
 
@@ -281,8 +278,7 @@ DataArray flatten(const DataArray &a,
                   const Dim to_dim) {
   const auto &labels = from_labels.value_or(a.dims().labels());
   if (from_labels.has_value() && labels.empty())
-    return DataArray(flatten(a.data(), labels, to_dim), a.coords(), a.masks(),
-                     a.attrs());
+    return DataArray(flatten(a.data(), labels, to_dim), a.coords(), a.masks());
   expect_dimension_subset(a.dims(), labels);
   return dataset::transform(a, [&](const auto &in) {
     auto var = (&in == &a.data()) ? in : maybe_broadcast(in, labels, a.dims());
@@ -301,8 +297,7 @@ DataArray flatten(const DataArray &a,
 }
 
 DataArray transpose(const DataArray &a, const scipp::span<const Dim> dims) {
-  return {transpose(a.data(), dims), a.coords(), a.masks(), a.attrs(),
-          a.name()};
+  return {transpose(a.data(), dims), a.coords(), a.masks(), a.name()};
 }
 
 Dataset transpose(const Dataset &d, const scipp::span<const Dim> dims) {
diff --git a/lib/dataset/sized_dict.cpp b/lib/dataset/sized_dict.cpp
index bc1e31ae0a..eba956adaa 100644
--- a/lib/dataset/sized_dict.cpp
+++ b/lib/dataset/sized_dict.cpp
@@ -340,7 +340,7 @@ SizedDict<Key, Value> SizedDict<Key, Value>::rename_dims(
   auto out(*this);
   out.m_sizes = out.m_sizes.rename_dims(names, fail_on_unknown);
   for (auto &&item : out.m_items) {
-    // DataArray coords/attrs support the special case of length-2 items with a
+    // DataArray coords support the special case of length-2 items with a
     // dim that is not contained in the data array dims. This occurs, e.g., when
     // slicing along a dim that has a bin edge coord. We must prevent renaming
     // to such dims. This is the reason for calling with `names` that may
@@ -387,12 +387,6 @@ SizedDict<Key, Value>::merge_from(const SizedDict &other) const {
   auto out(*this);
   out.m_readonly = false;
   for (const auto &[key, value] : other) {
-    if (out.contains(key))
-      throw except::DataArrayError(
-          "Coord '" + to_string(key) +
-          "' shadows attr of the same name. Remove the attr if you are slicing "
-          "an array or use the `coords` and `attrs` properties instead of "
-          "`meta`.");
     out.set(key, value);
   }
   out.m_readonly = m_readonly;
diff --git a/lib/dataset/sort.cpp b/lib/dataset/sort.cpp
index 82b269f46c..e679d4863a 100644
--- a/lib/dataset/sort.cpp
+++ b/lib/dataset/sort.cpp
@@ -85,7 +85,7 @@ DataArray sort(const DataArray &array, const Variable &key,
 
 /// Return a DataArray sorted based on coordinate.
 DataArray sort(const DataArray &array, const Dim &key, const SortOrder order) {
-  return sort(array, array.meta()[key], order);
+  return sort(array, array.coords()[key], order);
 }
 
 /// Return a Dataset sorted based on key.
diff --git a/lib/dataset/string.cpp b/lib/dataset/string.cpp
index 955f4ee4b0..ddb49b97c1 100644
--- a/lib/dataset/string.cpp
+++ b/lib/dataset/string.cpp
@@ -60,11 +60,6 @@ auto format_data_view(const Key &name, const DataArray &data,
     for (const auto &[key, var] : sorted(data.masks()))
       s << data_shift << format_variable(key, var, datasetSizes);
   }
-  if (!data.attrs().empty()) {
-    s << header_shift << "Attributes:\n";
-    for (const auto &[key, var] : sorted(data.attrs()))
-      s << data_shift << format_variable(key, var, datasetSizes);
-  }
   return s.str();
 }
 
diff --git a/lib/dataset/test/CMakeLists.txt b/lib/dataset/test/CMakeLists.txt
index b8e96c76dd..7cc7e59cac 100644
--- a/lib/dataset/test/CMakeLists.txt
+++ b/lib/dataset/test/CMakeLists.txt
@@ -7,7 +7,6 @@ add_dependencies(all-tests ${TARGET_NAME})
 add_executable(
   ${TARGET_NAME}
   astype_test.cpp
-  attributes_test.cpp
   binned_arithmetic_test.cpp
   binned_creation_test.cpp
   bins_test.cpp
diff --git a/lib/dataset/test/attributes_test.cpp b/lib/dataset/test/attributes_test.cpp
deleted file mode 100644
index e4af676c18..0000000000
--- a/lib/dataset/test/attributes_test.cpp
+++ /dev/null
@@ -1,138 +0,0 @@
-// SPDX-License-Identifier: BSD-3-Clause
-// Copyright (c) 2023 Scipp contributors (https://github.com/scipp)
-#include <gtest/gtest.h>
-
-#include "scipp/dataset/dataset.h"
-#include "scipp/dataset/mean.h"
-#include "scipp/dataset/rebin.h"
-#include "scipp/dataset/shape.h"
-#include "scipp/dataset/sum.h"
-#include "scipp/variable/arithmetic.h"
-
-using namespace scipp;
-using namespace scipp::dataset;
-
-class AttributesTest : public ::testing::Test {
-protected:
-  const Variable scalar = makeVariable<double>(Values{1});
-  const Variable varX =
-      makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{2, 3});
-  const Variable varZX = makeVariable<double>(Dims{Dim::Y, Dim::X}, Shape{2, 2},
-                                              Values{4, 5, 6, 7});
-};
-
-TEST_F(AttributesTest, dataset_item_attrs) {
-  Dataset d({{"a", varX}});
-  d["a"].attrs().set(Dim("scalar"), scalar);
-  d["a"].attrs().set(Dim("x"), varX);
-  d.coords().set(Dim("dataset_attr"), scalar);
-
-  ASSERT_FALSE(d.coords().contains(Dim("scalar")));
-  ASSERT_FALSE(d.coords().contains(Dim("x")));
-
-  ASSERT_EQ(d["a"].attrs().size(), 2);
-  ASSERT_TRUE(d["a"].attrs().contains(Dim("scalar")));
-  ASSERT_TRUE(d["a"].attrs().contains(Dim("x")));
-  ASSERT_TRUE(d["a"].coords().contains(Dim("dataset_attr")));
-  ASSERT_FALSE(d["a"].attrs().contains(Dim("dataset_attr")));
-
-  d["a"].attrs().erase(Dim("scalar"));
-  d["a"].attrs().erase(Dim("x"));
-  ASSERT_EQ(d["a"].attrs().size(), 0);
-}
-
-TEST_F(AttributesTest, slice_dataset_item_attrs) {
-  Dataset d({{"a", varZX}});
-  d["a"].attrs().set(Dim("scalar"), scalar);
-  d["a"].attrs().set(Dim("x"), varX);
-
-  // Same behavior as coord slicing:
-  // - Lower-dimensional attrs are not hidden by slicing.
-  // - Non-range slice hides attribute.
-  // The alternative would be to handle attributes like data, but at least for
-  // now coord-like handling appears to make more sense.
-  ASSERT_TRUE(d["a"].slice({Dim::X, 0}).meta().contains(Dim("scalar")));
-  ASSERT_FALSE(d["a"].slice({Dim::X, 0}).coords().contains(Dim("x")));
-  ASSERT_TRUE(d["a"].slice({Dim::X, 0}).attrs().contains(Dim("x")));
-  ASSERT_TRUE(d["a"].slice({Dim::X, 0, 1}).attrs().contains(Dim("scalar")));
-  ASSERT_TRUE(d["a"].slice({Dim::X, 0, 1}).attrs().contains(Dim("x")));
-  ASSERT_TRUE(d["a"].slice({Dim::Y, 0}).attrs().contains(Dim("scalar")));
-  ASSERT_TRUE(d["a"].slice({Dim::Y, 0}).attrs().contains(Dim("x")));
-  ASSERT_TRUE(d["a"].slice({Dim::Y, 0, 1}).attrs().contains(Dim("scalar")));
-  ASSERT_TRUE(d["a"].slice({Dim::Y, 0, 1}).attrs().contains(Dim("x")));
-}
-
-TEST_F(AttributesTest, coords_are_not_transferred_to_attrs_in_slicing) {
-  Dataset d({{"a", copy(varX)}});
-  d.coords().set(Dim::X, copy(varX));
-  ASSERT_TRUE(d.slice({Dim::X, 0})["a"].coords().contains(Dim::X));
-  ASSERT_TRUE(d.slice({Dim::X, 0})["a"].coords()[Dim::X].is_readonly());
-  ASSERT_FALSE(d.slice({Dim::X, 0})["a"].attrs().contains(Dim::X));
-  ASSERT_TRUE(d.slice({Dim::X, 0, 1})["a"].coords().contains(Dim::X));
-  ASSERT_TRUE(d.slice({Dim::X, 0, 1})["a"].coords()[Dim::X].is_readonly());
-  ASSERT_FALSE(d.slice({Dim::X, 0, 1})["a"].attrs().contains(Dim::X));
-}
-
-TEST_F(AttributesTest, binary_ops_matching_attrs_preserved) {
-  Dataset d({{"a", varX}});
-  d["a"].attrs().set(Dim("a_attr"), scalar);
-
-  for (const auto &result : {d + d, d - d, d * d, d / d}) {
-    EXPECT_EQ(result["a"].coords(), d["a"].coords());
-  }
-}
-
-TEST_F(AttributesTest, binary_ops_mismatching_attrs_dropped) {
-  Dataset d1({{"a", varX}});
-  d1["a"].attrs().set(Dim("a_attr"), scalar);
-  Dataset d2({{"a", varX}});
-  d2["a"].attrs().set(Dim("a_attr"), scalar + scalar); // mismatching content
-  d2["a"].attrs().set(Dim("a_attr2"), scalar);         // mismatching name
-
-  for (const auto &result : {d1 + d2, d1 - d2, d1 * d2, d1 / d2}) {
-    EXPECT_TRUE(result["a"].coords().empty());
-  }
-}
-
-TEST_F(AttributesTest, binary_ops_in_place) {
-  Dataset d1({{"a", varX}});
-  d1["a"].attrs().set(Dim("a_attr"), scalar);
-
-  Dataset d2({{"a", varX}});
-  d2["a"].attrs().set(Dim("a_attr"), varX);
-  d2["a"].attrs().set(Dim("a_attr2"), varX);
-
-  auto result(d1);
-
-  auto check_preserved_only_lhs_attrs = [&]() {
-    ASSERT_EQ(result["a"].attrs().size(), 1);
-    EXPECT_EQ(result["a"].attrs()[Dim("a_attr")], scalar);
-  };
-
-  result += d2;
-  check_preserved_only_lhs_attrs();
-  result -= d2;
-  check_preserved_only_lhs_attrs();
-  result *= d2;
-  check_preserved_only_lhs_attrs();
-  result /= d2;
-  check_preserved_only_lhs_attrs();
-}
-
-TEST_F(AttributesTest, reduction_ops) {
-  Dataset d({{"a", makeVariable<double>(Dims{Dim::X}, Shape{2}, units::counts,
-                                        Values{10, 20})}});
-  d.setCoord(Dim::X,
-             makeVariable<double>(Dims{Dim::X}, Shape{3}, Values{0, 1, 2}));
-  d["a"].attrs().set(Dim("a_attr"), scalar);
-  d["a"].attrs().set(Dim("a_attr_x"), varX);
-
-  for (const auto &result :
-       {sum(d, Dim::X), mean(d, Dim::X), resize(d, Dim::X, 4),
-        rebin(d, Dim::X,
-              makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{0, 2}))}) {
-    ASSERT_TRUE(result["a"].attrs().contains(Dim("a_attr")));
-    ASSERT_FALSE(result["a"].attrs().contains(Dim("a_attr_x")));
-    EXPECT_EQ(result["a"].attrs()[Dim("a_attr")], scalar);
-  }
-}
diff --git a/lib/dataset/test/bin_test.cpp b/lib/dataset/test/bin_test.cpp
index 83aaa649c2..245d28f27b 100644
--- a/lib/dataset/test/bin_test.cpp
+++ b/lib/dataset/test/bin_test.cpp
@@ -173,7 +173,6 @@ class BinTest : public ::testing::TestWithParam<DataArray> {
             .value<bool>());
     EXPECT_EQ(a.masks(), b.masks());
     EXPECT_EQ(a.coords(), b.coords());
-    EXPECT_EQ(a.attrs(), b.attrs());
   }
 };
 
@@ -206,65 +205,6 @@ TEST_P(BinTest, rebin_no_event_coord) {
   EXPECT_THROW_DISCARD(bin(x, {edges_x}), except::BinEdgeError);
 }
 
-TEST_P(BinTest, bin_using_attr) {
-  auto table = GetParam();
-  const auto da_coord = bin(table, {edges_x});
-  table.attrs().set(Dim::X, table.coords().extract(Dim::X));
-  const auto da_attr = bin(table, {edges_x});
-  auto da_attr_bins_view = bins_view<DataArray>(da_attr.data());
-  da_attr_bins_view.coords().set(Dim::X,
-                                 da_attr_bins_view.attrs().extract(Dim::X));
-  EXPECT_EQ(da_coord, da_attr);
-}
-
-TEST_P(BinTest, rebin_using_attr) {
-  auto table = GetParam();
-  const auto da_coord = bin(bin(table, {edges_x}), {edges_x_coarse});
-  table.attrs().set(Dim::X, table.coords().extract(Dim::X));
-  const auto da_attr = bin(bin(table, {edges_x}), {edges_x_coarse});
-  auto da_attr_bins_view = bins_view<DataArray>(da_attr.data());
-  da_attr_bins_view.coords().set(Dim::X,
-                                 da_attr_bins_view.attrs().extract(Dim::X));
-  EXPECT_EQ(da_coord, da_attr);
-}
-
-TEST_P(BinTest, rebin_using_attr_in_new_dimension) {
-  const auto z_coord = makeVariable<double>(Dims{Dim::X}, Shape{4},
-                                            Values{-10., -5.0, 0.5, 7.5});
-  const auto edges_z_coarse =
-      makeVariable<double>(Dims{Dim::Z}, Shape{3}, Values{-11., 0.0, 8.0});
-  const auto table = GetParam();
-  auto da_coord = bin(table, {edges_x});
-  auto da_attr = bin(table, {edges_x});
-  da_coord.coords().set(Dim::Z, z_coord);
-  da_attr.attrs().set(Dim::Z, z_coord);
-  const auto out_coord = bin(da_coord, {edges_z_coarse});
-  const auto out_attr = bin(da_attr, {edges_z_coarse});
-  EXPECT_EQ(out_coord, out_attr);
-}
-
-TEST_P(BinTest, rebin_existing_binning_attr_and_event_coord) {
-  auto table = GetParam();
-  const auto da_coord = bin(bin(table, {edges_x}), {edges_x_coarse});
-  auto da_attr_temp = bin(table, {edges_x});
-  da_attr_temp.attrs().set(Dim::X, da_attr_temp.coords().extract(Dim::X));
-  const auto da_attr = bin(da_attr_temp, {edges_x_coarse});
-  EXPECT_EQ(da_coord, da_attr);
-}
-
-TEST_P(BinTest, rebin_existing_binning_attr_and_event_attr) {
-  auto table = GetParam();
-  const auto da_coord = bin(bin(table, {edges_x}), {edges_x_coarse});
-  table.attrs().set(Dim::X, table.coords().extract(Dim::X));
-  auto da_attr_temp = bin(table, {edges_x});
-  da_attr_temp.attrs().set(Dim::X, da_attr_temp.coords().extract(Dim::X));
-  const auto da_attr = bin(da_attr_temp, {edges_x_coarse});
-  auto da_attr_bins_view = bins_view<DataArray>(da_attr.data());
-  da_attr_bins_view.coords().set(Dim::X,
-                                 da_attr_bins_view.attrs().extract(Dim::X));
-  EXPECT_EQ(da_coord, da_attr);
-}
-
 TEST_P(BinTest, rebin_coarse_to_fine_1d) {
   const auto table = GetParam();
   EXPECT_EQ(bin(table, {edges_x}),
@@ -362,19 +302,6 @@ TEST_P(BinTest, rebin_2d_with_2d_coord) {
             bin(xy, {edges_y_coarse}));
 }
 
-TEST_P(BinTest, rebin_2d_with_2d_attr) {
-  auto table = GetParam();
-  table.attrs().set(Dim::Y, table.coords().extract(Dim::Y));
-  auto xy = bin(table, {edges_x_coarse, edges_y_coarse});
-  Variable edges_y_2d = makeVariable<double>(Dims{Dim::X, Dim::Y}, Shape{2, 3},
-                                             Values{-2, 1, 2, -3, 0, 3});
-  xy.coords().erase(Dim::Y);
-  xy.attrs().set(Dim::Y, edges_y_2d);
-  bins_view<DataArray>(xy.data()).attrs()[Dim::Y] += 0.5 * units::one;
-  EXPECT_THROW(bin(xy, {edges_x_coarse}), except::DimensionError);
-  EXPECT_NO_THROW(bin(xy, {edges_x_coarse, edges_y_coarse}));
-}
-
 TEST_P(BinTest, rebin_coarse_to_fine_2d) {
   const auto table = GetParam();
   const auto xy_coarse = bin(table, {edges_x_coarse, edges_y_coarse});
@@ -478,7 +405,6 @@ TEST_P(BinTest, rebinned_meta_data_dropped) {
   xy1.masks().set("x", mask_x);
   xy1.coords().set(Dim("aux1"), mask_x);
   xy1.coords().set(Dim("aux1-edge"), edges_x_coarse);
-  xy1.attrs().set(Dim("aux2"), mask_x);
   expect_near(bin(xy1, {edges_x_coarse2, edges_y_coarse2}), xy2);
 }
 
diff --git a/lib/dataset/test/binned_arithmetic_test.cpp b/lib/dataset/test/binned_arithmetic_test.cpp
index fc249cfc69..667b83be2d 100644
--- a/lib/dataset/test/binned_arithmetic_test.cpp
+++ b/lib/dataset/test/binned_arithmetic_test.cpp
@@ -62,8 +62,7 @@ TEST_F(BinnedArithmeticTest, fail_array_and_array) {
   const auto binned = make_bins(indices, Dim::Event, array);
   // In principle the operation could be allowed in this case since the coords
   // match, but at this point our implementation is not sophisticated enough to
-  // support coord, mask, and attr handling for binned data in such binary
-  // operations.
+  // support coord and mask handling for binned data in such binary operations.
   EXPECT_THROW_DISCARD(binned + binned, except::BinnedDataError);
 }
 
diff --git a/lib/dataset/test/binned_creation_test.cpp b/lib/dataset/test/binned_creation_test.cpp
index ca7b07cd06..2648334368 100644
--- a/lib/dataset/test/binned_creation_test.cpp
+++ b/lib/dataset/test/binned_creation_test.cpp
@@ -14,8 +14,7 @@ class BinnedCreationTest : public ::testing::Test {
       Dims{Dim::X}, Shape{2}, Values{std::pair{0, 2}, std::pair{2, 5}});
   Variable m_data = makeVariable<double>(Dims{Dim::Event}, Shape{5}, units::m,
                                          Values{1, 2, 3, 4, 5});
-  DataArray m_buffer = DataArray(m_data, {{Dim::X, m_data}}, {{"mask", m_data}},
-                                 {{Dim("attr"), 1.2 * units::m}});
+  DataArray m_buffer = DataArray(m_data, {{Dim::X, m_data}}, {{"mask", m_data}});
   Variable m_var = make_bins(m_indices, Dim::Event, m_buffer);
 
   void check(const Variable &var) const {
@@ -23,7 +22,6 @@ class BinnedCreationTest : public ::testing::Test {
     static_cast<void>(indices);
     static_cast<void>(dim);
     EXPECT_EQ(buf.unit(), units::m);
-    EXPECT_EQ(buf.attrs(), m_buffer.attrs()); // scalar, so copied, not resized
     EXPECT_TRUE(buf.masks().contains("mask"));
     EXPECT_TRUE(buf.coords().contains(Dim::X));
   }
diff --git a/lib/dataset/test/bins_test.cpp b/lib/dataset/test/bins_test.cpp
index 7894821362..ede18356f2 100644
--- a/lib/dataset/test/bins_test.cpp
+++ b/lib/dataset/test/bins_test.cpp
@@ -213,7 +213,7 @@ class DataArrayBinsMapTest : public ::testing::Test {
 };
 
 TEST_F(DataArrayBinsMapTest, map) {
-  const auto &coord = bins_view<DataArray>(buckets).meta()[Dim::Z];
+  const auto &coord = bins_view<DataArray>(buckets).coords()[Dim::Z];
   auto fill_value = makeVariable<double>(units::K, Values{1234});
   const auto out = buckets::map(histogram, coord, Dim::Z, fill_value);
   // event coords 1,2,3,4
@@ -241,14 +241,14 @@ TEST_F(DataArrayBinsMapTest, map) {
 }
 
 TEST_F(DataArrayBinsMapTest, fail_no_bin_edges) {
-  const auto &coord = bins_view<DataArray>(buckets).meta()[Dim::Z];
+  const auto &coord = bins_view<DataArray>(buckets).coords()[Dim::Z];
   histogram.coords().set(Dim::Z, bin_edges.slice({Dim::Z, 1, 4}));
   EXPECT_THROW_DISCARD(buckets::map(histogram, coord, Dim::Z),
                        except::BinEdgeError);
 }
 
 TEST_F(DataArrayBinsMapTest, map_masked_values_replaced_by_fill_value) {
-  const auto &coord = bins_view<DataArray>(buckets).meta()[Dim::Z];
+  const auto &coord = bins_view<DataArray>(buckets).coords()[Dim::Z];
   histogram.masks().set(
       "mask", makeVariable<bool>(histogram.dims(), Values{false, true, false}));
   const auto fill_value = makeVariable<double>(units::K, Values{1234});
@@ -482,10 +482,6 @@ TEST_F(DatasetBinsTest, concatenate) {
   check_fail(buffer0, buffer1);
   buffer1["a"].masks().set("mask", column);
   check(buffer0, buffer1);
-  buffer0["b"].attrs().set(Dim("attr"), column);
-  check_fail(buffer0, buffer1);
-  buffer1["b"].attrs().set(Dim("attr"), column);
-  check(buffer0, buffer1);
   buffer0.coords().set(Dim("scalar"), 1.0 * units::m);
   check_fail(buffer0, buffer1);
   buffer1.coords().set(Dim("scalar"), 1.0 * units::m);
diff --git a/lib/dataset/test/bins_view_test.cpp b/lib/dataset/test/bins_view_test.cpp
index 0b13b0da51..03a533a0fa 100644
--- a/lib/dataset/test/bins_view_test.cpp
+++ b/lib/dataset/test/bins_view_test.cpp
@@ -48,8 +48,6 @@ TEST_F(BinsViewTest, DISABLED_slice_readonly) {
   // EXPECT_TRUE(view.is_readonly());
   // EXPECT_TRUE(view.coords().is_readonly());
   // EXPECT_TRUE(view.masks().is_readonly());
-  // EXPECT_TRUE(view.attrs().is_readonly());
-  // EXPECT_TRUE(view.meta().is_readonly());
   EXPECT_FALSE(view.data().is_readonly());
   EXPECT_FALSE(view.coords()[Dim::X].is_readonly());
   const auto copied(view);
@@ -59,8 +57,6 @@ TEST_F(BinsViewTest, DISABLED_slice_readonly) {
   // EXPECT_TRUE(view.is_readonly());
   // EXPECT_TRUE(view.coords().is_readonly());
   // EXPECT_TRUE(view.masks().is_readonly());
-  // EXPECT_TRUE(view.attrs().is_readonly());
-  // EXPECT_TRUE(view.meta().is_readonly());
   EXPECT_FALSE(copied.data().is_readonly());
   EXPECT_FALSE(copied.coords()[Dim::X].is_readonly());
 }
diff --git a/lib/dataset/test/concat_test.cpp b/lib/dataset/test/concat_test.cpp
index 2b9255e265..ae520acf3e 100644
--- a/lib/dataset/test/concat_test.cpp
+++ b/lib/dataset/test/concat_test.cpp
@@ -30,15 +30,9 @@ class Concatenate1DTest : public ::testing::Test {
             makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{14, 15, 16})}},
           {{Dim::X,
             makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{4, 5, 6})}}) {
-    a["data_1"].attrs().set(
-        Dim("label_1"),
-        makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{21, 22, 23}));
     a["data_1"].masks().set(
         "mask_1",
         makeVariable<bool>(Dims{Dim::X}, Shape{3}, Values{false, true, false}));
-    b["data_1"].attrs().set(
-        Dim("label_1"),
-        makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{24, 25, 26}));
     b["data_1"].masks().set(
         "mask_1",
         makeVariable<bool>(Dims{Dim::X}, Shape{3}, Values{false, true, false}));
@@ -56,9 +50,6 @@ TEST_F(Concatenate1DTest, simple_1d) {
   EXPECT_EQ(d["data_1"].data(),
             makeVariable<int>(Dims{Dim::X}, Shape{6},
                               Values{11, 12, 13, 14, 15, 16}));
-  EXPECT_EQ(d["data_1"].attrs()[Dim("label_1")],
-            makeVariable<int>(Dims{Dim::X}, Shape{6},
-                              Values{21, 22, 23, 24, 25, 26}));
   EXPECT_EQ(d["data_1"].masks()["mask_1"],
             makeVariable<bool>(Dims{Dim::X}, Shape{6},
                                Values{false, true, false, false, true, false}));
@@ -157,20 +148,8 @@ class Concatenate1DHistogramTest : public ::testing::Test {
             makeVariable<int>(Dims{Dim::X}, Shape{2}, Values{13, 14})}},
           {{Dim::X,
             makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{3, 4, 5})}}) {
-    a["data_1"].attrs().set(
-        Dim("edge_labels"),
-        makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{21, 22, 23}));
-    a["data_1"].attrs().set(
-        Dim("labels"),
-        makeVariable<int>(Dims{Dim::X}, Shape{2}, Values{21, 22}));
     a["data_1"].masks().set("masks", makeVariable<bool>(Dims{Dim::X}, Shape{2},
                                                         Values{false, true}));
-    b["data_1"].attrs().set(
-        Dim("edge_labels"),
-        makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{23, 24, 25}));
-    b["data_1"].attrs().set(
-        Dim("labels"),
-        makeVariable<int>(Dims{Dim::X}, Shape{2}, Values{24, 25}));
     b["data_1"].masks().set("masks", makeVariable<bool>(Dims{Dim::X}, Shape{2},
                                                         Values{false, true}));
   }
@@ -184,12 +163,6 @@ TEST_F(Concatenate1DHistogramTest, simple_1d) {
                                                  Values{11, 12, 13, 14})}},
                    {{Dim::X, makeVariable<int>(Dims{Dim::X}, Shape{5},
                                                Values{1, 2, 3, 4, 5})}});
-  expected["data_1"].attrs().set(
-      Dim("edge_labels"),
-      makeVariable<int>(Dims{Dim::X}, Shape{5}, Values{21, 22, 23, 24, 25}));
-  expected["data_1"].attrs().set(
-      Dim("labels"),
-      makeVariable<int>(Dims{Dim::X}, Shape{4}, Values{21, 22, 24, 25}));
   expected["data_1"].masks().set(
       "masks", makeVariable<bool>(Dims{Dim::X}, Shape{4},
                                   Values{false, true, false, true}));
@@ -455,8 +428,6 @@ TEST_F(ConcatenateBinnedTest, mismatching_buffer) {
        {buffer * (1.0 * units::m),
         DataArray(data, {{Dim::X, data + data}}, {{"mask", 1.0 * units::one}},
                   {}),
-        DataArray(data, {{Dim::X, data + data}}, {},
-                  {{Dim("attr"), 1.0 * units::one}}),
         DataArray(data, {{Dim::Y, data + data}, {Dim::X, data + data}}),
         DataArray(data, {})}) {
     auto var2 = make_bins(indices, Dim::Event, buffer2);
diff --git a/lib/dataset/test/copy_test.cpp b/lib/dataset/test/copy_test.cpp
index e9ef018c65..6ceca77021 100644
--- a/lib/dataset/test/copy_test.cpp
+++ b/lib/dataset/test/copy_test.cpp
@@ -12,15 +12,12 @@ using namespace scipp::dataset;
 
 struct CopyTest : public ::testing::Test {
   CopyTest() : dataset(factory.make("data")), array(copy(dataset["data"])) {
-    array.attrs().set(Dim("attr"), attr);
-    dataset["data"].attrs().set(Dim("attr"), attr);
   }
 
 protected:
   DatasetFactory factory;
   Dataset dataset;
   DataArray array;
-  Variable attr = makeVariable<double>(Values{1});
 };
 TEST_F(CopyTest, data_array) { EXPECT_EQ(copy(array), array); }
 TEST_F(CopyTest, dataset) { EXPECT_EQ(copy(dataset), dataset); }
@@ -44,20 +41,6 @@ TEST_F(CopyTest, dataset_with_bin_edge_coord) {
   }
 }
 
-TEST_F(CopyTest, data_array_drop_attrs) {
-  auto copied = copy(array, AttrPolicy::Drop);
-  EXPECT_NE(copied, array);
-  copied.attrs().set(Dim("attr"), attr);
-  EXPECT_EQ(copied, array);
-}
-
-TEST_F(CopyTest, dataset_drop_attrs) {
-  auto copied = copy(dataset, AttrPolicy::Drop);
-  EXPECT_NE(copied, dataset);
-  copied["data"].attrs().set(Dim("attr"), attr);
-  EXPECT_EQ(copied, dataset);
-}
-
 struct CopyOutArgTest : public CopyTest {
   CopyOutArgTest() : dataset_copy(copy(dataset)), array_copy(copy(array)) {
     const auto one = 1.0 * units::one;
@@ -65,10 +48,8 @@ struct CopyOutArgTest : public CopyTest {
     array_copy.coords()[Dim::X] += one;
     array_copy.coords()[Dim::Y] += one;
     copy(~array_copy.masks()["mask"], array_copy.masks()["mask"]);
-    array_copy.attrs()[Dim("attr")] += one;
     EXPECT_NE(array_copy, array);
     dataset_copy["data"].data() += one;
-    dataset_copy["data"].attrs()[Dim("attr")] += one;
     dataset_copy.coords()[Dim::X] += one;
     dataset_copy.coords()[Dim::Y] += one;
     copy(~array_copy.masks()["mask"], dataset_copy["data"].masks()["mask"]);
@@ -81,47 +62,13 @@ struct CopyOutArgTest : public CopyTest {
 };
 
 TEST_F(CopyOutArgTest, data_array_out_arg) {
-  // copy with out arg also copies coords, masks, and attrs
+  // copy with out arg also copies coords and masks
   EXPECT_EQ(copy(array, array_copy), array);
   EXPECT_EQ(array_copy, array);
 }
 
 TEST_F(CopyOutArgTest, dataset_out_arg) {
-  // copy with out arg also copies coords, masks, and attrs
+  // copy with out arg also copies coords and masks
   EXPECT_EQ(copy(dataset, dataset_copy), dataset);
   EXPECT_EQ(dataset_copy, dataset);
 }
-
-TEST_F(CopyOutArgTest, data_array_out_arg_drop_attrs) {
-  copy(array.attrs()[Dim("attr")], array_copy.attrs()[Dim("attr")]);
-  // copy with out arg also copies coords, masks, and attrs
-  EXPECT_EQ(copy(array, array_copy, AttrPolicy::Drop), array);
-  EXPECT_EQ(array_copy, array);
-}
-
-TEST_F(CopyOutArgTest, dataset_out_arg_drop_attrs) {
-  copy(dataset["data"].attrs()[Dim("attr")],
-       dataset_copy["data"].attrs()[Dim("attr")]);
-  // copy with out arg also copies coords, masks, and attrs
-  EXPECT_EQ(copy(dataset, dataset_copy, AttrPolicy::Drop), dataset);
-  EXPECT_EQ(dataset_copy, dataset);
-}
-
-TEST_F(CopyOutArgTest, data_array_out_arg_drop_attrs_untouched) {
-  // copy with out arg leaves items in output that are not in the input
-  // untouched. This also applies to dropped attributes.
-  EXPECT_NE(copy(array, array_copy, AttrPolicy::Drop), array);
-  EXPECT_NE(array_copy, array);
-  copy(array.attrs()[Dim("attr")], array_copy.attrs()[Dim("attr")]);
-  EXPECT_EQ(array_copy, array);
-}
-
-TEST_F(CopyOutArgTest, dataset_out_arg_drop_attrs_untouched) {
-  // copy with out arg leaves items in output that are not in the input
-  // untouched. This also applies to dropped attributes.
-  EXPECT_NE(copy(dataset, dataset_copy, AttrPolicy::Drop), dataset);
-  EXPECT_NE(dataset_copy, dataset);
-  copy(dataset["data"].attrs()[Dim("attr")],
-       dataset_copy["data"].attrs()[Dim("attr")]);
-  EXPECT_EQ(dataset_copy, dataset);
-}
diff --git a/lib/dataset/test/data_array_comparison_test.cpp b/lib/dataset/test/data_array_comparison_test.cpp
index 09391a53a8..5f7b819f58 100644
--- a/lib/dataset/test/data_array_comparison_test.cpp
+++ b/lib/dataset/test/data_array_comparison_test.cpp
@@ -89,16 +89,6 @@ auto make_1_mask(const std::string &name, const Dimensions &dims,
   return a;
 }
 
-template <class T, class T2>
-auto make_1_attr(const std::string &name, const Dimensions &dims,
-                 const units::Unit unit,
-                 const std::initializer_list<T2> &data) {
-  auto a = make_values<T>(dims);
-  a.attrs().set(Dim(name), makeVariable<T>(Dimensions(dims), units::Unit(unit),
-                                           Values(data)));
-  return a;
-}
-
 template <class T, class T2>
 auto make_values(const std::string &name, const Dimensions &dims,
                  const units::Unit unit,
@@ -165,18 +155,6 @@ TEST_F(DataArray_comparison_operators, single_mask) {
       a, make_1_mask<bool>("a", {Dim::X, 3}, units::m, {false, false, false}));
 }
 
-TEST_F(DataArray_comparison_operators, single_attr) {
-  auto a = make_1_attr<double>("a", {Dim::X, 3}, units::m, {1, 2, 3});
-  expect_eq(a, a);
-  expect_ne(a, make_values<double>({Dim::X, 3}));
-  expect_ne(a, make_1_attr<float>("a", {Dim::X, 3}, units::m, {1, 2, 3}));
-  expect_ne(a, make_1_attr<double>("b", {Dim::X, 3}, units::m, {1, 2, 3}));
-  expect_ne(a, make_1_attr<double>("a", {Dim::Y, 3}, units::m, {1, 2, 3}));
-  expect_ne(a, make_1_attr<double>("a", {Dim::X, 2}, units::m, {1, 2}));
-  expect_ne(a, make_1_attr<double>("a", {Dim::X, 3}, units::s, {1, 2, 3}));
-  expect_ne(a, make_1_attr<double>("a", {Dim::X, 3}, units::m, {1, 2, 4}));
-}
-
 TEST_F(DataArray_comparison_operators, single_values) {
   auto a = make_values<double>("a", {Dim::X, 3}, units::m, {1, 2, 3});
   expect_eq(a, a);
@@ -231,12 +209,6 @@ TEST_F(DataArray_comparison_operators, extra_mask) {
   expect_ne(extra, da);
 }
 
-TEST_F(DataArray_comparison_operators, extra_attr) {
-  auto extra = da;
-  extra.attrs().set(Dim("extra"), makeVariable<double>(Values{0.0}));
-  expect_ne(extra, da);
-}
-
 TEST_F(DataArray_comparison_operators, extra_variance) {
   auto extra = copy(da);
   da.data().setVariances(makeVariable<double>(da.dims()));
@@ -254,17 +226,6 @@ TEST_F(DataArray_comparison_operators, different_coord_insertion_order) {
   expect_eq(a, b);
 }
 
-TEST_F(DataArray_comparison_operators, different_attr_insertion_order) {
-  const auto var = makeVariable<double>(Dims{Dim::X, Dim::Y}, Shape{3, 4});
-  auto a = DataArray(var);
-  auto b = DataArray(var);
-  a.attrs().set(Dim::X, da.coords()[Dim::X]);
-  a.attrs().set(Dim::Y, da.coords()[Dim::Y]);
-  b.attrs().set(Dim::Y, da.coords()[Dim::Y]);
-  b.attrs().set(Dim::X, da.coords()[Dim::X]);
-  expect_eq(a, b);
-}
-
 TEST_F(DataArray_comparison_operators, respects_coord_alignment) {
   auto a = da;
   auto b = da;
diff --git a/lib/dataset/test/data_array_test.cpp b/lib/dataset/test/data_array_test.cpp
index 1db1ac1497..435ae37814 100644
--- a/lib/dataset/test/data_array_test.cpp
+++ b/lib/dataset/test/data_array_test.cpp
@@ -15,43 +15,36 @@ class DataArrayTest : public ::testing::Test {
   Variable data = makeVariable<double>(Values{1});
   Variable coord = makeVariable<double>(Values{2});
   Variable mask = makeVariable<bool>(Values{false});
-  Variable attr = makeVariable<double>(Values{3});
 };
 
 TEST_F(DataArrayTest, constructor_shares) {
-  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}}, {{Dim("attr"), attr}});
+  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}});
   EXPECT_TRUE(a.data().is_same(data));
   EXPECT_TRUE(a.coords()[Dim::X].is_same(coord));
   EXPECT_TRUE(a.masks()["mask"].is_same(mask));
-  EXPECT_TRUE(a.attrs()[Dim("attr")].is_same(attr));
 }
 
 TEST_F(DataArrayTest, copy_shares) {
-  const DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}},
-                    {{Dim("attr"), attr}});
+  const DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}});
   const DataArray b(a);
   EXPECT_TRUE(a.data().is_same(b.data()));
   EXPECT_TRUE(a.coords()[Dim::X].is_same(b.coords()[Dim::X]));
   EXPECT_TRUE(a.masks()["mask"].is_same(b.masks()["mask"]));
-  EXPECT_TRUE(a.attrs()[Dim("attr")].is_same(b.attrs()[Dim("attr")]));
   // Meta data may be shallow-copied but dicts are not shared
   EXPECT_NE(&a.coords(), &b.coords());
   EXPECT_NE(&a.masks(), &b.masks());
-  EXPECT_NE(&a.attrs(), &b.attrs());
 }
 
 TEST_F(DataArrayTest, copy_assign_shares) {
-  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}}, {{Dim("attr"), attr}});
+  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}});
   DataArray b{coord};
   b = a;
   EXPECT_TRUE(a.data().is_same(b.data()));
   EXPECT_TRUE(a.coords()[Dim::X].is_same(b.coords()[Dim::X]));
   EXPECT_TRUE(a.masks()["mask"].is_same(b.masks()["mask"]));
-  EXPECT_TRUE(a.attrs()[Dim("attr")].is_same(b.attrs()[Dim("attr")]));
   // Meta data may be shallow-copied but dicts are not shared
   EXPECT_NE(&a.coords(), &b.coords());
   EXPECT_NE(&a.masks(), &b.masks());
-  EXPECT_NE(&a.attrs(), &b.attrs());
 }
 
 TEST_F(DataArrayTest, construct_fail) {
@@ -70,83 +63,47 @@ TEST_F(DataArrayTest, get_coord) {
   DataArray a(data);
   a.coords().set(Dim::X, coord);
   EXPECT_EQ(a.coords().at(Dim::X), coord);
-  EXPECT_THROW_DISCARD(a.attrs().at(Dim::X), except::NotFoundError);
   EXPECT_THROW_DISCARD(a.coords().at(Dim::Y), except::NotFoundError);
 }
 
 TEST_F(DataArrayTest, erase_coord) {
   DataArray a(data);
   a.coords().set(Dim::X, coord);
-  EXPECT_THROW(a.attrs().erase(Dim::X), except::NotFoundError);
   EXPECT_NO_THROW(a.coords().erase(Dim::X));
-  a.attrs().set(Dim::X, attr);
-  EXPECT_NO_THROW(a.attrs().erase(Dim::X));
-  a.attrs().set(Dim::X, attr);
   EXPECT_THROW(a.coords().erase(Dim::X), except::NotFoundError);
 }
 
-TEST_F(DataArrayTest, shadow_attr) {
-  const auto var1 = 1.0 * units::m;
-  const auto var2 = 2.0 * units::m;
-  DataArray a(0.0 * units::m);
-  a.coords().set(Dim::X, var1);
-  a.attrs().set(Dim::X, var2);
-  EXPECT_EQ(a.coords()[Dim::X], var1);
-  EXPECT_EQ(a.attrs()[Dim::X], var2);
-  EXPECT_THROW_DISCARD(a.meta(), except::DataArrayError);
-  a.attrs().erase(Dim::X);
-  EXPECT_EQ(a.meta()[Dim::X], var1);
-}
-
-TEST_F(DataArrayTest, mutate_via_meta_throws) {
-  DataArray da(data);
-  da.coords().set(Dim::X, coord);
-  const auto original = copy(da);
-  EXPECT_THROW(da.meta().erase(Dim::X), except::DataArrayError);
-  EXPECT_EQ(da, original);
-  EXPECT_THROW_DISCARD(da.meta().extract(Dim::X), except::DataArrayError);
-  EXPECT_EQ(da, original);
-  EXPECT_THROW(da.meta().set(Dim::Y, coord), except::DataArrayError);
-  EXPECT_EQ(da, original);
-}
-
 TEST_F(DataArrayTest, view) {
   const auto var = makeVariable<double>(Values{1});
-  const DataArray a(copy(var), {{Dim::X, copy(var)}}, {{"mask", copy(var)}},
-                    {{Dim("attr"), copy(var)}});
+  const DataArray a(copy(var), {{Dim::X, copy(var)}}, {{"mask", copy(var)}});
   const auto b = a.view();
   EXPECT_EQ(a, b);
   EXPECT_EQ(&a.data(), &b.data());
   EXPECT_EQ(&a.coords(), &b.coords());
   EXPECT_EQ(&a.masks(), &b.masks());
-  EXPECT_EQ(&a.attrs(), &b.attrs());
   EXPECT_EQ(a.name(), b.name());
 }
 
 TEST_F(DataArrayTest, as_const) {
   const auto var = makeVariable<double>(Values{1});
-  const DataArray a(copy(var), {{Dim::X, copy(var)}}, {{"mask", copy(var)}},
-                    {{Dim("attr"), copy(var)}});
+  const DataArray a(copy(var), {{Dim::X, copy(var)}}, {{"mask", copy(var)}});
   EXPECT_FALSE(var.is_readonly());
   const auto b = a.as_const();
   EXPECT_EQ(a, b);
   EXPECT_TRUE(b.is_readonly());
   EXPECT_TRUE(b.coords().is_readonly());
   EXPECT_TRUE(b.masks().is_readonly());
-  EXPECT_TRUE(b.attrs().is_readonly());
   EXPECT_TRUE(b.coords()[Dim::X].is_readonly());
   EXPECT_TRUE(b.masks()["mask"].is_readonly());
-  EXPECT_TRUE(b.attrs()[Dim("attr")].is_readonly());
   EXPECT_EQ(a.name(), b.name());
 }
 
 TEST_F(DataArrayTest, full_slice) {
-  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}}, {{Dim("attr"), attr}});
+  DataArray a(data, {{Dim::X, coord}}, {{"mask", mask}});
   const auto slice = a.slice({});
   EXPECT_TRUE(slice.data().is_same(a.data()));
   EXPECT_TRUE(slice.coords()[Dim::X].is_same(a.coords()[Dim::X]));
   EXPECT_TRUE(slice.masks()["mask"].is_same(a.masks()["mask"]));
-  EXPECT_TRUE(slice.attrs()[Dim("attr")].is_same(a.attrs()[Dim("attr")]));
 }
 
 TEST_F(DataArrayTest, self_nesting) {
@@ -168,12 +125,6 @@ TEST_F(DataArrayTest, self_nesting) {
   nested_in_coord.masks().set("mask", var);
   ASSERT_THROW_DISCARD(var.value<DataArray>() = nested_in_coord,
                        std::invalid_argument);
-
-  DataArray nested_in_attr{
-      makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{3, 4})};
-  nested_in_coord.attrs().set(Dim::X, var);
-  ASSERT_THROW_DISCARD(var.value<DataArray>() = nested_in_coord,
-                       std::invalid_argument);
 }
 
 TEST_F(DataArrayTest, is_edges_1d_without_edges) {
@@ -243,11 +194,9 @@ DataArray make_drop_example_data_arrays() {
   Variable data = makeVariable<double>(Values{1});
   Variable coord = makeVariable<double>(Values{2});
   Variable mask = makeVariable<bool>(Values{false});
-  Variable attr = makeVariable<double>(Values{3});
   return DataArray(
       data, {{Dim{"dim0"}, coord}, {Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr0"}, attr}, {Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}});
+      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}});
 }
 
 TEST_F(DataArrayTest, drop_single_coord) {
@@ -256,8 +205,7 @@ TEST_F(DataArrayTest, drop_single_coord) {
   const DataArray expected_da{
       data,
       {{Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr0"}, attr}, {Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}}};
+      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}}};
   ASSERT_EQ(new_da, expected_da);
 }
 
@@ -267,8 +215,7 @@ TEST_F(DataArrayTest, drop_multiple_coords) {
   const DataArray expected_da{
       data,
       {{Dim{"dim0"}, coord}},
-      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr0"}, attr}, {Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}}};
+      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}}};
   ASSERT_EQ(new_da, expected_da);
 }
 
@@ -278,8 +225,7 @@ TEST_F(DataArrayTest, drop_single_mask) {
   const DataArray expected_da{
       data,
       {{Dim{"dim0"}, coord}, {Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr0"}, attr}, {Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}}};
+      {{"mask1", mask}, {"mask2", mask}}};
   ASSERT_EQ(new_da, expected_da);
 }
 
@@ -289,29 +235,6 @@ TEST_F(DataArrayTest, drop_multiple_mask) {
   const DataArray expected_da{
       data,
       {{Dim{"dim0"}, coord}, {Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask0", mask}},
-      {{Dim{"attr0"}, attr}, {Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}}};
-  ASSERT_EQ(new_da, expected_da);
-}
-
-TEST_F(DataArrayTest, drop_single_attrs) {
-  const DataArray da = make_drop_example_data_arrays();
-  auto new_da = da.drop_attrs(std::vector{Dim{"attr0"}});
-  const DataArray expected_da{
-      data,
-      {{Dim{"dim0"}, coord}, {Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr1"}, attr}, {Dim{"attr2"}, attr}}};
-  ASSERT_EQ(new_da, expected_da);
-}
-
-TEST_F(DataArrayTest, drop_multiple_attrs) {
-  const DataArray da = make_drop_example_data_arrays();
-  auto new_da = da.drop_attrs(std::vector{Dim{"attr1"}, Dim{"attr2"}});
-  const DataArray expected_da{
-      data,
-      {{Dim{"dim0"}, coord}, {Dim{"dim1"}, coord}, {Dim{"dim2"}, coord}},
-      {{"mask0", mask}, {"mask1", mask}, {"mask2", mask}},
-      {{Dim{"attr0"}, attr}}};
+      {{"mask0", mask}}};
   ASSERT_EQ(new_da, expected_da);
 }
diff --git a/lib/dataset/test/dataset_arithmetic_test.cpp b/lib/dataset/test/dataset_arithmetic_test.cpp
index 7bf62a9b49..1aee341152 100644
--- a/lib/dataset/test/dataset_arithmetic_test.cpp
+++ b/lib/dataset/test/dataset_arithmetic_test.cpp
@@ -736,7 +736,7 @@ TEST(DatasetInPlaceStrongExceptionGuarantee, events) {
                            Values{1, 2, 3, 4}, Variances{5, 6, 7, 8});
   Variable good = make_bins(indicesGood, Dim::Event, table);
   Variable bad = make_bins(indicesBad, Dim::Event, table);
-  DataArray good_array(good, {}, {});
+  DataArray good_array(good);
   Dataset good_dataset({{"a", good}, {"b", good}});
 
   // We have no control over the iteration order in the implementation of binary
diff --git a/lib/dataset/test/dataset_test.cpp b/lib/dataset/test/dataset_test.cpp
index b0400f49a2..1c97ab5047 100644
--- a/lib/dataset/test/dataset_test.cpp
+++ b/lib/dataset/test/dataset_test.cpp
@@ -447,8 +447,6 @@ void check_array_shared(Dataset &ds, const std::string &name,
   EXPECT_EQ(ds[name].coords()[Dim::X].is_same(array.coords()[Dim::X]),
             shared_coord);
   EXPECT_TRUE(ds[name].masks()["mask"].is_same(array.masks()["mask"]));
-  EXPECT_TRUE(
-      ds[name].attrs()[Dim("attr")].is_same(array.attrs()[Dim("attr")]));
   // Metadata *dicts* are not shared
   ds.coords().erase(Dim::X);
   EXPECT_NE(ds[name].coords(), array.coords());
@@ -456,9 +454,6 @@ void check_array_shared(Dataset &ds, const std::string &name,
   ds[name].masks().erase("mask");
   EXPECT_NE(ds[name].masks(), array.masks());
   EXPECT_TRUE(array.masks().contains("mask"));
-  ds[name].attrs().erase(Dim("attr"));
-  EXPECT_NE(ds[name].attrs(), array.attrs());
-  EXPECT_TRUE(array.attrs().contains(Dim("attr")));
 }
 
 TEST(DatasetTest, setData_from_DataArray) {
@@ -531,26 +526,6 @@ TEST(DatasetTest, setData_sets_sizes) {
   ASSERT_EQ(d.coords()[Dim::X], x);
 }
 
-TEST(DatasetTest, setData_clears_attributes) {
-  const auto var = makeVariable<double>(Values{1});
-  Dataset d({{"x", var}});
-  d["x"].attrs().set(Dim("attr"), var);
-
-  EXPECT_TRUE(d["x"].attrs().contains(Dim("attr")));
-  d.setData("x", var);
-  EXPECT_FALSE(d["x"].attrs().contains(Dim("attr")));
-}
-
-TEST(DatasetTest, setData_keep_attributes) {
-  const auto var = makeVariable<double>(Values{1});
-  Dataset d({{"x", var}});
-  d["x"].attrs().set(Dim("attr"), var);
-
-  EXPECT_TRUE(d["x"].attrs().contains(Dim("attr")));
-  d.setData("x", var, AttrPolicy::Keep);
-  EXPECT_TRUE(d["x"].attrs().contains(Dim("attr")));
-}
-
 TEST(DatasetTest, setData_with_mismatched_dims) {
   scipp::index expected_size = 2;
   const auto original =
@@ -725,16 +700,6 @@ TEST(DatasetTest, item_coord_cannot_change_coord) {
   ASSERT_EQ(ds.coords()[Dim::X], original);
 }
 
-TEST(DatasetTest, set_erase_item_attr) {
-  DatasetFactory factory;
-  auto ds = factory.make("data");
-  const auto attr = makeVariable<double>(Values{1.0});
-  ds["data"].attrs().set(Dim("item-attr"), attr);
-  EXPECT_TRUE(ds["data"].attrs().contains(Dim("item-attr")));
-  ds["data"].attrs().erase(Dim("item-attr"));
-  EXPECT_FALSE(ds["data"].attrs().contains(Dim("item-attr")));
-}
-
 TEST(DatasetTest, set_erase_item_mask) {
   DatasetFactory factory;
   auto ds = factory.make("data");
@@ -802,13 +767,6 @@ TEST_F(DatasetRenameTest, fail_duplicate_in_edge_dim_of_coord) {
   ASSERT_THROW(ds.rename_dims({{Dim::X, dim}}), except::DimensionError);
 }
 
-TEST_F(DatasetRenameTest, fail_duplicate_in_edge_dim_of_item_attr) {
-  auto ds = copy(d);
-  const Dim dim{"edge"};
-  ds["data_xy"].attrs().set(dim, makeVariable<double>(Dims{dim}, Shape{2}));
-  ASSERT_THROW(ds.rename_dims({{Dim::X, dim}}), except::DimensionError);
-}
-
 TEST_F(DatasetRenameTest, fail_duplicate_in_edge_dim_in_data_array_coord) {
   auto da = copy(d["data_xy"]);
   const Dim dim{"edge"};
@@ -816,13 +774,6 @@ TEST_F(DatasetRenameTest, fail_duplicate_in_edge_dim_in_data_array_coord) {
   ASSERT_THROW(da.rename_dims({{Dim::X, dim}}), except::DimensionError);
 }
 
-TEST_F(DatasetRenameTest, fail_duplicate_in_edge_dim_in_data_array_attr) {
-  auto da = copy(d["data_xy"]);
-  const Dim dim{"edge"};
-  da.attrs().set(dim, makeVariable<double>(Dims{dim}, Shape{2}));
-  ASSERT_THROW(da.rename_dims({{Dim::X, dim}}), except::DimensionError);
-}
-
 TEST_F(DatasetRenameTest, existing) {
   auto out = d.rename_dims({{Dim::X, Dim::X}});
   ASSERT_EQ(d, original);
diff --git a/lib/dataset/test/equals_nan_test.cpp b/lib/dataset/test/equals_nan_test.cpp
index 594f456683..1e70d17a04 100644
--- a/lib/dataset/test/equals_nan_test.cpp
+++ b/lib/dataset/test/equals_nan_test.cpp
@@ -23,8 +23,7 @@ class EqualsNanTest : public ::testing::Test {
   Variable data =
       makeVariable<double>(Dims{Dim::X}, Shape{4}, Values{1, 2, 3, 4});
   DataArray da =
-      DataArray(data, {{Dim::X, data + data}}, {{"mask", data + data}},
-                {{Dim("attr"), data + data}});
+      DataArray(data, {{Dim::X, data + data}}, {{"mask", data + data}});
   Variable nan = makeVariable<double>(Dims{Dim::X}, Shape{4},
                                       Values{1.0f, 2.0f, NAN, 4.0f});
   Dataset ds;
@@ -62,13 +61,6 @@ TEST_F(EqualsNanTest, nan_mask) {
   check();
 }
 
-TEST_F(EqualsNanTest, nan_attr) {
-  da.attrs()[Dim("attr")] += nan;
-  check();
-  const auto out = da + copy(da);
-  ASSERT_TRUE(out.attrs().contains(Dim("attr")));
-}
-
 TEST_F(EqualsNanTest, concat_nan_coord) {
   da.coords()[Dim::X] += nan;
   const auto out = dataset::concat(std::vector{da, copy(da)}, Dim::Y);
@@ -81,12 +73,6 @@ TEST_F(EqualsNanTest, concat_nan_mask) {
   ASSERT_TRUE(equals_nan(out.masks()["mask"], da.masks()["mask"]));
 }
 
-TEST_F(EqualsNanTest, concat_nan_attr) {
-  da.attrs()[Dim("attr")] += nan;
-  const auto out = dataset::concat(std::vector{da, copy(da)}, Dim::Y);
-  ASSERT_TRUE(equals_nan(out.attrs()[Dim("attr")], da.attrs()[Dim("attr")]));
-}
-
 TEST_F(EqualsNanTest, concat_nan_item) {
   da.masks().erase("mask");
   ds["a"].masks().erase("mask");
@@ -106,6 +92,5 @@ TEST_F(EqualsNanTest, dataset_item_self_assign) {
   da += nan;
   da.coords()[Dim::X] += nan;
   da.masks()["mask"] += nan;
-  da.attrs()[Dim("attr")] += nan;
   ds.slice({Dim::X, 0}).setData("a", item);
 }
diff --git a/lib/dataset/test/generated_test.cpp b/lib/dataset/test/generated_test.cpp
index ebcc5faa90..ec82496f69 100644
--- a/lib/dataset/test/generated_test.cpp
+++ b/lib/dataset/test/generated_test.cpp
@@ -17,15 +17,12 @@ void check_meta(const DataArray &out, const DataArray &a) {
   EXPECT_FALSE(out.data().is_same(a.data()));
   EXPECT_EQ(out.coords(), a.coords());
   EXPECT_EQ(out.masks(), a.masks());
-  EXPECT_EQ(out.attrs(), a.attrs());
   // Meta data may be shallow-copied but dicts are not shared
   EXPECT_NE(&out.coords(), &a.coords());
   EXPECT_NE(&out.masks(), &a.masks());
-  EXPECT_NE(&out.attrs(), &a.attrs());
   EXPECT_TRUE(out.coords()[Dim::X].is_same(a.coords()[Dim::X]));
   // Masks are NOT shallow-copied, just like data
   EXPECT_FALSE(out.masks()["mask"].is_same(a.masks()["mask"]));
-  EXPECT_TRUE(out.attrs()[Dim("attr")].is_same(a.attrs()[Dim("attr")]));
 }
 } // namespace
 
@@ -74,11 +71,9 @@ TEST_F(GeneratedBinaryDataArrayTest, DataArray_DataArray) {
   EXPECT_EQ(out.data(), less(a.data(), b.data()));
   EXPECT_EQ(out.coords(), a.coords()); // because both inputs have same coords
   EXPECT_NE(out.masks(), a.masks());
-  EXPECT_NE(out.attrs(), a.attrs());
   // Meta data may be shallow-copied but dicts are not shared
   EXPECT_NE(&out.coords(), &a.coords());
   EXPECT_NE(&out.masks(), &a.masks());
-  EXPECT_NE(&out.attrs(), &a.attrs());
 }
 
 TEST_F(GeneratedBinaryDataArrayTest, coord_union) {
@@ -105,15 +100,6 @@ TEST_F(GeneratedBinaryDataArrayTest, mask_is_deep_copied_even_if_same) {
   EXPECT_FALSE(less(a, a).masks()["mask"].is_same(a.masks()["mask"]));
 }
 
-TEST_F(GeneratedBinaryDataArrayTest, attr_intersection) {
-  EXPECT_TRUE(a.attrs().contains(Dim("attr1")));
-  EXPECT_TRUE(b.attrs().contains(Dim("attr2")));
-  // Attrs are shared
-  EXPECT_TRUE(out.attrs()[Dim("attr")].is_same(a.attrs()[Dim("attr")]));
-  EXPECT_FALSE(out.attrs().contains(Dim("attr1")));
-  EXPECT_FALSE(out.attrs().contains(Dim("attr2")));
-}
-
 TEST_F(GeneratedBinaryDataArrayTest, non_bool_masks_with_same_names) {
   auto data = makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{0.1, 0.2});
   auto coord =
diff --git a/lib/dataset/test/groupby_test.cpp b/lib/dataset/test/groupby_test.cpp
index 0cf14fdb12..0ec31a62fb 100644
--- a/lib/dataset/test/groupby_test.cpp
+++ b/lib/dataset/test/groupby_test.cpp
@@ -29,7 +29,6 @@ struct GroupbyTest : public ::testing::Test {
                                                  units::m, Values{1, 2, 3})},
            {Dim("labels2"), makeVariable<double>(Dimensions{Dim::X, 3},
                                                  units::m, Values{1, 1, 3})}}) {
-    d["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   }
 
   Dataset d;
@@ -71,7 +70,6 @@ TEST_F(GroupbyTest, dataset_1d_and_2d) {
                                   Variances{9.0 / 4, 6.0, 9.0 / 4, 6.0})},
        {"c", makeVariable<double>(Dims{Dim(Dim::Z), dim}, Shape{2, 2}, units::s,
                                   Values{1.5, 3.0, 4.5, 6.0})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   expected.setCoord(
       dim, makeVariable<double>(Dims{dim}, Shape{2}, units::m, Values{1, 3}));
 
@@ -106,22 +104,12 @@ TEST_F(GroupbyTest, array_variable) {
   EXPECT_THROW(groupby(arr, var_bad, bins), except::DimensionError);
 }
 
-TEST_F(GroupbyTest, by_attr) {
-  auto da = copy(d["a"]);
-  const auto key = Dim("labels1");
-  const auto grouped_coord = groupby(da, key).sum(Dim::X);
-  da.attrs().set(key, da.coords().extract(key));
-  const auto grouped_attr = groupby(da, key).sum(Dim::X);
-  EXPECT_EQ(grouped_coord, grouped_attr);
-}
-
 struct GroupbyReductionTest : public ::testing::Test {
   GroupbyReductionTest()
       : d({{"a", makeVariable<double>(Dimensions{{Dim::Z, 2}, {Dim::X, 3}},
                                       units::m, Values{1, 2, 3, 1, 2, 3})},
            {"c", makeVariable<double>(Dimensions{{Dim::Z, 2}, {Dim::X, 3}},
                                       units::s, Values{1, 2, 3, 4, 5, 6})}}) {
-    d["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
     d.setCoord(Dim("labels1"), makeVariable<double>(Dimensions{Dim::X, 3},
                                                     units::m, Values{1, 2, 3}));
     d.setCoord(Dim("labels2"), makeVariable<double>(Dimensions{Dim::X, 3},
@@ -144,7 +132,6 @@ TEST_F(GroupbyReductionTest, sum_groups_with_multiple_elements) {
                                                units::m, Values{3, 3, 3, 3})},
                     {"c", makeVariable<double>(Dims{Dim::Z, dim}, Shape{2, 2},
                                                units::s, Values{3, 3, 9, 6})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   expected.setCoord(
       dim, makeVariable<double>(Dims{dim}, units::m, Shape{2}, Values{1, 3}));
   EXPECT_EQ(groupby(d, dim).sum(Dim::X), expected);
@@ -163,7 +150,6 @@ TEST_F(GroupbyReductionTest, max_groups_with_multiple_elements) {
                                                units::m, Values{2, 3, 2, 3})},
                     {"c", makeVariable<double>(Dims{Dim::Z, dim}, Shape{2, 2},
                                                units::s, Values{2, 3, 5, 6})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   expected.setCoord(
       dim, makeVariable<double>(Dims{dim}, units::m, Shape{2}, Values{1, 3}));
   EXPECT_EQ(groupby(d, dim).max(Dim::X), expected);
@@ -219,7 +205,6 @@ TEST_F(GroupbyMaskedTest, sum) {
                                   Values{1, 3, 4, 6})}},
       {{dim,
         makeVariable<double>(Dimensions{dim, 2}, units::m, Values{1, 3})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   for (const auto &item : {"a", "c"})
     expected[item].masks().set(
         "mask_z",
@@ -241,7 +226,6 @@ TEST_F(GroupbyMaskedTest, sum_irrelevant_mask) {
                                   Values{3, 3, 9, 6})}},
       {{dim,
         makeVariable<double>(Dimensions{dim, 2}, units::m, Values{1, 3})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   for (const auto &item : {"a", "c"})
     expected[item].masks().set(
         "mask_z",
@@ -273,7 +257,6 @@ TEST_F(GroupbyMaskedTest, mean_mask_ignores_values_properly) {
                                   Values{1, 3, 4, 6})}},
       {{dim,
         makeVariable<double>(Dimensions{dim, 2}, units::m, Values{1, 3})}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
   for (const auto &item : {"a", "c"})
     expected[item].masks().set(
         "mask_z",
@@ -390,7 +373,6 @@ struct GroupbyWithBinsTest : public ::testing::Test {
   GroupbyWithBinsTest()
       : d({{"a", makeVariable<double>(Dimensions{Dim::X, 5}, units::s,
                                       Values{0.1, 0.2, 0.3, 0.4, 0.5})}}) {
-    d["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
     d.setCoord(Dim("labels1"),
                makeVariable<double>(Dimensions{Dim::X, 5}, units::m,
                                     Values{1, 2, 3, 4, 5}));
@@ -409,7 +391,6 @@ TEST_F(GroupbyWithBinsTest, bins) {
   Dataset expected({{"a", makeVariable<double>(Dims{Dim::Z}, Shape{3}, units::s,
                                                Values{0.0, 0.8, 0.3})}},
                    {{Dim::Z, bins}});
-  expected["a"].attrs().set(Dim("scalar"), makeVariable<double>(Values{1.2}));
 
   EXPECT_EQ(groupby(d, Dim("labels2"), bins).sum(Dim::X), expected);
   EXPECT_EQ(groupby(d["a"], Dim("labels2"), bins).sum(Dim::X), expected["a"]);
@@ -519,16 +500,14 @@ struct GroupbyBinnedTest : public ::testing::Test {
       {{Dim("0-d"), makeVariable<double>(Values{1.2})},
        {Dim("labels"), makeVariable<int64_t>(Dims{Dim::Y}, Shape{3}, units::m,
                                              Values{1, 1, 3})}},
-      {},
-      {{Dim("scalar_attr"), makeVariable<double>(Values{1.2})}}};
+      {}};
 
   DataArray expected{
       make_events_out(),
       {{Dim("0-d"), makeVariable<double>(Values{1.2})},
        {Dim("labels"), makeVariable<int64_t>(Dims{Dim("labels")}, Shape{2},
                                              units::m, Values{1, 3})}},
-      {},
-      {{Dim("scalar_attr"), makeVariable<double>(Values{1.2})}}};
+      {}};
 };
 
 TEST_F(GroupbyBinnedTest, min_data_array) {
@@ -566,14 +545,6 @@ TEST_F(GroupbyBinnedTest, concatenate_data_array) {
   EXPECT_EQ(groupby(a, Dim("labels")).concat(Dim::Y), expected);
 }
 
-TEST_F(GroupbyBinnedTest, concatenate_by_attr) {
-  const auto key = Dim("labels");
-  const auto grouped_coord = groupby(a, key).concat(Dim::Y);
-  a.attrs().set(key, a.coords().extract(key));
-  const auto grouped_attr = groupby(a, key).concat(Dim::Y);
-  EXPECT_EQ(grouped_coord, grouped_attr);
-}
-
 TEST_F(GroupbyBinnedTest, concatenate_data_array_2d) {
   a = bin(a, {makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{1, 8})});
   auto grouped = groupby(a, Dim("labels")).concat(Dim::Y);
diff --git a/lib/dataset/test/histogram_test.cpp b/lib/dataset/test/histogram_test.cpp
index 40f5c4873a..d231f17455 100644
--- a/lib/dataset/test/histogram_test.cpp
+++ b/lib/dataset/test/histogram_test.cpp
@@ -117,7 +117,7 @@ auto make_single_events() {
 DataArray make_expected(const Variable &var, const Variable &edges) {
   auto dim = var.dims().inner();
   core::Dict<Dim, Variable> coords = {{dim, edges}};
-  auto expected = DataArray(var, coords, {}, {}, "events");
+  auto expected = DataArray(var, coords, {}, "events");
   return expected;
 }
 
diff --git a/lib/dataset/test/merge_test.cpp b/lib/dataset/test/merge_test.cpp
index 8c2bbdec51..e01a0bec70 100644
--- a/lib/dataset/test/merge_test.cpp
+++ b/lib/dataset/test/merge_test.cpp
@@ -16,8 +16,6 @@ TEST(MergeTest, simple) {
       {{Dim::X, makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{1, 2, 3})},
        {Dim("label_1"),
         makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{9, 8, 7})}});
-  a["data_1"].attrs().set(Dim("attr_1"), makeVariable<int>(Values{42}));
-  a["data_1"].attrs().set(Dim("attr_2"), makeVariable<int>(Values{495}));
 
   Dataset b(
       {{"data_2",
@@ -25,7 +23,6 @@ TEST(MergeTest, simple) {
       {{Dim::X, makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{1, 2, 3})},
        {Dim("label_2"),
         makeVariable<int>(Dims{Dim::X}, Shape{3}, Values{9, 8, 9})}});
-  b["data_2"].attrs().set(Dim("attr_2"), makeVariable<int>(Values{495}));
 
   const auto d = merge(a, b);
 
@@ -36,11 +33,6 @@ TEST(MergeTest, simple) {
 
   EXPECT_EQ(a.coords()[Dim("label_1")], d.coords()[Dim("label_1")]);
   EXPECT_EQ(b.coords()[Dim("label_2")], d.coords()[Dim("label_2")]);
-
-  EXPECT_EQ(a["data_1"].attrs()[Dim("attr_1")],
-            d["data_1"].attrs()[Dim("attr_1")]);
-  EXPECT_EQ(b["data_2"].attrs()[Dim("attr_2")],
-            d["data_2"].attrs()[Dim("attr_2")]);
 }
 
 TEST(MergeTest, non_matching_dense_data) {
diff --git a/lib/dataset/test/shape_test.cpp b/lib/dataset/test/shape_test.cpp
index 8ca981a1e7..83fdbb8f0b 100644
--- a/lib/dataset/test/shape_test.cpp
+++ b/lib/dataset/test/shape_test.cpp
@@ -17,7 +17,6 @@ TEST(ResizeTest, data_array_1d) {
   const auto var = makeVariable<double>(Dims{Dim::X}, Shape{2}, Values{1, 2});
   DataArray a(var);
   a.coords().set(Dim::X, var);
-  a.attrs().set(Dim::Y, var);
   a.masks().set("mask", var);
   DataArray expected(makeVariable<double>(Dims{Dim::X}, Shape{3}));
   EXPECT_EQ(resize(a, Dim::X, 3), expected);
@@ -31,14 +30,11 @@ TEST(ResizeTest, data_array_2d) {
   DataArray a(var);
   a.coords().set(Dim::X, x);
   a.coords().set(Dim::Y, y);
-  a.attrs().set(Dim("unaligned-x"), x);
-  a.attrs().set(Dim("unaligned-y"), y);
   a.masks().set("mask-x", x);
   a.masks().set("mask-y", y);
 
   DataArray expected(makeVariable<double>(Dims{Dim::Y, Dim::X}, Shape{1, 2}));
   expected.coords().set(Dim::X, x);
-  expected.attrs().set(Dim("unaligned-x"), x);
   expected.masks().set("mask-x", x);
 
   EXPECT_EQ(resize(a, Dim::Y, 1), expected);
@@ -305,66 +301,6 @@ TEST(ReshapeTest, round_trip_binedges) {
             a);
 }
 
-TEST(ReshapeTest, fold_x_with_attrs) {
-  const auto var = fold(arange(Dim::X, 24), Dim::X, {{Dim::X, 6}, {Dim::Y, 4}});
-  DataArray a(var);
-  a.coords().set(Dim::X, arange(Dim::X, 6) + 0.1 * units::one);
-  a.coords().set(Dim::Y, arange(Dim::Y, 4) + 0.2 * units::one);
-  a.attrs().set(Dim("attr_x"), arange(Dim::X, 6) + 0.3 * units::one);
-  a.attrs().set(Dim("attr_y"), arange(Dim::Y, 4) + 0.4 * units::one);
-
-  const auto rshp = fold(arange(Dim::X, 24), Dim::X,
-                         {{Dim::Row, 2}, {Dim::Time, 3}, {Dim::Y, 4}});
-  DataArray expected(rshp);
-  expected.coords().set(
-      Dim::X, fold(arange(Dim::X, 6), Dim::X, {{Dim::Row, 2}, {Dim::Time, 3}}) +
-                  0.1 * units::one);
-  expected.coords().set(Dim::Y, a.coords()[Dim::Y]);
-  expected.attrs().set(Dim("attr_x"), fold(arange(Dim::X, 6), Dim::X,
-                                           {{Dim::Row, 2}, {Dim::Time, 3}}) +
-                                          0.3 * units::one);
-  expected.attrs().set(Dim("attr_y"), a.attrs()[Dim("attr_y")]);
-
-  EXPECT_EQ(fold(a, Dim::X, {{Dim::Row, 2}, {Dim::Time, 3}}), expected);
-}
-
-TEST(ReshapeTest, flatten_with_attrs) {
-  const auto var = fold(arange(Dim::X, 24), Dim::X, {{Dim::X, 6}, {Dim::Y, 4}});
-  DataArray a(var);
-  a.coords().set(Dim::X, arange(Dim::X, 6) + 0.1 * units::one);
-  a.coords().set(Dim::Y, arange(Dim::Y, 4) + 0.2 * units::one);
-  a.attrs().set(Dim("attr_x"), arange(Dim::X, 6) + 0.3 * units::one);
-  a.attrs().set(Dim("attr_y"), arange(Dim::Y, 4) + 0.4 * units::one);
-
-  const auto rshp = arange(Dim::Z, 24);
-  DataArray expected(rshp);
-  expected.coords().set(
-      Dim::X,
-      makeVariable<double>(Dims{Dim::Z}, Shape{24},
-                           Values{0.1, 0.1, 0.1, 0.1, 1.1, 1.1, 1.1, 1.1,
-                                  2.1, 2.1, 2.1, 2.1, 3.1, 3.1, 3.1, 3.1,
-                                  4.1, 4.1, 4.1, 4.1, 5.1, 5.1, 5.1, 5.1}));
-  expected.coords().set(
-      Dim::Y,
-      makeVariable<double>(Dims{Dim::Z}, Shape{24},
-                           Values{0.2, 1.2, 2.2, 3.2, 0.2, 1.2, 2.2, 3.2,
-                                  0.2, 1.2, 2.2, 3.2, 0.2, 1.2, 2.2, 3.2,
-                                  0.2, 1.2, 2.2, 3.2, 0.2, 1.2, 2.2, 3.2}));
-  expected.attrs().set(
-      Dim("attr_x"),
-      makeVariable<double>(Dims{Dim::Z}, Shape{24},
-                           Values{0.3, 0.3, 0.3, 0.3, 1.3, 1.3, 1.3, 1.3,
-                                  2.3, 2.3, 2.3, 2.3, 3.3, 3.3, 3.3, 3.3,
-                                  4.3, 4.3, 4.3, 4.3, 5.3, 5.3, 5.3, 5.3}));
-  expected.attrs().set(
-      Dim("attr_y"),
-      makeVariable<double>(Dims{Dim::Z}, Shape{24},
-                           Values{0.4, 1.4, 2.4, 3.4, 0.4, 1.4, 2.4, 3.4,
-                                  0.4, 1.4, 2.4, 3.4, 0.4, 1.4, 2.4, 3.4,
-                                  0.4, 1.4, 2.4, 3.4, 0.4, 1.4, 2.4, 3.4}));
-
-  EXPECT_EQ(flatten(a, std::vector<Dim>{Dim::X, Dim::Y}, Dim::Z), expected);
-}
 
 TEST(ReshapeTest, fold_x_with_2d_coord) {
   const auto var = fold(arange(Dim::X, 24), Dim::X, {{Dim::X, 6}, {Dim::Y, 4}});
@@ -515,8 +451,6 @@ TEST(ReshapeTest, round_trip_with_all) {
   a.coords().set(Dim::Z,
                  fold(arange(Dim::X, 24), Dim::X, {{Dim::X, 6}, {Dim::Y, 4}}) +
                      0.5 * units::one);
-  a.attrs().set(Dim("attr_x"), arange(Dim::X, 6) + 0.3 * units::one);
-  a.attrs().set(Dim("attr_y"), arange(Dim::Y, 4) + 0.4 * units::one);
   a.masks().set("mask_x", makeVariable<bool>(
                               Dims{Dim::X}, Shape{6},
                               Values{true, true, true, false, false, false}));
@@ -567,7 +501,6 @@ TEST_F(TransposeTest, data_array_2d_meta_data) {
   // not right now.
   a.coords().set(Dim("edges"), edges);
   a.masks().set("mask", xy);
-  a.attrs().set(Dim("attr"), xy);
   auto transposed = transpose(a);
   EXPECT_EQ(transposed.data(), transpose(a.data()));
   transposed.setData(a.data());
@@ -601,7 +534,6 @@ class SqueezeTest : public ::testing::Test {
     a.masks().set("mask-x", x);
     a.masks().set("mask-z", z);
     a.masks().set("mask-xyz", xyz);
-    a.attrs().set(Dim{"attr-x"}, x);
   }
   Variable xyz = makeVariable<double>(Dims{Dim::X, Dim::Y, Dim::Z},
                                       Shape{1, 1, 2}, Values{1, 2});
@@ -623,7 +555,6 @@ TEST_F(SqueezeTest, data_array_3d_outer) {
   EXPECT_EQ(squeezed.masks()["mask-x"], makeVariable<double>(Values{10}));
   EXPECT_EQ(squeezed.masks()["mask-z"], z);
   EXPECT_EQ(squeezed.masks()["mask-xyz"], squeeze(xyz, dims));
-  EXPECT_EQ(squeezed.attrs()[Dim{"attr-x"}], makeVariable<double>(Values{10}));
 }
 
 TEST_F(SqueezeTest, data_array_3d_center) {
@@ -638,7 +569,6 @@ TEST_F(SqueezeTest, data_array_3d_center) {
   EXPECT_EQ(squeezed.masks()["mask-x"], x);
   EXPECT_EQ(squeezed.masks()["mask-z"], z);
   EXPECT_EQ(squeezed.masks()["mask-xyz"], squeeze(xyz, dims));
-  EXPECT_EQ(squeezed.attrs()[Dim{"attr-x"}], x);
 }
 
 TEST_F(SqueezeTest, data_array_3d_inner_and_center) {
@@ -654,7 +584,6 @@ TEST_F(SqueezeTest, data_array_3d_inner_and_center) {
   EXPECT_EQ(squeezed.masks()["mask-x"], makeVariable<double>(Values{10}));
   EXPECT_EQ(squeezed.masks()["mask-z"], z);
   EXPECT_EQ(squeezed.masks()["mask-xyz"], squeeze(xyz, dims));
-  EXPECT_EQ(squeezed.attrs()[Dim{"attr-x"}], makeVariable<double>(Values{10}));
 }
 
 TEST_F(SqueezeTest, data_array_3d_outer_bin_edge) {
@@ -672,7 +601,6 @@ TEST_F(SqueezeTest, data_array_3d_outer_bin_edge) {
   EXPECT_EQ(squeezed.masks()["mask-x"], makeVariable<double>(Values{10}));
   EXPECT_EQ(squeezed.masks()["mask-z"], z);
   EXPECT_EQ(squeezed.masks()["mask-xyz"], squeeze(xyz, dims));
-  EXPECT_EQ(squeezed.attrs()[Dim{"attr-x"}], makeVariable<double>(Values{10}));
 }
 
 TEST_F(SqueezeTest, data_array_3d_all) {
diff --git a/lib/dataset/test/size_of_test.cpp b/lib/dataset/test/size_of_test.cpp
index 2977c5ba96..6af192b539 100644
--- a/lib/dataset/test/size_of_test.cpp
+++ b/lib/dataset/test/size_of_test.cpp
@@ -34,8 +34,7 @@ class BinnedDataArraySizeOfTest : public ::testing::Test {
       dims, Values{std::pair{0, 2}, std::pair{2, 4}});
   Variable data = makeVariable<double>(Dims{Dim::X}, Shape{4});
   DataArray buffer =
-      DataArray(data, {{Dim::X, data + data}}, {},
-                {{Dim::Z, makeVariable<int>(Dims{}, Values{1})}});
+      DataArray(data, {{Dim::X, data + data}}, {});
   Variable var = make_bins(indices, Dim::X, buffer);
 
   const scipp::index object_size =
@@ -265,8 +264,8 @@ TEST(SizeOf, data_array) {
       makeVariable<int64_t>(Dims{Dim::X}, Shape{3}, Values{0, 1, 2});
   const DataArray da(data, {{Dim::X, coord}});
   const auto object_size = sizeof(DataArray) + sizeof(dataset::Coords) +
-                           sizeof(dataset::Attrs) + sizeof(dataset::Masks) +
-                           da.coords().capacity() + da.attrs().capacity() +
+                            sizeof(dataset::Masks) +
+                           da.coords().capacity() +
                            da.masks().capacity();
   EXPECT_EQ(size_of(da, SizeofTag::ViewOnly),
             size_of(data, SizeofTag::ViewOnly) +
diff --git a/lib/dataset/test/test_data_arrays.cpp b/lib/dataset/test/test_data_arrays.cpp
index 0c70efebe3..d3f32f86f2 100644
--- a/lib/dataset/test/test_data_arrays.cpp
+++ b/lib/dataset/test/test_data_arrays.cpp
@@ -24,8 +24,5 @@ DataArray make_data_array_1d(const int64_t seed) {
   return DataArray(
       data, {{Dim::X, coord}, {Dim("scalar"), scalar_coord}},
       {{"mask", mask}, {"mask" + name, mask}, {"scalar_mask", scalar_mask}},
-      {{Dim("attr"), coord + coord},
-       {Dim("attr" + name), coord + seed * units::m},
-       {Dim("scalar_attr"), scalar_coord + scalar_coord}},
       "array" + name);
 }
diff --git a/lib/dataset/test/test_data_arrays.h b/lib/dataset/test/test_data_arrays.h
index 14425537ec..4c081ee067 100644
--- a/lib/dataset/test/test_data_arrays.h
+++ b/lib/dataset/test/test_data_arrays.h
@@ -6,7 +6,7 @@
 
 #include "scipp/dataset/data_array.h"
 
-/// Create a data array with coord, masks, and attrs.
+/// Create a data array with coord and masks.
 ///
 /// Different but compatible arrays can be created using different seeds. The
 /// seed does not affect coords to ensure that the produced arrays can be
diff --git a/lib/dataset/test/to_unit_test.cpp b/lib/dataset/test/to_unit_test.cpp
index bbfc3a7b89..cbdd6b266b 100644
--- a/lib/dataset/test/to_unit_test.cpp
+++ b/lib/dataset/test/to_unit_test.cpp
@@ -11,8 +11,7 @@ using namespace scipp;
 auto make_array() {
   return DataArray(makeVariable<double>(Values{2.0}, units::m),
                    {{Dim("coord"), makeVariable<int>(Values{4}, units::s)}},
-                   {{"mask1", makeVariable<bool>(Values{true})}},
-                   {{Dim("attr"), makeVariable<int>(Values{7}, units::kg)}});
+                   {{"mask1", makeVariable<bool>(Values{true})}});
 }
 
 class ToUnitTest
@@ -106,14 +105,3 @@ TEST_P(ToUnitTest, does_not_affect_coords) {
   EXPECT_EQ(converted.coords(), da.coords());
   EXPECT_TRUE(converted.coords()[Dim::X].is_same(da.coords()[Dim::X]));
 }
-
-TEST_P(ToUnitTest, does_not_affect_attrs) {
-  da.attrs().set(Dim::X, makeVariable<int>(Values{4}, units::s));
-
-  const auto [unit, policy] = GetParam();
-  const auto converted = to_unit(da, unit, policy);
-
-  EXPECT_EQ(converted.attrs()[Dim::X], makeVariable<int>(Values{4}, units::s));
-  EXPECT_EQ(converted.attrs(), da.attrs());
-  EXPECT_TRUE(converted.attrs()[Dim::X].is_same(da.attrs()[Dim::X]));
-}
diff --git a/lib/dataset/to_unit.cpp b/lib/dataset/to_unit.cpp
index 87c62be835..e792ed558c 100644
--- a/lib/dataset/to_unit.cpp
+++ b/lib/dataset/to_unit.cpp
@@ -16,7 +16,7 @@ DataArray to_unit(const DataArray &array, const units::Unit &unit,
                        ? array.masks()
                        : dataset::copy(array.masks());
   return DataArray(std::move(new_data), array.coords(), std::move(new_masks),
-                   array.attrs(), array.name());
+                   array.name());
 }
 
 } // namespace scipp::dataset
diff --git a/lib/dataset/util.cpp b/lib/dataset/util.cpp
index 4b7213e9d3..0c7909f4d1 100644
--- a/lib/dataset/util.cpp
+++ b/lib/dataset/util.cpp
@@ -38,19 +38,15 @@ size_of_impl(const Variable &var, const SizeofTag tag,
 scipp::index
 size_of_impl(const DataArray &da, const SizeofTag tag,
              const std::optional<std::pair<Dim, double>> &scale_in_dim,
-             bool include_aligned_coords = true) {
+             bool include_coords = true) {
   auto size = static_cast<scipp::index>(
-      sizeof(DataArray) + sizeof(dataset::Coords) + sizeof(dataset::Attrs) +
-      sizeof(dataset::Masks) + da.coords().capacity() + da.attrs().capacity() +
-      da.masks().capacity());
+      sizeof(DataArray) + sizeof(dataset::Coords) +
+      sizeof(dataset::Masks) + da.coords().capacity() + da.masks().capacity());
   size += size_of_impl(da.data(), tag, scale_in_dim);
-  for (const auto &coord : da.attrs()) {
-    size += size_of_impl(coord.second, tag, scale_in_dim);
-  }
   for (const auto &mask : da.masks()) {
     size += size_of_impl(mask.second, tag, scale_in_dim);
   }
-  if (include_aligned_coords) {
+  if (include_coords) {
     for (const auto &coord : da.coords()) {
       size += size_of_impl(coord.second, tag, scale_in_dim);
     }
@@ -194,9 +190,6 @@ DataArray strip_edges_along(const DataArray &da, const Dim dim) {
   for (const auto &[name, var] : da.masks())
     if (core::is_edges(da.dims(), var.dims(), dim))
       out.masks().erase(name);
-  for (const auto &[name, var] : da.attrs())
-    if (core::is_edges(da.dims(), var.dims(), dim))
-      out.attrs().erase(name);
   return out;
 }
 
diff --git a/lib/dataset/variable_instantiate_bin_elements.cpp b/lib/dataset/variable_instantiate_bin_elements.cpp
index 7fbeda3194..3604820485 100644
--- a/lib/dataset/variable_instantiate_bin_elements.cpp
+++ b/lib/dataset/variable_instantiate_bin_elements.cpp
@@ -65,8 +65,6 @@ std::string Formatter<core::bin<DataArray>>::format(const Variable &var) const {
     s << ",\n" << dict_to_compact_string(buffer.coords(), "coords", margin);
   if (!buffer.masks().empty())
     s << ",\n" << dict_to_compact_string(buffer.masks(), "masks", margin);
-  if (!buffer.attrs().empty())
-    s << ",\n" << dict_to_compact_string(buffer.attrs(), "attrs", margin);
   return s.str() + ')';
 }
 
@@ -110,7 +108,7 @@ class BinVariableMakerDataArray : public variable::BinVariableMaker<DataArray> {
     if (source.dims() == Dimensions{dim, dims.volume()} &&
         indices == parent.bin_indices()) {
       auto buffer = DataArray(std::move(data_buffer), copy(source.coords()),
-                              copy(source.masks()), copy(source.attrs()));
+                              copy(source.masks()));
       return make_bins_no_validate(indices, dim, std::move(buffer));
     } else {
       auto buffer = resize_default_init(source, dim, dims.volume());
diff --git a/lib/python/bind_data_array.h b/lib/python/bind_data_array.h
index 3b9039f27b..62df93c7ba 100644
--- a/lib/python/bind_data_array.h
+++ b/lib/python/bind_data_array.h
@@ -321,13 +321,6 @@ void bind_data_array_properties(py::class_<T, Ignored...> &c) {
   c.def_property_readonly(
       "coords", [](T &self) -> decltype(auto) { return self.coords(); },
       R"(Dict of coords.)");
-  c.def_property_readonly(
-      "deprecated_meta", [](T &self) -> decltype(auto) { return self.meta(); },
-      R"(Dict of coords and attrs.)");
-  c.def_property_readonly(
-      "deprecated_attrs",
-      [](T &self) -> decltype(auto) { return self.attrs(); },
-      R"(Dict of attrs.)");
   c.def_property_readonly(
       "masks", [](T &self) -> decltype(auto) { return self.masks(); },
       R"(Dict of masks.)");
@@ -349,16 +342,4 @@ void bind_data_array_properties(py::class_<T, Ignored...> &c) {
   c.def("drop_masks", [](T &self, std::vector<std::string> &mask_names) {
     return self.drop_masks(mask_names);
   });
-  c.def("deprecated_drop_attrs", [](T &self, std::string &attr_name) {
-    std::vector<scipp::Dim> attr_names_c = {scipp::Dim{attr_name}};
-    return self.drop_attrs(attr_names_c);
-  });
-  c.def("deprecated_drop_attrs",
-        [](T &self, std::vector<std::string> &attr_names) {
-          std::vector<scipp::Dim> attr_names_c;
-          std::transform(attr_names.begin(), attr_names.end(),
-                         std::back_inserter(attr_names_c),
-                         [](const auto &name) { return scipp::Dim{name}; });
-          return self.drop_attrs(attr_names_c);
-        });
 }
diff --git a/lib/python/bins.cpp b/lib/python/bins.cpp
index b2ace40b56..baa8208eb7 100644
--- a/lib/python/bins.cpp
+++ b/lib/python/bins.cpp
@@ -124,15 +124,11 @@ template <class T> void bind_bins_view(py::module &m) {
 
   py::class_<decltype(dataset::bins_view<T>(Variable{}))> c(
       m, "_BinsViewDataArray");
-  bind_bins_map_view<decltype(dataset::bins_view<T>(Variable{}).meta())>(
-      m, "_BinsMeta");
   bind_mutable_view_no_dim<
       decltype(dataset::bins_view<T>(Variable{}).coords())>(
       m, "_BinsCoords", "Dict of event coords.");
   bind_mutable_view<decltype(dataset::bins_view<T>(Variable{}).masks())>(
       m, "_BinsMasks", "Dict of event masks.");
-  bind_bins_map_view<decltype(dataset::bins_view<T>(Variable{}).attrs())>(
-      m, "_BinsAttrs");
   bind_data_array_properties(c);
   m.def("_bins_view",
         [](const Variable &var) { return dataset::bins_view<T>(var); });
diff --git a/lib/python/dataset.cpp b/lib/python/dataset.cpp
index bf84f1b002..6a2af1bcbf 100644
--- a/lib/python/dataset.cpp
+++ b/lib/python/dataset.cpp
@@ -46,12 +46,6 @@ void bind_dataset_coord_properties(py::class_<T, Ignored...> &c) {
       "coords", [](T &self) -> decltype(auto) { return self.coords(); },
       R"(
       Dict of coordinates.)");
-  // Metadata for dataset is same as `coords` since dataset cannot have attrs
-  // (unaligned coords).
-  c.def_property_readonly(
-      "meta", [](T &self) -> decltype(auto) { return self.meta(); },
-      R"(
-      Dict of coordinates.)");
 }
 
 template <class... Ignored>
@@ -181,30 +175,29 @@ void init_dataset(py::module &m) {
   bind_helper_view<values_view, Masks>(m, "Masks");
 
   bind_mutable_view_no_dim<Coords>(m, "Coords",
-                                   R"(dict-like collection of meta data
+                                   R"(dict-like collection of coordinates.
 
-Returned by :py:func:`DataArray.coords`, :py:func:`DataArray.attrs`, :py:func:`DataArray.meta`,
-and the corresponding properties of :py:class:`Dataset`.)");
+Returned by :py:meth:`DataArray.coords` and :py:meth:`Dataset.coords`.)");
   bind_mutable_view<Masks>(m, "Masks", R"(dict-like collection of masks.
 
 Returned by :py:func:`DataArray.masks`)");
 
   py::class_<DataArray> dataArray(m, "DataArray", R"(
-    Named variable with associated coords, masks, and attributes.)");
+    Named variable with associated coords and masks.)");
   py::options options;
   options.disable_function_signatures();
   dataArray.def(
       py::init([](const Variable &data, const py::object &coords,
-                  const py::object &masks, const py::object &attrs,
+                  const py::object &masks,
                   const std::string &name) {
         return DataArray{data, to_cpp_dict<Dim, Variable>(coords),
                          to_cpp_dict<std::string, Variable>(masks),
-                         to_cpp_dict<Dim, Variable>(attrs), name};
+                          name};
       }),
       py::arg("data"), py::kw_only(), py::arg("coords") = py::dict(),
-      py::arg("masks") = py::dict(), py::arg("attrs") = py::dict(),
+      py::arg("masks") = py::dict(),
       py::arg("name") = std::string{},
-      R"doc(__init__(self, data: Variable, coords: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, masks: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, attrs: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, name: str = '') -> None
+      R"doc(__init__(self, data: Variable, coords: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, masks: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, name: str = '') -> None
 
           DataArray initializer.
 
@@ -216,8 +209,6 @@ Returned by :py:func:`DataArray.masks`)");
               Coordinates referenced by dimension.
           masks:
               Masks referenced by name.
-          attrs:
-              Attributes referenced by dimension.
           name:
               Name of the data array.
           )doc");
diff --git a/lib/templates/dataset_binary.cpp.in b/lib/templates/dataset_binary.cpp.in
index c9b46c2336..71a5bf3762 100644
--- a/lib/templates/dataset_binary.cpp.in
+++ b/lib/templates/dataset_binary.cpp.in
@@ -12,20 +12,18 @@ namespace scipp::dataset {
 DataArray @NAME@(const DataArray &a, const DataArray &b) {
   auto coords = union_(a.coords(), b.coords(), "@OPNAME@");
   auto masks = union_or(a.masks(), b.masks());
-  auto attrs = intersection(a.attrs(), b.attrs());
   return DataArray(
       @NAME@(a.data(), b.data()),
       std::move(coords),
-      std::move(masks),
-      std::move(attrs));
+      std::move(masks));
 }
 
 DataArray @NAME@(const DataArray &a, const Variable &b) {
-  return DataArray(@NAME@(a.data(), b), a.coords(), copy(a.masks()), a.attrs());
+  return DataArray(@NAME@(a.data(), b), a.coords(), copy(a.masks()));
 }
 
 DataArray @NAME@(const Variable &a, const DataArray &b) {
-  return DataArray(@NAME@(a, b.data()), b.coords(), copy(b.masks()), b.attrs());
+  return DataArray(@NAME@(a, b.data()), b.coords(), copy(b.masks()));
 }
 
 } // namespace scipp::dataset
diff --git a/lib/templates/dataset_unary.cpp.in b/lib/templates/dataset_unary.cpp.in
index ecdc91f651..e081aa1bdf 100644
--- a/lib/templates/dataset_unary.cpp.in
+++ b/lib/templates/dataset_unary.cpp.in
@@ -10,7 +10,7 @@
 namespace scipp::dataset {
 
 DataArray @NAME@(const DataArray &a) {
-  return DataArray(@NAME@(a.data()), a.coords(), copy(a.masks()), a.attrs(), a.name());
+  return DataArray(@NAME@(a.data()), a.coords(), copy(a.masks()), a.name());
 }
 
 Dataset @NAME@(const Dataset &ds) {

From d1dc2f177effc3de4690e195379200858681d707 Mon Sep 17 00:00:00 2001
From: jl-wynen <jl-wynen@users.noreply.github.com>
Date: Fri, 20 Dec 2024 13:18:57 +0000
Subject: [PATCH 3/7] Apply automatic formatting

---
 .../include/scipp/dataset/data_array.h        |  3 +--
 lib/dataset/include/scipp/dataset/dataset.h   | 21 +++++++++----------
 lib/dataset/test/binned_creation_test.cpp     |  3 ++-
 lib/dataset/test/copy_test.cpp                |  3 +--
 lib/dataset/test/shape_test.cpp               |  1 -
 lib/dataset/test/size_of_test.cpp             |  6 ++----
 lib/dataset/util.cpp                          |  4 ++--
 lib/python/dataset.cpp                        |  9 +++-----
 8 files changed, 21 insertions(+), 29 deletions(-)

diff --git a/lib/dataset/include/scipp/dataset/data_array.h b/lib/dataset/include/scipp/dataset/data_array.h
index fbec20d262..13da16503a 100644
--- a/lib/dataset/include/scipp/dataset/data_array.h
+++ b/lib/dataset/include/scipp/dataset/data_array.h
@@ -111,8 +111,7 @@ class SCIPP_DATASET_EXPORT DataArray {
 SCIPP_DATASET_EXPORT bool operator==(const DataArray &a, const DataArray &b);
 SCIPP_DATASET_EXPORT bool operator!=(const DataArray &a, const DataArray &b);
 
-[[nodiscard]] SCIPP_DATASET_EXPORT DataArray
-copy(const DataArray &array);
+[[nodiscard]] SCIPP_DATASET_EXPORT DataArray copy(const DataArray &array);
 
 [[nodiscard]] SCIPP_DATASET_EXPORT bool equals_nan(const DataArray &a,
                                                    const DataArray &b);
diff --git a/lib/dataset/include/scipp/dataset/dataset.h b/lib/dataset/include/scipp/dataset/dataset.h
index c76ccd1841..055611ab39 100644
--- a/lib/dataset/include/scipp/dataset/dataset.h
+++ b/lib/dataset/include/scipp/dataset/dataset.h
@@ -236,17 +236,16 @@ class SCIPP_DATASET_EXPORT Dataset {
   bool m_valid{true};
 };
 
-[[nodiscard]] SCIPP_DATASET_EXPORT Dataset
-copy(const Dataset &dataset);
-
-[[maybe_unused]] SCIPP_DATASET_EXPORT DataArray &
-copy(const DataArray &array, DataArray &out);
-[[maybe_unused]] SCIPP_DATASET_EXPORT DataArray
-copy(const DataArray &array, DataArray &&out);
-[[maybe_unused]] SCIPP_DATASET_EXPORT Dataset &
-copy(const Dataset &dataset, Dataset &out);
-[[maybe_unused]] SCIPP_DATASET_EXPORT Dataset
-copy(const Dataset &dataset, Dataset &&out);
+[[nodiscard]] SCIPP_DATASET_EXPORT Dataset copy(const Dataset &dataset);
+
+[[maybe_unused]] SCIPP_DATASET_EXPORT DataArray &copy(const DataArray &array,
+                                                      DataArray &out);
+[[maybe_unused]] SCIPP_DATASET_EXPORT DataArray copy(const DataArray &array,
+                                                     DataArray &&out);
+[[maybe_unused]] SCIPP_DATASET_EXPORT Dataset &copy(const Dataset &dataset,
+                                                    Dataset &out);
+[[maybe_unused]] SCIPP_DATASET_EXPORT Dataset copy(const Dataset &dataset,
+                                                   Dataset &&out);
 
 SCIPP_DATASET_EXPORT Dataset operator+(const Dataset &lhs, const Dataset &rhs);
 SCIPP_DATASET_EXPORT Dataset operator+(const Dataset &lhs,
diff --git a/lib/dataset/test/binned_creation_test.cpp b/lib/dataset/test/binned_creation_test.cpp
index 2648334368..465e476b90 100644
--- a/lib/dataset/test/binned_creation_test.cpp
+++ b/lib/dataset/test/binned_creation_test.cpp
@@ -14,7 +14,8 @@ class BinnedCreationTest : public ::testing::Test {
       Dims{Dim::X}, Shape{2}, Values{std::pair{0, 2}, std::pair{2, 5}});
   Variable m_data = makeVariable<double>(Dims{Dim::Event}, Shape{5}, units::m,
                                          Values{1, 2, 3, 4, 5});
-  DataArray m_buffer = DataArray(m_data, {{Dim::X, m_data}}, {{"mask", m_data}});
+  DataArray m_buffer =
+      DataArray(m_data, {{Dim::X, m_data}}, {{"mask", m_data}});
   Variable m_var = make_bins(m_indices, Dim::Event, m_buffer);
 
   void check(const Variable &var) const {
diff --git a/lib/dataset/test/copy_test.cpp b/lib/dataset/test/copy_test.cpp
index 6ceca77021..412566146b 100644
--- a/lib/dataset/test/copy_test.cpp
+++ b/lib/dataset/test/copy_test.cpp
@@ -11,8 +11,7 @@ using namespace scipp;
 using namespace scipp::dataset;
 
 struct CopyTest : public ::testing::Test {
-  CopyTest() : dataset(factory.make("data")), array(copy(dataset["data"])) {
-  }
+  CopyTest() : dataset(factory.make("data")), array(copy(dataset["data"])) {}
 
 protected:
   DatasetFactory factory;
diff --git a/lib/dataset/test/shape_test.cpp b/lib/dataset/test/shape_test.cpp
index 83fdbb8f0b..dcbe47af3c 100644
--- a/lib/dataset/test/shape_test.cpp
+++ b/lib/dataset/test/shape_test.cpp
@@ -301,7 +301,6 @@ TEST(ReshapeTest, round_trip_binedges) {
             a);
 }
 
-
 TEST(ReshapeTest, fold_x_with_2d_coord) {
   const auto var = fold(arange(Dim::X, 24), Dim::X, {{Dim::X, 6}, {Dim::Y, 4}});
   DataArray a(var);
diff --git a/lib/dataset/test/size_of_test.cpp b/lib/dataset/test/size_of_test.cpp
index 6af192b539..2778559e47 100644
--- a/lib/dataset/test/size_of_test.cpp
+++ b/lib/dataset/test/size_of_test.cpp
@@ -33,8 +33,7 @@ class BinnedDataArraySizeOfTest : public ::testing::Test {
   Variable indices = makeVariable<std::pair<scipp::index, scipp::index>>(
       dims, Values{std::pair{0, 2}, std::pair{2, 4}});
   Variable data = makeVariable<double>(Dims{Dim::X}, Shape{4});
-  DataArray buffer =
-      DataArray(data, {{Dim::X, data + data}}, {});
+  DataArray buffer = DataArray(data, {{Dim::X, data + data}}, {});
   Variable var = make_bins(indices, Dim::X, buffer);
 
   const scipp::index object_size =
@@ -264,8 +263,7 @@ TEST(SizeOf, data_array) {
       makeVariable<int64_t>(Dims{Dim::X}, Shape{3}, Values{0, 1, 2});
   const DataArray da(data, {{Dim::X, coord}});
   const auto object_size = sizeof(DataArray) + sizeof(dataset::Coords) +
-                            sizeof(dataset::Masks) +
-                           da.coords().capacity() +
+                           sizeof(dataset::Masks) + da.coords().capacity() +
                            da.masks().capacity();
   EXPECT_EQ(size_of(da, SizeofTag::ViewOnly),
             size_of(data, SizeofTag::ViewOnly) +
diff --git a/lib/dataset/util.cpp b/lib/dataset/util.cpp
index 0c7909f4d1..5a91cd7110 100644
--- a/lib/dataset/util.cpp
+++ b/lib/dataset/util.cpp
@@ -40,8 +40,8 @@ size_of_impl(const DataArray &da, const SizeofTag tag,
              const std::optional<std::pair<Dim, double>> &scale_in_dim,
              bool include_coords = true) {
   auto size = static_cast<scipp::index>(
-      sizeof(DataArray) + sizeof(dataset::Coords) +
-      sizeof(dataset::Masks) + da.coords().capacity() + da.masks().capacity());
+      sizeof(DataArray) + sizeof(dataset::Coords) + sizeof(dataset::Masks) +
+      da.coords().capacity() + da.masks().capacity());
   size += size_of_impl(da.data(), tag, scale_in_dim);
   for (const auto &mask : da.masks()) {
     size += size_of_impl(mask.second, tag, scale_in_dim);
diff --git a/lib/python/dataset.cpp b/lib/python/dataset.cpp
index 6a2af1bcbf..67384e8670 100644
--- a/lib/python/dataset.cpp
+++ b/lib/python/dataset.cpp
@@ -188,15 +188,12 @@ Returned by :py:func:`DataArray.masks`)");
   options.disable_function_signatures();
   dataArray.def(
       py::init([](const Variable &data, const py::object &coords,
-                  const py::object &masks,
-                  const std::string &name) {
+                  const py::object &masks, const std::string &name) {
         return DataArray{data, to_cpp_dict<Dim, Variable>(coords),
-                         to_cpp_dict<std::string, Variable>(masks),
-                          name};
+                         to_cpp_dict<std::string, Variable>(masks), name};
       }),
       py::arg("data"), py::kw_only(), py::arg("coords") = py::dict(),
-      py::arg("masks") = py::dict(),
-      py::arg("name") = std::string{},
+      py::arg("masks") = py::dict(), py::arg("name") = std::string{},
       R"doc(__init__(self, data: Variable, coords: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, masks: Union[Mapping[str, Variable], Iterable[tuple[str, Variable]]] = {}, name: str = '') -> None
 
           DataArray initializer.

From f0c1a07d6c1a2d6b7d3da43560c4b06378eec82b Mon Sep 17 00:00:00 2001
From: Mridul Seth <git@mriduls.com>
Date: Thu, 2 Jan 2025 14:16:04 +0100
Subject: [PATCH 4/7] Trigger CI Actions


From 126e73932b6ea8565b9b065293905ea4bd7f0d32 Mon Sep 17 00:00:00 2001
From: Jan-Lukas Wynen <jan-lukas.wynen@ess.eu>
Date: Mon, 6 Jan 2025 09:34:44 +0100
Subject: [PATCH 5/7] Remove warning ignore rule for attrs

---
 pyproject.toml | 1 -
 1 file changed, 1 deletion(-)

diff --git a/pyproject.toml b/pyproject.toml
index 0488de2917..db65c69df0 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -170,7 +170,6 @@ filterwarnings = [
   "ignore:The 'asyncio_mode' default value will change to 'strict' in future:DeprecationWarning",
   'ignore::scipy.optimize._optimize.OptimizeWarning',
   'ignore:Support for mapping types has been deprecated and will be dropped in a future release.:DeprecationWarning',
-  'ignore:sc.DataArray.attrs has been deprecated:scipp.VisibleDeprecationWarning',
   # Triggered by h5py
   'ignore:`product` is deprecated as of NumPy 1.25.0:DeprecationWarning'
 ]

From fc5faaa1248e4876ea7cfff45b95d699397da453 Mon Sep 17 00:00:00 2001
From: Jan-Lukas Wynen <jan-lukas.wynen@ess.eu>
Date: Wed, 8 Jan 2025 13:19:45 +0100
Subject: [PATCH 6/7] Properly concat paths

---
 tests/io/hdf5_test.py | 11 ++++++-----
 1 file changed, 6 insertions(+), 5 deletions(-)

diff --git a/tests/io/hdf5_test.py b/tests/io/hdf5_test.py
index 2bc9657ee7..d893bc810a 100644
--- a/tests/io/hdf5_test.py
+++ b/tests/io/hdf5_test.py
@@ -4,6 +4,7 @@
 # @author Simon Heybrock
 import os
 import tempfile
+from pathlib import Path
 
 import numpy as np
 import pytest
@@ -16,7 +17,7 @@
 
 def roundtrip(obj):
     with tempfile.TemporaryDirectory() as path:
-        name = f'{path}/test.hdf5'
+        name = Path(path, 'test.hdf5')
         obj.save_hdf5(filename=name)
         return sc.io.load_hdf5(filename=name)
 
@@ -158,7 +159,7 @@ def test_variable_legacy_str_unit():
     var = x.copy()
     var.unit = 'm/s*kg^2'
     with tempfile.TemporaryDirectory() as path:
-        name = f'{path}/test.hdf5'
+        name = Path(path, 'test.hdf5')
         var.save_hdf5(filename=name)
         with h5py.File(name, 'a') as f:
             f['values'].attrs['unit'] = str(var.unit)
@@ -246,7 +247,7 @@ def test_dataset():
 def test_dataset_item_can_be_read_as_data_array():
     ds = sc.Dataset(data={'a': array_1d})
     with tempfile.TemporaryDirectory() as path:
-        name = f'{path}/test.hdf5'
+        name = Path(path, 'test.hdf5')
         ds.save_hdf5(filename=name)
         loaded = {}
         with h5py.File(name, 'r') as f:
@@ -268,8 +269,8 @@ def test_dataset_with_many_coords():
     ds1 = sc.Dataset({'a': a}, coords=coords)
     ds2 = sc.Dataset({'a': a, 'b': b}, coords=coords)
     with tempfile.TemporaryDirectory() as path:
-        name1 = f'{path}/test1.hdf5'
-        name2 = f'{path}/test2.hdf5'
+        name1 = Path(path, 'test1.hdf5')
+        name2 = Path(path, 'test2.hdf5')
         ds1.save_hdf5(filename=name1)
         ds2.save_hdf5(filename=name2)
         size1 = os.path.getsize(name1)

From 8aaf573113d744cef473bd73a4ef8f66e6c0d52d Mon Sep 17 00:00:00 2001
From: Jan-Lukas Wynen <jan-lukas.wynen@ess.eu>
Date: Wed, 8 Jan 2025 13:51:48 +0100
Subject: [PATCH 7/7] Load attrs as coords in hdf5

---
 src/scipp/io/hdf5.py  | 19 +++++++++++++++++++
 tests/io/hdf5_test.py | 37 +++++++++++++++++++++++++++++++++++++
 2 files changed, 56 insertions(+)

diff --git a/src/scipp/io/hdf5.py b/src/scipp/io/hdf5.py
index 9185972c8e..eea77bb385 100644
--- a/src/scipp/io/hdf5.py
+++ b/src/scipp/io/hdf5.py
@@ -384,8 +384,27 @@ def read(group: h5.Group, override=None):
         contents['data'] = _VariableIO.read(group['data'])
         for category in ['coords', 'masks']:
             contents[category] = _read_mapping(group[category], override.get(category))
+        _DataArrayIO._read_legacy_attrs_into(contents, group, override)
         return DataArray(**contents)
 
+    @staticmethod
+    def _read_legacy_attrs_into(
+        contents: dict[str, Any], group: h5.Group, override: Mapping[str, h5.Group]
+    ) -> None:
+        """Load attributes as coordinates.
+
+        Attributes were removed in https://github.com/scipp/scipp/pull/3626
+        but old files that contain attributes remain.
+        """
+        if (attrs_group := group.get('attrs')) is not None:
+            attrs = _read_mapping(attrs_group, override.get('attrs'))
+            if intersection := contents['coords'].keys() & attrs.keys():
+                raise ValueError(
+                    f"Data array '{contents['name']}' contains legacy attributes "
+                    f'{intersection} which also exist as coordinates.'
+                )
+            contents['coords'].update(attrs)
+
 
 class _DatasetIO:
     @staticmethod
diff --git a/tests/io/hdf5_test.py b/tests/io/hdf5_test.py
index d893bc810a..5593e621c5 100644
--- a/tests/io/hdf5_test.py
+++ b/tests/io/hdf5_test.py
@@ -10,6 +10,7 @@
 import pytest
 
 import scipp as sc
+import scipp.testing
 from scipp.io.hdf5 import _collection_element_name
 
 h5py = pytest.importorskip('h5py')
@@ -233,6 +234,42 @@ def test_data_array_coord_alignment():
     assert sc.identical(a, b)
 
 
+# Attributes where removed in https://github.com/scipp/scipp/pull/3626
+# But the loader can still load attrs from files and assigns them as coords
+# as per https://github.com/scipp/scipp/pull/3626#discussion_r1906966229
+def test_data_array_loads_legacy_attributes():
+    a = sc.ones(sizes=array_1d.sizes, dtype='float64')
+    Âµ = sc.array(dims=array_1d.dims, values=[f'a{i}' for i in range(len(array_1d))])
+    with_attrs_as_coords = array_1d.assign_coords({'a': a, 'Âµ': Âµ})
+    with_attrs_as_coords.coords.set_aligned('a', False)
+    with_attrs_as_coords.coords.set_aligned('Âµ', False)
+
+    with tempfile.TemporaryDirectory() as path:
+        name = Path(path, 'test.hdf5')
+        with_attrs_as_coords.save_hdf5(filename=name)
+        with h5py.File(name, 'r+') as f:
+            # Move new coords to attrs
+            f.move(source='coords/elem_002_a', dest='attrs/elem_000_a')
+            f.move(source='coords/elem_003_&#181;', dest='attrs/elem_001_&#181;')
+
+        loaded = sc.io.load_hdf5(filename=name)
+    sc.testing.assert_identical(with_attrs_as_coords, loaded)
+
+
+def test_data_array_raises_with_clashing_attr_and_coord():
+    initial = array_1d
+
+    with tempfile.TemporaryDirectory() as path:
+        name = Path(path, 'test.hdf5')
+        initial.save_hdf5(filename=name)
+        with h5py.File(name, 'r+') as f:
+            # Copy coord into attr to create clash
+            f.copy(source='coords/elem_000_x', dest='attrs/elem_000_x')
+
+        with pytest.raises(ValueError, match="attributes {'x'}"):
+            sc.io.load_hdf5(filename=name)
+
+
 def test_variable_binned_data_array_coord_alignment():
     binned = sc.bins(dim='x', data=array_1d)
     binned.bins.coords.set_aligned('x', False)
