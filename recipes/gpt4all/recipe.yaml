# TODO: Add konpute and cuda support

context:
  version: "3.10.0"

package:
  name: gpt4all
  version: ${{ version }}

source:
  - url: https://github.com/nomic-ai/gpt4all/archive/refs/tags/v${{ version }}.tar.gz
    sha256: 14cfcf13de40e1bfb4df1096aac9d410bfa29d7b0c30a297bb2b3474a554f44e
  - url: https://github.com/nomic-ai/llama.cpp/archive/11f734c3b0334dbae4823b4a7467764e447fc6d6.tar.gz
    sha256: 49a6d9e340474152d68478a46051b39facc5060965edc95a4b08002cfbd5eedc
    target_directory: gpt4all-backend/deps/llama.cpp-mainline

build:
  number: 0

requirements:
  build:
    - ${{ compiler("cxx") }}
    - ${{ stdlib("c") }}
    - cmake
    # - if: cuda_compiler_version != "None"
    #   then: ${{ compiler("cuda") }}
    - if: unix
      then: make
    - if: win
      then: jom
  host:
    - llvm-openmp
    - openblas
    - pip
    - python ${{ python }}
    - setuptools
    - zlib
    # Vulkan
    - if: linux or win
      then:
        - glslang
        - spirv-tools
        - vulkan-headers
        - libvulkan-loader
    # # Cuda
    # - if: (linux or win) and cuda_compiler_version != "None"
    #   then:
    #     - cuda-cudart-dev
    #     - cuda-version ${{ cuda_compiler_version }}
    #     - libcublas-dev
    #     - libcusolver-dev
    #     - libcusparse-dev
  run:
    - jinja2 >=3.1,<4.0
    - python ${{ python }}
    - requests
    - tqdm
    - if: py >= 39 and py < 311
      then: typing-extensions >=4.3.0
  run_exports:
    - ${{ pin_subpackage("gpt4all", upper_bound="x") }}

tests:
  - script: |
      cd gpt4all-bindings/python/gpt4all/tests/test_embed_timings.py
      python test_embed_timings.py
    files:
      source:
        - gpt4all-bindings/python/gpt4all/tests/test_embed_timings.py
  - python:
      imports:
        - gpt4all
      pip_check: true
      python_version:
        - ${{ python }}

about:
  homepage: https://www.nomic.ai/gpt4all
  repository: https://github.com/nomic-ai/gpt4all
  documentation: https://docs.gpt4all.io
  license: MIT
  license_file: LICENSE.txt
  summary: "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use."
  description: |
    Designed for developers, teams, and AI power-users,
    GPT4All runs open-source language models on Windows, macOS, and Linux
    —with full customization, local document chat (LocalDocs), and support for thousands of models
    —empowering you to build assistants and workflows with maximum control, security, and speed.

extra:
  recipe-maintainers:
    - eunos-1128
