{% set name = "s3contents" %}
{% set version = "0.2.2" %}
{% set file_ext = "tar.gz" %}
{% set hash_type = "sha256" %}
{% set hash_value = "ab8904b0e4881dd3be0e030e39035d9f2ea45e162bb8bee88faf576df9897e47" %}

package:
  name: '{{ name|lower }}'
  version: '{{ version }}'

source:
  fn: '{{ name }}-{{ version }}.{{ file_ext }}'
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.{{ file_ext }}
  '{{ hash_type }}': '{{ hash_value }}'

build:
  number: 0
  # skipped on windows due to an issue in the library itself
  skip: True  # [win]
  script: python -m pip install --no-deps --ignore-installed .

requirements:
  host:
    - python
    - pip
  run:
    - python
    - jupyter
    - boto3
    - requests
    - s3fs
    - gcsfs

test:
  requires:
    - nose
    - mock
  imports:
    - s3contents
    - s3contents.tests

about:
  home: https://github.com/danielfrg/s3contents
  license: Apache 2.0
  license_family: APACHE
  license_file: 'LICENSE'
  summary: A S3-backed ContentsManager implementation for Jupyter
  description: |

    A S3 and GCS backed ContentsManager implementation for Jupyter.

    It aims to a be a transparent, drop-in replacement for Jupyter standard
    filesystem-backed storage system. With this implementation of a Jupyter
    Contents Manager you can save all your notebooks, regular files, directories
    structure directly to a S3/GCS bucket, this could be on AWS/GCP or a self
    hosted S3 API compatible like minio.
  dev_url: 'https://github.com/danielfrg/s3contents'

extra:
  recipe-maintainers:
    - mariusvniekerk
