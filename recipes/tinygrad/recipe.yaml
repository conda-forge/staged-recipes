context:
  version: "0.10.1"
  build_number: 0
  # see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
  torch_proc_type: ${{ "cuda" ~ cuda_compiler_version | version_to_buildstring if cuda_compiler_version != "None" else "cpu" }}
  tests_to_skip: >
    _not_a_real_test
    ${{ "fails `assert Device.DEFAULT in failed_platforms`" if 0 }}
    ${{ " or (TestLinearizerFailures and test_failure_27)" if linux }}
    ${{ " or (TestLinearizerFailures and (test_failure_56 or test_failure_57))" if osx }}
    ${{ "Causes `Fatal Python error: Bus error` + segfault" if 0 }}
    ${{ " or testCopySHMtoDefault" if linux }}
    ${{ "timing-sensitive; may fail in our relatively puny CI" if 0 }}
    ${{ " or test_recursive_pad" if linux }}
    ${{ "`NotImplementedError: Encountered unknown relocation type 4` for something elf-related" if 0 }}
    ${{ " or test_backward_sum_acc_dtype" if linux }}
    ${{ "RuntimeError: Attribute list does not match Module context!" if 0 }}
    ${{ " or test_bf16_disk_write_read" if linux and cuda_compiler_version != "None" }}
    ${{ "`error: use of undefined value '@.const.pickledata.7893608704'`" if 0 }}
    ${{ " or (TestWhisper and (test_transcribe_batch21 or test_transcribe_file1))" if osx }}
    ${{ "signed int32 overflow" if 0 }}
    ${{ " or test_float_midcast_int32" if osx }}
    ${{ "tinygrad.codegen.kernel.KernelOptError: must have tensor cores or TC=2" if 0 }}
    ${{ " or test_unmerged_ifs" if osx }}

recipe:
  name: tinygrad
  version: ${{ version }}

source:
  url: https://github.com/tinygrad/tinygrad/archive/refs/tags/v${{ version }}.tar.gz
  sha256: a22402a8c08da0930720b13a8a66a9c9f99507b15fca9caf31fde63776529ca8
  patches:
    - patches/0001-also-install-tinygrad.viz.patch
    # clang 19 doesn't seem to support -std=metal3.1 yet
    - patches/0002-downgrade-default-metal-standard.patch

build:
  number: ${{ build_number }}
  string: ${{ torch_proc_type }}_py${{ python | version_to_buildstring }}_h${{ hash }}_${{ build_number }}
  skip:
    - match(python, "<3.10")
    # toolchain for 11.8 is not usable in end-user environment
    - match(cuda_compiler_version, "==11.8")
    # skip windows until next version (where testing without jax should be possible),
    # or when conda-forge gains windows-support for jax
    - win
    # only one CUDA build because there's not enough disk space to build all variants in one job
    - cuda_compiler_version != "None" and match(python, "!=3.12")

outputs:
  - package:
      name: tinygrad
    build:
      script: python -m pip install . -vv
    requirements:
      host:
        - python
        - pip
        - setuptools
      run:
        - python
        - if: win
          then:
            - clang-cl_${{ target_platform }}
          else:
            - clangxx_${{ target_platform }}
        - if: cuda_compiler_version != "None"
          then:
            - cuda-nvcc_${{ target_platform }}
            - triton
    tests:
      - python:
          imports:
          - tinygrad
          pip_check: true

  - package:
      name: tinygrad-tests
    requirements:
      run:
        - ${{ pin_subpackage('tinygrad', exact=True) }}
    tests:
      - requirements:
          run:
            # minimal
            - pytest
            - pytest-rerunfailures
            - pytest-xdist
            - hypothesis
            - numpy
            - pytorch
            # optional
            - blobfile
            - bottle
            - capstone
            # https://github.com/conda-forge/staged-recipes/issues/29179
            # - ggml-python
            - if: unix
              then:
                # not available on windows yet
                - jax
            - librosa
            - networkx
            - nibabel
            - onnx2torch
            - onnx
            - py-opencv
            - pillow
            - safetensors
            - sentencepiece
            - tabulate
            - tiktoken
            - tqdm
            - transformers
        files:
          source:
            - examples/
            - extra/
            - test/
        script:
          # tinygrad uses `CLANG` as a boolean switch, which is incompatible with our compiler activation;
          # see https://github.com/tinygrad/tinygrad/blob/v0.10.1/tinygrad/device.py#L13
          - if: unix
            then:
              - unset CLANG
          - if: win
            then:
              - set "CLANG="
          - pytest -n 2 -v test/ -k "not (${{ tests_to_skip }})" --reruns=5 --reruns-delay=5

about:
  homepage: https://github.com/tinygrad/tinygrad
  summary: 'You like pytorch? You like micrograd? You love tinygrad! ❤️'
  description: |
    This may not be the best deep learning framework, but it is a deep learning framework.
    
    Due to its extreme simplicity, it aims to be the easiest framework to add new accelerators to,
    with support for both inference and training. If XLA is CISC, tinygrad is RISC.
  license: MIT
  license_file: LICENSE
  documentation: https://docs.tinygrad.org/
  repository: https://github.com/tinygrad/tinygrad

extra:
  recipe-maintainers:
    - h-vetinari
