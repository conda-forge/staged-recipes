[build-system]
requires = ["setuptools>=62", "torch", "ninja"]
build-backend = "setuptools.build_meta"

[project]
dynamic = ["version"]
name = "flash_attn"
authors = [
    {name = "Tri Dao", email = "trid@cs.stanford.edu"},
]
description="Flash Attention: Fast and Memory-Efficient Exact Attention"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: Unix",
    "License :: OSI Approved :: BSD License",
]
readme = "README.md"
license = {file = "LICENSE"}
dependencies = [
    "torch",
    "einops",
]

[project.urls]
Homepage = "https://github.com/Dao-AILab/flash-attention"

[tool.setuptools.dynamic]
version = {attr = "flash_attn.__version__"}
