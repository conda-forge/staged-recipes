{% set name = "bilm" %}
{% set version = "0.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  # there is no Github release - so this ugly link is needed
  url: https://github.com/allenai/bilm-tf/archive/ebf52c6ec1012a3672247c2d14ff7bcad7fb812b.zip
  sha256: 5722ebd46f4120823469e1c221d4123cc6a1bc33b7083243e0893066e6f5a0f1

build:
  noarch: python
  number: 0
  script: "{{ PYTHON }} -m pip install . --no-deps --ignore-installed --no-cache-dir -vvv"

requirements:
  host:
    - python
    - pip
  run:
    - python
    - tensorflow
    - h5py

test:
    imports:
        - bilm
        - bilm.data
        - bilm.model
        - bilm.elmo
        - bilm.training

about:
  home: https://github.com/allenai/bilm-tf
  license: Apache-2.0
  license_file: LICENSE
  summary: 'Tensorflow implementation of the pretrained biLM used to compute ELMo representations from "Deep contextualized word representations".'
  description: |
    ELMo is a deep contextualized word representation that models both (1) complex characteristics 
    of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts 
    (i.e., to model polysemy). These word vectors are learned functions of the internal states of a 
    deep bidirectional language model (biLM), which is pre-trained on a large text corpus. They can 
    be easily added to existing models and significantly improve the state of the art across a broad 
    range of challenging NLP problems, including question answering, textual entailment and sentiment 
    analysis. 
  doc_url: https://github.com/allenai/bilm-tf
  dev_url: https://github.com/allenai/bilm-tf

extra:
  recipe-maintainers:
    - PhilipMay
