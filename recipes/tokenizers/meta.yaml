{% set name = "tokenizers" %}
{% set version = "0.7.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: a3cb9be31e3be381ab3f9e9ea7f96d4ba83588c40c44fe63b535b7341cdf74fe

build:
  number: 0
  script:
    # - export CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_LINKER=$CC
    # - export CARGO_HOME="$BUILD_PREFIX/cargo"
    # - mkdir $CARGO_HOME
    # - cargo install cargo-license
    - {{ PYTHON }} setup.py install
  missing_dso_whitelist:
    - /usr/lib/libresolv.9.dylib  # [osx]
    - /usr/lib/libgcc_s.so.1  # [linux]

requirements:
  build:
    - {{ compiler('rust') }}
    - make
    - setuptools-rust
    - setuptools
  host:
    - python
    - setuptools-rust
    - setuptools
  run:
    - python

test:
  imports:
    - tokenizers
    - tokenizers.models
    - tokenizers.decoders
    - tokenizers.normalizers
    - tokenizers.pre_tokenizers
    - tokenizers.processors
    - tokenizers.trainers
    - tokenizers.implementations

about:
  home: https://github.com/huggingface/tokenizers
  license: Apache-2.0
  license_family: APACHE
  license_file: LICENSE
  summary: "Fast and Customizable Tokenizers"
  doc_url: https://huggingface.co/tokenizers/

extra:
  recipe-maintainers:
    - oblute
    - rluria14
    - ndmaxar
    - setu4993
