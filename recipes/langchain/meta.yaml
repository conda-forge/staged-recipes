{% set name = "langchain" %}
{% set version = "0.0.119" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/langchain-{{ version }}.tar.gz
  sha256: 95a93c966b1a2ff056c43870747aba1c39924c145179f0b8ffa27fef6a525610

build:
  entry_points:
    - langchain-server = langchain.server:main
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.8,<4.0
    - poetry-core
    - pip
  run:
    - python >=3.8.1,<4.0
    - pydantic >=1.0.0,<2.0.0
    - sqlalchemy >=1.0.0,<2.0.0
    - requests >=2.0.0,<3.0.0
    - pyyaml >=5.4.1
    - numpy >=1.0.0,<2.0.0
    - dataclasses-json >=0.5.7,<0.6.0
    - tenacity >=8.1.0,<9.0.0
    - aiohttp >=3.8.3,<4.0.0
  run_constrained:
    - faiss-cpu >=1.0.0,<2.0.0
    - wikipedia >=1.0.0,<2.0.0
    - elasticsearch >=8.0.0,<9.0.0
    - opensearch-py >=2.0.0,<3.0.0
    - redis-py >=4.0.0,<5.0.0
    - manifest-ml >=0.0.1,<0.0.2
    - spacy >=3.0.0,<4.0.0
    - nltk >=3.0.0,<4.0.0
    - transformers >=4.0.0,<5.0.0
    - beautifulsoup4 >=4.0.0,<5.0.0
    - pytorch >=1.0.0,<2.0.0
    - jinja2 >=3.0.0,<4.0.0
    - tiktoken >=0.0.0,<1.0.0
    - pinecone-client >=2.0.0,<3.0.0
    - weaviate-client >=3.0.0,<4.0.0
    - google-api-python-client 2.70.0
    - wolframalpha 5.0.0
    - anthropic >=0.2.2,<0.3.0
    - qdrant-client >=1.0.4,<2.0.0
    - tensorflow-text >=2.11.0,<3.0.0
    - cohere >=3.0.0,<4.0.0
    - openai >=0.0.0,<1.0.0
    - nlpcloud >=1.0.0,<2.0.0
    - nomic >=1.0.43,<2.0.0
    - huggingface_hub >=0.0.0,<1.0.0
    - google-search-results >=2.0.0,<3.0.0
    - sentence-transformers >=2.0.0,<3.0.0
    - pypdf >=3.4.0,<4.0.0
    - networkx >=2.6.3,<3.0.0
    - aleph-alpha-client >=2.15.0,<3.0.0
    - deeplake >=3.2.9,<4.0.0
    - pgvector >=0.1.6,<0.2.0
    - psycopg2-binary >=2.9.5,<3.0.0

test:
  imports:
    - langchain
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://www.github.com/hwchase17/langchain
  summary: Building applications with LLMs through composability
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - hwchase17
    - dlqqq
